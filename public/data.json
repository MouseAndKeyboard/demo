[
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.692474134,
    "title": "Mixed-Reality Robot Behavior Replay: A System Implementation",
    "abstract": "As robots become increasingly complex, they must explain their behaviors to\ngain trust and acceptance. However, it may be difficult through verbal\nexplanation alone to fully convey information about past behavior, especially\nregarding objects no longer present due to robots' or humans' actions. Humans\noften try to physically mimic past movements to accompany verbal explanations.\nInspired by this human-human interaction, we describe the technical\nimplementation of a system for past behavior replay for robots in this tool\npaper. Specifically, we used Behavior Trees to encode and separate robot\nbehaviors, and schemaless MongoDB to structurally store and query the\nunderlying sensor data and joint control messages for future replay. Our\napproach generalizes to different types of replays, including both manipulation\nand navigation replay, and visual (i.e., augmented reality (AR)) and auditory\nreplay. Additionally, we briefly summarize a user study to further provide\nempirical evidence of its effectiveness and efficiency. Sample code and\ninstructions are available on GitHub at\nhttps:\/\/github.com\/umhan35\/robot-behavior-replay."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.8651524162,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.3861709233,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -1.027440103,
    "title": "Towards Implementing ML-Based Failure Detectors",
    "abstract": "Most existing failure detection algorithms rely on statistical methods, and\nvery few use machine learning (ML). This paper explores the viability of ML in\nthe field of failure detection: is it possible to implement an ML-based\ndetector that achieves a satisfactory quality of service? We implement a\nprototype that uses a basic long short-term memory neural network algorithm,\nand study its behavior with real traces. Although ML model has comparatively\nlonger computing time, our prototype performs well in terms of accuracy and\ndetection time."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8651524162,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Going In Blind: Object Motion Classification using Distributed Tactile Sensing for Safe Reaching in Clutter",
    "abstract": "Robotic manipulators navigating cluttered shelves or cabinets may find it\nchallenging to avoid contact with obstacles. Indeed, rearranging obstacles may\nbe necessary to access a target. Rather than planning explicit motions that\nplace obstacles into a desired pose, we suggest allowing incidental contacts to\nrearrange obstacles while monitoring contacts for safety. Bypassing object\nidentification, we present a method for categorizing object motions from\ntactile data collected from incidental contacts with a capacitive tactile skin\non an Allegro Hand. We formalize tactile cues associated with categories of\nobject motion, demonstrating that they can determine with $>90$% accuracy\nwhether an object is movable and whether a contact is causing the object to\nslide stably (safe contact) or tip (unsafe)."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.9070226202,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": 1.5998033579,
    "title": "Entropy and Seebeck signals meet on the edges",
    "abstract": "We explore the electronic entropy per particle $s$ and Seebeck coefficient\n$\\mathcal{S}$ in zigzag graphene ribbons. Pristine and edge-doped ribbons are\nconsidered using tight-binding models to inspect the role of edge states in the\nobserved thermal transport properties. As a bandgap opens when the ribbons are\ndoped at one or both edges, due to asymmetric edge potentials, we find that $s$\nand $\\mathcal{S}$ signals are closely related to each other: both develop sharp\ndip-peak lineshapes as the chemical potential lies in the gap, while the ratio\n$s\/\\mathcal{S}$ exhibits a near constant value equal to the elementary charge\n$e$ at low temperatures. This constant ratio suggests that $\\mathcal{S}$ can be\nseen as the transport differential entropy per charge, as suggested by some\nauthors. Our calculations also indicate that measurement of $s$ and\n$\\mathcal{S}$ may be useful as a spectroscopic probe of different electronic\nenergy scales involved in such quantities in gapped materials."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -1.7569770067,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 1.7327369984,
    "title": "Exotic Behavior of Parity in the Superradiant Phase of Quantum Rabi Model",
    "abstract": "Parity describing the symmetry of quantum mechanics wavefunction under space\ninversion transformation not only plays an essential role in solving quantum\nsystems but also can be used to manipulate and measure the motional quantum\nstates of such hybrid quantum systems as quantum Rabi model(QRM) and\/or its\nvariants through parity measurements. Here we address an exotic parity behavior\nof the QRM in its superradiant phase by numerical exact diagonalization,\nnamely, the parities of eigenstates of the QRM behave irregular in the strong\ncoupling regime but the sum of parities for each pair of eigenstates beginning\nfrom the ground state remains vanishing. It is found that this exotic behavior\noriginates from the comparability of the photon distribution in the odd and\neven components of Fock basis when the eigenenergies of each pair of\neigenstates approach enough to each other and physically is due to the emergent\ndouble-well potential induced by the strong coupling between the single-mode\nphoton field and the two-level atom. The result not only uncovers the physics\nnot known previously in the QRM but also makes an intrinsic limitation on the\nmeasurement precision of motional quantum states through parity measurements in\nmodern quantum science and technologies."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 1.1349646314,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": 1.7327369984,
    "title": "Off-resonant modulated driving gate protocols for two-photon ground-Rydberg transition and finite Rydberg blockade strength",
    "abstract": "Recently, the notion of two-qubit controlled phase gate via off-resonant\nmodulated driving has been introduced into the neutral atom qubit platform,\nwith respect to both single-photon and two-photon ground-Rydberg transitions.\nIn order to reach a better performance practically, further developments are in\nneed to overcome a few known limitations in previous discussions of this\npromising method. Here, we thoroughly analyze a variety of modulation styles\nfor two-photon transitions, demonstrating the versatility of off-resonant\nmodulated driving protocols. Furthermore, we show that it is possible to refine\nthe designing process for improved performances for specific finite Rydberg\nblockade strength values. In particular, a reduced requirement on the blockade\nstrength can be directly linked to an improvement of connectivity in qubit\narray of neutral atoms. These progress are closely related to the core feature\nthat the atomic wave function acquires a geometric phase from the time\nevolution, which begins and finishes at the same quantum state. Under\nreasonable experimental conditions readily available nowadays, we anticipate\nthat the fidelity of such protocols can reach as high as the essential\nrequirement of NISQ even if the effects of technical errors and cold atoms'\nnonzero temperatures are considered."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.6488403974,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Integrating Conventional Headway Control with Reinforcement Learning to Avoid Bus Bunching",
    "abstract": "Bus bunching is a natural-occurring phenomenon that undermines the efficiency\nand stability of the public transportation system. The mainstream solutions\ncontrol the bus to intentionally stay longer at certain stations. Existing\ncontrol methods include conventional methods that provide a formula to\ncalculate the control time and reinforcement learning (RL) methods that\ndetermine the control policy through repeated interactions with the system. In\nthis paper, we propose an integrated proximal policy optimization model with\ndual-headway (IPPO-DH). IPPO-DH integrates the conventional headway control\nwith reinforcement learning, so that it acquires the advantages of both\nalgorithms -- it is more efficient in normal environments and more stable in\nharsh ones. To demonstrate such an advantage, we design a bus simulation\nenvironment and compare IPPO-DH with RL and several conventional methods. The\nresults show that the proposed model maintains the application value of the\nconventional method by avoiding the instability of the RL method in certain\nenvironments, and improves the efficiency compared with the conventional\ncontrol, shedding new light on real-world bus transit system optimization."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.5595405096,
    "title": "PathFinder: Discovering Decision Pathways in Deep Neural Networks",
    "abstract": "Explainability is becoming an increasingly important topic for deep neural\nnetworks. Though the operation in convolutional layers is easier to understand,\nprocessing becomes opaque in fully-connected layers. The basic idea in our work\nis that each instance, as it flows through the layers, causes a different\nactivation pattern in the hidden layers and in our Paths methodology, we\ncluster these activation vectors for each hidden layer and then see how the\nclusters in successive layers connect to one another as activation flows from\nthe input layer to the output. We find that instances of the same class follow\na small number of cluster sequences over the layers, which we name ``decision\npaths.\" Such paths explain how classification decisions are typically made, and\nalso help us determine outliers that follow unusual paths. We also propose\nusing the Sankey diagram to visualize such pathways. We validate our method\nwith experiments on two feed-forward networks trained on MNIST and CELEB data\nsets, and one recurrent network trained on PenDigits."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Flow induced rigidity percolation in shear thickening suspensions",
    "abstract": "Discontinuous shear thickening (DST) is associated with a sharp rise of a\nsuspension's viscosity with increasing applied shear rate. A key signature of\nDST, highlighted in recent studies, is the very large fluctuations of the\nmeasured stress as the suspension thickens. A clear link between\nmicrostructural development and the dramatic increase of the stress\nfluctuations has not been established yet. To identify the microstructural\nunderpinnings of this behavior, we perform simulations of sheared dense\nsuspensions. By analyzing particle contact networks, we identify a subset of\nconstrained particles that contribute directly to the rapid rise in viscosity\nand the large stress fluctuations. Indeed, both phenomena can be explained by\nthe growth and percolation of constrained particle networks -- in direct\nanalogy to rigidity percolation. A finite size scaling analysis confirms this\nis a percolation phenomenon and allows us to estimate the critical exponents.\nOur findings reveal the specific microstructural transition that underlies DST."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.9589538955,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.692474134,
    "title": "CHARTOPOLIS: A Small-Scale Labor-art-ory for Research and Reflection on Autonomous Vehicles, Human-Robot Interaction, and Sociotechnical Imaginaries",
    "abstract": "CHARTOPOLIS is a multi-faceted sociotechnical testbed meant to aid in\nbuilding connections among engineers, psychologists, anthropologists,\nethicists, and artists. Superficially, it is an urban autonomous-vehicle\ntestbed that includes both a physical environment for small-scale robotic\nvehicles as well as a high-fidelity virtual replica that provides extra\nflexibility by way of computer simulation. However, both environments have been\ndeveloped to allow for participatory simulation with human drivers as well.\nEach physical vehicle can be remotely operated by human drivers that have a\ndriver-seat point of view that immerses them within the small-scale testbed,\nand those same drivers can also pilot high-fidelity models of those vehicles in\na virtual replica of the environment. Juxtaposing human driving performance\nacross these two contexts will help identify to what extent human driving\nbehaviors are sensorimotor responses or involve psychological engagement with a\nsystem that has physical, not virtual, side effects and consequences.\nFurthermore, through collaboration with artists, we have designed the physical\ntestbed to make tangible the reality that technological advancement causes the\nhistory of a city to fork into multiple, parallel timelines that take place\nwithin populations whose increasing isolation effectively creates multiple\nindependent cities in one. Ultimately, CHARTOPOLIS is meant to challenge\nengineers to take a more holistic view when designing autonomous systems, while\nalso enabling them to gather novel data that will assist them in making these\nsystems more trustworthy."
  },
  {
    "CAGR": -0.4786452539,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": -0.8631889569,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -1.9128980884,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.3373958805,
    "title": "HUXt -- An open source, computationally efficient reduced-physics solar wind model, written in Python",
    "abstract": "HUXt is an open source numerical model of the solar wind written in Python.\nIt is based on the solution of the 1D inviscid Burger's equation. This\nreduced-physics approach produces solar wind flow simulations that closely\nemulate the flow produced by 3-D magnetohydrodynamic solar wind models at a\nsmall fraction of the computational expense. While not intended as a\nreplacement for 3-D MHD, the simplicity and computational efficiency of HUXt\noffers several key advantages that enable experiments and the use of techniques\nthat would otherwise be cost prohibitive. For example, large ensembles can\neasily be run with modest computing resources, which are useful for exploring\nand quantifying the uncertainty in space weather predictions, as well as for\nthe application of some data assimilation methods.\n  We present the developments in the latest version of HUXt, v4.0, and discuss\nour plans for future developments and applications of the model. The three key\ndevelopments in v4.0 are: a restructuring of the models solver to enable fully\ntime-dependent boundary conditions, such that HUXt can in principle be\ninitialised with in-situ observations from any of the fleet of heliospheric\nmonitors; new functionality to trace streaklines through the HUXt flow\nsolutions, which can be used to track features such as the Heliospheric Current\nSheet; introduction of a small test-suite so that we can better ensure the\nreliability and reproducibility of HUXt simulations for all users across future\nversions. Other more minor developments are discussed in the article.\n  Future applications of HUXt are discussed, including the development data\nassimilation schemes for assimilation of both remote sensing and in-situ plasma\nmeasures. We discuss the progress of transitioning HUXt into an operational\nmodel at the UK's Met Office Space Weather Operations Center as part of the UK\ngovernments SWIMMR programme."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -1.1517610651,
    "rnd_investment_required_log": -1.3825183138,
    "title": "Fast and Robust Video-Based Exercise Classification via Body Pose Tracking and Scalable Multivariate Time Series Classifiers",
    "abstract": "Technological advancements have spurred the usage of machine learning based\napplications in sports science. Physiotherapists, sports coaches and athletes\nactively look to incorporate the latest technologies in order to further\nimprove performance and avoid injuries. While wearable sensors are very\npopular, their use is hindered by constraints on battery power and sensor\ncalibration, especially for use cases which require multiple sensors to be\nplaced on the body. Hence, there is renewed interest in video-based data\ncapture and analysis for sports science. In this paper, we present the\napplication of classifying S\\&C exercises using video. We focus on the popular\nMilitary Press exercise, where the execution is captured with a video-camera\nusing a mobile device, such as a mobile phone, and the goal is to classify the\nexecution into different types. Since video recordings need a lot of storage\nand computation, this use case requires data reduction, while preserving the\nclassification accuracy and enabling fast prediction. To this end, we propose\nan approach named BodyMTS to turn video into time series by employing body pose\ntracking, followed by training and prediction using multivariate time series\nclassifiers. We analyze the accuracy and robustness of BodyMTS and show that it\nis robust to different types of noise caused by either video quality or pose\nestimation factors. We compare BodyMTS to state-of-the-art deep learning\nmethods which classify human activity directly from videos and show that\nBodyMTS achieves similar accuracy, but with reduced running time and model\nengineering effort. Finally, we discuss some of the practical aspects of\nemploying BodyMTS in this application in terms of accuracy and robustness under\nreduced data quality and size. We show that BodyMTS achieves an average\naccuracy of 87\\%, which is significantly higher than the accuracy of human\ndomain experts."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.808212098,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.025748487,
    "rnd_investment_required_log": 1.7327369984,
    "title": "Joule spectroscopy of hybrid superconductor-semiconductor nanodevices",
    "abstract": "Hybrid superconductor-semiconductor devices offer highly tunable platforms,\npotentially suitable for quantum technology applications, that have been\nintensively studied in the past decade. Here we establish that measurements of\nthe superconductor-to-normal transition originating from Joule heating provide\na powerful spectroscopical tool to characterize such hybrid devices.\nConcretely, we apply this technique to junctions in full-shell Al-InAs\nnanowires in the Little-Parks regime and obtain detailed information of each\nlead independently and in a single measurement, including differences in the\nsuperconducting coherence lengths of the leads, inhomogeneous covering of the\nepitaxial shell, and the inverse superconducting proximity effect; all-in-all\nconstituting a unique fingerprint of each device and highlighting the large\nvariability present in these systems. Besides the practical uses, our work also\nunderscores the importance of heating in hybrid devices, an effect that is\noften overlooked."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.8459347379,
    "title": "DFA: Dynamic Feature Aggregation for Efficient Video Object Detection",
    "abstract": "Video object detection is a fundamental yet challenging task in computer\nvision. One practical solution is to take advantage of temporal information\nfrom the video and apply feature aggregation to enhance the object features in\neach frame. Though effective, those existing methods always suffer from low\ninference speeds because they use a fixed number of frames for feature\naggregation regardless of the input frame. Therefore, this paper aims to\nimprove the inference speed of the current feature aggregation-based video\nobject detectors while maintaining their performance. To achieve this goal, we\npropose a vanilla dynamic aggregation module that adaptively selects the frames\nfor feature enhancement. Then, we extend the vanilla dynamic aggregation module\nto a more effective and reconfigurable deformable version. Finally, we\nintroduce inplace distillation loss to improve the representations of objects\naggregated with fewer frames. Extensive experimental results validate the\neffectiveness and efficiency of our proposed methods: On the ImageNet VID\nbenchmark, integrated with our proposed methods, FGFA and SELSA can improve the\ninference speed by 31% and 76% respectively while getting comparable\nperformance on accuracy."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.847481283,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -2.1424131503,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Deep learning for track recognition in pixel and strip-based particle detectors",
    "abstract": "The reconstruction of charged particle trajectories in tracking detectors is\na key problem in the analysis of experimental data for high-energy and nuclear\nphysics. The amount of data in modern experiments is so large that classical\ntracking methods, such as the Kalman filter, cannot process them fast enough.\nTo solve this problem, we developed two neural network algorithms based on deep\nlearning architectures for track recognition in pixel and strip-based particle\ndetectors. These are TrackNETv3 for local (track by track) and RDGraphNet for\nglobal (all tracks in an event) tracking. These algorithms were tested using\nthe GEM tracker of the BM@N experiment at JINR (Dubna) and the cylindrical GEM\ninner tracker of the BESIII experiment at IHEP CAS (Beijing). The RDGraphNet\nmodel, based on a reverse directed graph, showed encouraging results: 95%\nrecall and 74% precision for track finding. The TrackNETv3 model demonstrated a\nrecall value of 95% and 76% precision. This result can be improved after\nfurther model optimization."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Throwing Objects into A Moving Basket While Avoiding Obstacles",
    "abstract": "The capabilities of a robot will be increased significantly by exploiting\nthrowing behavior. In particular, throwing will enable robots to rapidly place\nthe object into the target basket, located outside its feasible kinematic\nspace, without traveling to the desired location. In previous approaches, the\nrobot often learned a parameterized throwing kernel through analytical\napproaches, imitation learning, or hand-coding. There are many situations in\nwhich such approaches do not work\/generalize well due to various object shapes,\nheterogeneous mass distribution, and also obstacles that might be presented in\nthe environment. It is obvious that a method is needed to modulate the throwing\nkernel through its meta parameters. In this paper, we tackle object throwing\nproblem through a deep reinforcement learning approach that enables robots to\nprecisely throw objects into moving baskets while there are obstacles\nobstructing the path. To the best of our knowledge, we are the first group that\naddresses throwing objects with obstacle avoidance. Such a throwing skill not\nonly increases the physical reachability of a robot arm but also improves the\nexecution time. In particular, the robot detects the pose of the target object,\nbasket, and obstacle at each time step, predicts the proper grasp configuration\nfor the target object, and then infers appropriate parameters to throw the\nobject into the basket. Due to safety constraints, we develop a simulation\nenvironment in Gazebo to train the robot and then use the learned policy in\nreal-robot directly. To assess the performers of the proposed approach, we\nperform extensive sets of experiments in both simulation and real robots in\nthree scenarios. Experimental results showed that the robot could precisely\nthrow a target object into the basket outside its kinematic range and\ngeneralize well to new locations and objects without colliding with obstacles."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 2.3661742663,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 2.3141419596,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Energy-Rate-Quality Tradeoffs of State-of-the-Art Video Codecs",
    "abstract": "The adoption of video conferencing and video communication services,\naccelerated by COVID-19, has driven a rapid increase in video data traffic. The\ndemand for higher resolutions and quality, the need for immersive video\nformats, and the newest, more complex video codecs increase the energy\nconsumption in data centers and display devices. In this paper, we explore and\ncompare the energy consumption across optimized state-of-the-art video codecs,\nSVT-AV1, VVenC\/VVdeC, VP9, and x.265. Furthermore, we align the energy usage\nwith various objective quality metrics and the compression performance for a\nset of video sequences across different resolutions. The results indicate that\nfrom the tested codecs and configurations, SVT-AV1 provides the best tradeoff\nbetween energy consumption and quality. The reported results aim to serve as a\nguide towards sustainable video streaming while not compromising the quality of\nexperience of the end user."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.729673728,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -1.027440103,
    "title": "Heatmap Distribution Matching for Human Pose Estimation",
    "abstract": "For tackling the task of 2D human pose estimation, the great majority of the\nrecent methods regard this task as a heatmap estimation problem, and optimize\nthe heatmap prediction using the Gaussian-smoothed heatmap as the optimization\nobjective and using the pixel-wise loss (e.g. MSE) as the loss function. In\nthis paper, we show that optimizing the heatmap prediction in such a way, the\nmodel performance of body joint localization, which is the intrinsic objective\nof this task, may not be consistently improved during the optimization process\nof the heatmap prediction. To address this problem, from a novel perspective,\nwe propose to formulate the optimization of the heatmap prediction as a\ndistribution matching problem between the predicted heatmap and the dot\nannotation of the body joint directly. By doing so, our proposed method does\nnot need to construct the Gaussian-smoothed heatmap and can achieve a more\nconsistent model performance improvement during the optimization of the heatmap\nprediction. We show the effectiveness of our proposed method through extensive\nexperiments on the COCO dataset and the MPII dataset."
  },
  {
    "CAGR": -0.0643795475,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.0860305789,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": 0.7562984273,
    "title": "CERBERUS: Simple and Effective All-In-One Automotive Perception Model with Multi Task Learning",
    "abstract": "Perceiving the surrounding environment is essential for enabling autonomous\nor assisted driving functionalities. Common tasks in this domain include\ndetecting road users, as well as determining lane boundaries and classifying\ndriving conditions. Over the last few years, a large variety of powerful Deep\nLearning models have been proposed to address individual tasks of camera-based\nautomotive perception with astonishing performances. However, the limited\ncapabilities of in-vehicle embedded computing platforms cannot cope with the\ncomputational effort required to run a heavy model for each individual task. In\nthis work, we present CERBERUS (CEnteR Based End-to-end peRception Using a\nSingle model), a lightweight model that leverages a multitask-learning approach\nto enable the execution of multiple perception tasks at the cost of a single\ninference. The code will be made publicly available at\nhttps:\/\/github.com\/cscribano\/CERBERUS"
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.8278466905,
    "ROI_percent": -0.0192437628,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.2476060596,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": -1.027440103,
    "title": "Accelerate Reinforcement Learning with PID Controllers in the Pendulum Simulations",
    "abstract": "We propose a Proportional Integral Derivative (PID) controller-based coaching\nscheme to expedite reinforcement learning (RL)."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.808212098,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Low and high-energy localization landscapes for tight-binding Hamiltonians in 2D lattices",
    "abstract": "Localization of electronic wave functions in modern two-dimensional (2D)\nmaterials such as graphene can impact drastically their transport and magnetic\nproperties. The recent localization landscape (LL) theory has brought many\ntools and theoretical results to understand such localization phenomena in the\ncontinuous setting, but with very few extensions so far to the discrete realm\nor to tight-binding Hamiltonians. In this paper, we show how this approach can\nbe extended to almost all known 2D~lattices, and propose a systematic way of\ndesigning LL even for higher dimension. We demonstrate in detail how this LL\ntheory works and predicts accurately not only the location, but also the\nenergies of localized eigenfunctions in the low and high energy regimes for the\nhoneycomb and hexagonal lattices, making it a highly promising tool for\ninvestigating the role of disorder in these materials."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3894497787,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.027440103,
    "title": "Merging Classification Predictions with Sequential Information for Lightweight Visual Place Recognition in Changing Environments",
    "abstract": "Low-overhead visual place recognition (VPR) is a highly active research\ntopic. Mobile robotics applications often operate under low-end hardware, and\neven more hardware capable systems can still benefit from freeing up onboard\nsystem resources for other navigation tasks. This work addresses lightweight\nVPR by proposing a novel system based on the combination of binary-weighted\nclassifier networks with a one-dimensional convolutional network, dubbed\nmerger. Recent work in fusing multiple VPR techniques has mainly focused on\nincreasing VPR performance, with computational efficiency not being highly\nprioritized. In contrast, we design our technique prioritizing low inference\ntimes, taking inspiration from the machine learning literature where the\nefficient combination of classifiers is a heavily researched topic. Our\nexperiments show that the merger achieves inference times as low as 1\nmillisecond, being significantly faster than other well-established lightweight\nVPR techniques, while achieving comparable or superior VPR performance on\nseveral visual changes such as seasonal variations and viewpoint lateral\nshifts."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.1152512465,
    "title": "Deep learning and multi-level featurization of graph representations of microstructural data",
    "abstract": "Many material response functions depend strongly on microstructure, such as\ninhomogeneities in phase or orientation. Homogenization presents the task of\npredicting the mean response of a sample of the microstructure to external\nloading for use in subgrid models and structure-property explorations. Although\nmany microstructural fields have obvious segmentations, learning directly from\nthe graph induced by the segmentation can be difficult because this\nrepresentation does not encode all the information of the full field. We\ndevelop a means of deep learning of hidden features on the reduced graph given\nthe native discretization and a segmentation of the initial input field. The\nfeatures are associated with regions represented as nodes on the reduced graph.\nThis reduced representation is then the basis for the subsequent\nmulti-level\/scale graph convolutional network model. There are a number of\nadvantages of reducing the graph before fully processing with convolutional\nlayers it, such as interpretable features and efficiency on large meshes. We\ndemonstrate the performance of the proposed network relative to convolutional\nneural networks operating directly on the native discretization of the data\nusing three physical exemplars."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.1908569835,
    "title": "The Long Tail of Context: Does it Exist and Matter?",
    "abstract": "Context has been an important topic in recommender systems over the past two\ndecades. A standard representational approach to context assumes that\ncontextual variables and their structures are known in an application. Most of\nthe prior CARS papers following representational approach manually selected and\nconsidered only a few crucial contextual variables in an application, such as\ntime, location, and company of a person. This prior work demonstrated\nsignificant recommendation performance improvements when various CARS-based\nmethods have been deployed in numerous applications. However, some recommender\nsystems applications deal with a much bigger and broader types of contexts, and\nmanually identifying and capturing a few contextual variables is not sufficient\nin such cases. In this paper, we study such ``context-rich'' applications\ndealing with a large variety of different types of contexts. We demonstrate\nthat supporting only a few most important contextual variables, although\nuseful, is not sufficient. In our study, we focus on the application that\nrecommends various banking products to commercial customers within the context\nof dialogues initiated by customer service representatives. In this\napplication, we managed to identify over two hundred types of contextual\nvariables. Sorting those variables by their importance forms the Long Tail of\nContext (LTC). In this paper, we empirically demonstrate that LTC matters and\nusing all these contextual variables from the Long Tail leads to significant\nimprovements in recommendation performance."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -1.5129768028,
    "rnd_investment_required_log": -1.9396287803,
    "title": "Doing data science with platforms crumbs: an investigation into fakes views on YouTube",
    "abstract": "This paper contributes to the ongoing discussions on the scholarly access to\nsocial media data, discussing a case where this access is barred despite its\nvalue for understanding and countering online disinformation and despite the\nabsence of privacy or copyright issues. Our study concerns YouTube's engagement\nmetrics and, more specifically, the way in which the platform removes \"fake\nviews\" (i.e., views considered as artificial or illegitimate by the platform).\nWorking with one and a half year of data extracted from a thousand French\nYouTube channels, we show the massive extent of this phenomenon, which concerns\nthe large majority of the channels and more than half the videos in our corpus.\nOur analysis indicates that most fakes news are corrected relatively late in\nthe life of the videos and that the final view counts of the videos are not\nindependent from the fake views they received. We discuss the potential harm\nthat delays in corrections could produce in content diffusion: by inflating\nviews counts, illegitimate views could make a video appear more popular than it\nis and unwarrantedly encourage its human and algorithmic recommendation.\nUnfortunately, we cannot offer a definitive assessment of this phenomenon,\nbecause YouTube provides no information on fake views in its API or interface.\nThis paper is, therefore, also a call for greater transparency by YouTube and\nother online platforms about information that can have crucial implications for\nthe quality of online public debate."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Dual control of coupled oscillator networks",
    "abstract": "Robust coordination and organization in large ensembles of nonlinear\noscillatory units play a vital role in a wide range of natural and engineered\nsystem. The control of self-organizing network-coupled systems has recently\nseen significant attention, but largely in the context of modifying or\naugmenting existing structures. This leaves a gap in our understanding of\nreactive control, where and how to design direct interventions, and what such\ncontrol strategies may teach us about existing structures and dynamics. Here we\nstudy reactive control of coupled oscillator networks and demonstrate dual\ncontrol strategies that may be implemented interchangeably to achieve\nsynchronization. These differing strategies take advantage of different network\nproperties, the first directly targeting oscillator that are difficult to\nentrain, and the second targeting oscillators with strong influence on others.\nThus, in addition to enlarge strategies for network control, the different\ncontrol sets shed light on the oscillators dynamical and structural roles\nwithin the system. We close with a demonstration of the applicability of dual\ncontrol of a power grid dynamics."
  },
  {
    "CAGR": -0.2715124007,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.2476060596,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": 0.3526483917,
    "title": "That Sounds Right: Auditory Self-Supervision for Dynamic Robot Manipulation",
    "abstract": "Learning to produce contact-rich, dynamic behaviors from raw sensory data has\nbeen a longstanding challenge in robotics. Prominent approaches primarily focus\non using visual or tactile sensing, where unfortunately one fails to capture\nhigh-frequency interaction, while the other can be too delicate for large-scale\ndata collection. In this work, we propose a data-centric approach to dynamic\nmanipulation that uses an often ignored source of information: sound. We first\ncollect a dataset of 25k interaction-sound pairs across five dynamic tasks\nusing commodity contact microphones. Then, given this data, we leverage\nself-supervised learning to accelerate behavior prediction from sound. Our\nexperiments indicate that this self-supervised 'pretraining' is crucial to\nachieving high performance, with a 34.5% lower MSE than plain supervised\nlearning and a 54.3% lower MSE over visual training. Importantly, we find that\nwhen asked to generate desired sound profiles, online rollouts of our models on\na UR10 robot can produce dynamic behavior that achieves an average of 11.5%\nimprovement over supervised learning on audio similarity metrics."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 0.0662541385,
    "title": "TPGNN: Learning High-order Information in Dynamic Graphs via Temporal Propagation",
    "abstract": "Temporal graph is an abstraction for modeling dynamic systems that consist of\nevolving interaction elements. In this paper, we aim to solve an important yet\nneglected problem -- how to learn information from high-order neighbors in\ntemporal graphs? -- to enhance the informativeness and discriminativeness for\nthe learned node representations. We argue that when learning high-order\ninformation from temporal graphs, we encounter two challenges, i.e.,\ncomputational inefficiency and over-smoothing, that cannot be solved by\nconventional techniques applied on static graphs. To remedy these deficiencies,\nwe propose a temporal propagation-based graph neural network, namely TPGNN. To\nbe specific, the model consists of two distinct components, i.e., propagator\nand node-wise encoder. The propagator is leveraged to propagate messages from\nthe anchor node to its temporal neighbors within $k$-hop, and then\nsimultaneously update the state of neighborhoods, which enables efficient\ncomputation, especially for a deep model. In addition, to prevent\nover-smoothing, the model compels the messages from $n$-hop neighbors to update\nthe $n$-hop memory vector preserved on the anchor. The node-wise encoder adopts\ntransformer architecture to learn node representations by explicitly learning\nthe importance of memory vectors preserved on the node itself, that is,\nimplicitly modeling the importance of messages from neighbors at different\nlayers, thus mitigating the over-smoothing. Since the encoding process will not\nquery temporal neighbors, we can dramatically save time consumption in\ninference. Extensive experiments on temporal link prediction and node\nclassification demonstrate the superiority of TPGNN over state-of-the-art\nbaselines in efficiency and robustness."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": -1.027440103,
    "title": "Extending Compositional Attention Networks for Social Reasoning in Videos",
    "abstract": "We propose a novel deep architecture for the task of reasoning about social\ninteractions in videos. We leverage the multi-step reasoning capabilities of\nCompositional Attention Networks (MAC), and propose a multimodal extension\n(MAC-X). MAC-X is based on a recurrent cell that performs iterative mid-level\nfusion of input modalities (visual, auditory, text) over multiple reasoning\nsteps, by use of a temporal attention mechanism. We then combine MAC-X with\nLSTMs for temporal input processing in an end-to-end architecture. Our ablation\nstudies show that the proposed MAC-X architecture can effectively leverage\nmultimodal input cues using mid-level fusion mechanisms. We apply MAC-X to the\ntask of Social Video Question Answering in the Social IQ dataset and obtain a\n2.5% absolute improvement in terms of binary accuracy over the current\nstate-of-the-art."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.5923303378,
    "rnd_investment_required_log": -0.7662503525,
    "title": "Influence Maximization: Divide and Conquer",
    "abstract": "The problem of influence maximization, i.e., finding the set of nodes having\nmaximal influence on a network, is of great importance for several\napplications. In the past two decades, many heuristic metrics to spot\ninfluencers have been proposed. Here, we introduce a framework to boost the\nperformance of any such metric. The framework consists in dividing the network\ninto sectors of influence, and then selecting the most influential nodes within\nthese sectors. We explore three different methodologies to find sectors in a\nnetwork: graph partitioning, graph hyperbolic embedding, and community\nstructure. The framework is validated with a systematic analysis of real and\nsynthetic networks. We show that the gain in performance generated by dividing\na network into sectors before selecting the influential spreaders increases as\nthe modularity and heterogeneity of the network increase. Also, we show that\nthe division of the network into sectors can be efficiently performed in a time\nthat scales linearly with the network size, thus making the framework\napplicable to large-scale influence maximization problems."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.0271308869,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.7569770067,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.3861709233,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 1.1599484684,
    "title": "Interpretable Deep Tracking",
    "abstract": "Imagine experiencing a crash as the passenger of an autonomous vehicle.\nWouldn't you want to know why it happened? Current end-to-end optimizable deep\nneural networks (DNNs) in 3D detection, multi-object tracking, and motion\nforecasting provide little to no explanations about how they make their\ndecisions. To help bridge this gap, we design an end-to-end optimizable\nmulti-object tracking architecture and training protocol inspired by the\nrecently proposed method of interchange intervention training (IIT). By\nenumerating different tracking decisions and associated reasoning procedures,\nwe can train individual networks to reason about the possible decisions via\nIIT. Each network's decisions can be explained by the high-level structural\ncausal model (SCM) it is trained in alignment with. Moreover, our proposed\nmodel learns to rank these outcomes, leveraging the promise of deep learning in\nend-to-end training, while being inherently interpretable."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": -0.3373958805,
    "title": "An attention-based backend allowing efficient fine-tuning of transformer models for speaker verification",
    "abstract": "In recent years, self-supervised learning paradigm has received extensive\nattention due to its great success in various down-stream tasks. However, the\nfine-tuning strategies for adapting those pre-trained models to speaker\nverification task have yet to be fully explored. In this paper, we analyze\nseveral feature extraction approaches built on top of a pre-trained model, as\nwell as regularization and learning rate schedule to stabilize the fine-tuning\nprocess and further boost performance: multi-head factorized attentive pooling\nis proposed to factorize the comparison of speaker representations into\nmultiple phonetic clusters. We regularize towards the parameters of the\npre-trained model and we set different learning rates for each layer of the\npre-trained model during fine-tuning. The experimental results show our method\ncan significantly shorten the training time to 4 hours and achieve SOTA\nperformance: 0.59%, 0.79% and 1.77% EER on Vox1-O, Vox1-E and Vox1-H,\nrespectively."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -1.0038482884,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Extraneousness-Aware Imitation Learning",
    "abstract": "Visual imitation learning provides an effective framework to learn skills\nfrom demonstrations. However, the quality of the provided demonstrations\nusually significantly affects the ability of an agent to acquire desired\nskills. Therefore, the standard visual imitation learning assumes near-optimal\ndemonstrations, which are expensive or sometimes prohibitive to collect.\nPrevious works propose to learn from noisy demonstrations; however, the noise\nis usually assumed to follow a context-independent distribution such as a\nuniform or gaussian distribution. In this paper, we consider another crucial\nyet underexplored setting -- imitation learning with task-irrelevant yet\nlocally consistent segments in the demonstrations (e.g., wiping sweat while\ncutting potatoes in a cooking tutorial). We argue that such noise is common in\nreal world data and term them \"extraneous\" segments. To tackle this problem, we\nintroduce Extraneousness-Aware Imitation Learning (EIL), a self-supervised\napproach that learns visuomotor policies from third-person demonstrations with\nextraneous subsequences. EIL learns action-conditioned observation embeddings\nin a self-supervised manner and retrieves task-relevant observations across\nvisual demonstrations while excluding the extraneous ones. Experimental results\nshow that EIL outperforms strong baselines and achieves comparable policies to\nthose trained with perfect demonstration on both simulated and real-world robot\ncontrol tasks. The project page can be found at\nhttps:\/\/sites.google.com\/view\/eil-website."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 1.0650371595,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.4670767536,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.442284741,
    "title": "Inverse Game Theory for Stackelberg Games: the Blessing of Bounded Rationality",
    "abstract": "Optimizing strategic decisions (a.k.a. computing equilibrium) is key to the\nsuccess of many non-cooperative multi-agent applications. However, in many\nreal-world situations, we may face the exact opposite of this game-theoretic\nproblem -- instead of prescribing equilibrium of a given game, we may directly\nobserve the agents' equilibrium behaviors but want to infer the underlying\nparameters of an unknown game. This research question, also known as inverse\ngame theory, has been studied in multiple recent works in the context of\nStackelberg games. Unfortunately, existing works exhibit quite negative\nresults, showing statistical hardness and computational hardness, assuming\nfollower's perfectly rational behaviors. Our work relaxes the perfect\nrationality agent assumption to the classic quantal response model, a more\nrealistic behavior model of bounded rationality. Interestingly, we show that\nthe smooth property brought by such bounded rationality model actually leads to\nprovably more efficient learning of the follower utility parameters in general\nStackelberg games. Systematic empirical experiments on synthesized games\nconfirm our theoretical results and further suggest its robustness beyond the\nstrict quantal response model."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.847481283,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.0791806145,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Homotopy-based training of NeuralODEs for accurate dynamics discovery",
    "abstract": "Neural Ordinary Differential Equations (NeuralODEs) present an attractive way\nto extract dynamical laws from time series data, as they bridge neural networks\nwith the differential equation-based modeling paradigm of the physical\nsciences. However, these models often display long training times and\nsuboptimal results, especially for longer duration data. While a common\nstrategy in the literature imposes strong constraints to the NeuralODE\narchitecture to inherently promote stable model dynamics, such methods are\nill-suited for dynamics discovery as the unknown governing equation is not\nguaranteed to satisfy the assumed constraints. In this paper, we develop a new\ntraining method for NeuralODEs, based on synchronization and homotopy\noptimization, that does not require changes to the model architecture. We show\nthat synchronizing the model dynamics and the training data tames the\noriginally irregular loss landscape, which homotopy optimization can then\nleverage to enhance training. Through benchmark experiments, we demonstrate our\nmethod achieves competitive or better training loss while often requiring less\nthan half the number of training epochs compared to other model-agnostic\ntechniques. Furthermore, models trained with our method display better\nextrapolation capabilities, highlighting the effectiveness of our method."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Using Deep Reinforcement Learning for mmWave Real-Time Scheduling",
    "abstract": "We study the problem of real-time scheduling in a multi-hop millimeter-wave\n(mmWave) mesh. We develop a model-free deep reinforcement learning algorithm\ncalled Adaptive Activator RL (AARL), which determines the subset of mmWave\nlinks that should be activated during each time slot and the power level for\neach link. The most important property of AARL is its ability to make\nscheduling decisions within the strict time slot constraints of typical 5G\nmmWave networks. AARL can handle a variety of network topologies, network\nloads, and interference models, it can also adapt to different workloads. We\ndemonstrate the operation of AARL on several topologies: a small topology with\n10 links, a moderately-sized mesh with 48 links, and a large topology with 96\nlinks. We show that for each topology, we compare the throughput obtained by\nAARL to that of a benchmark algorithm called RPMA (Residual Profit Maximizer\nAlgorithm). The most important advantage of AARL compared to RPMA is that it is\nmuch faster and can make the necessary scheduling decisions very rapidly during\nevery time slot, while RPMA cannot. In addition, the quality of the scheduling\ndecisions made by AARL outperforms those made by RPMA."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": 2.3585316987,
    "title": "A Propensity-Score Integrated Approach to Bayesian Dynamic Power Prior Borrowing",
    "abstract": "Use of historical control data to augment a small internal control arm in a\nrandomized control trial (RCT) can lead to significant improvement of the\nefficiency of the trial. It introduces the risk of potential bias, since the\nhistorical control population is often rather different from the RCT. Power\nprior approaches have been introduced to discount the historical data to\nmitigate the impact of the population difference. However, even with a Bayesian\ndynamic borrowing which can discount the historical data based on the outcome\nsimilarity of the two populations, a considerable population difference may\nstill lead to a moderate bias. Hence, a robust adjustment for the population\ndifference using approaches such as the inverse probability weighting or\nmatching, can make the borrowing more efficient and robust. In this paper, we\npropose a novel approach integrating propensity score for the covariate\nadjustment and Bayesian dynamic borrowing using power prior. The proposed\napproach uses Bayesian bootstrap in combination with the empirical Bayes method\nutilizing quasi-likelihood for determining the power prior. The performance of\nour approach is examined by a simulation study. We apply the approach to two\nAcute Myeloid Leukemia (AML) studies for illustration."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.7036515238,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Transformation hydrodynamic metamaterials: Rigorous arguments on form invariance and structured design with spatial variance",
    "abstract": "The method of transformation optics has been a powerful tool to manipulate\nphysical fields if governing equations are formally invariant under coordinate\ntransformations. However, regulation of hydrodynamics is still far from\nsatisfactory due to the lack of rigorous arguments on the validation of\ntransformation theory for various categories of fluids. In this paper, we\nsystematically investigate the applicability of transformation optics to fluid\nmechanics. We find that the Stokes equation and the Navier-Stokes equations,\nrespectively describing the Stokes flow and general flow, will alter their\nforms under curvilinear transformations. On the contrary, the Hele-Shaw flow\ncharacterized with shallow geometries rigidly retain the form of its governing\nequation under arbitrary transformations. Based on the derived transformation\nrules, we propose the design of multilayered structures with spatially varying\ncell depth, instead of engineering the rank-2 shear viscosity tensor, to\nrealize the required anisotropy of transformation Hele-Shaw hydrodynamic\nmetamaterials. The theoretical certify and fabrication method revealed in this\nwork may pave an avenue for precisely controlling flow distribution with the\nconcept of artificial structure design."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.247070394,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Learning Depth Vision-Based Personalized Robot Navigation From Dynamic Demonstrations in Virtual Reality",
    "abstract": "For the best human-robot interaction experience, the robot's navigation\npolicy should take into account personal preferences of the user. In this\npaper, we present a learning framework complemented by a perception pipeline to\ntrain a depth vision-based, personalized navigation controller from user\ndemonstrations. Our virtual reality interface enables the demonstration of\nrobot navigation trajectories under motion of the user for dynamic interaction\nscenarios. The novel perception pipeline enrolls a variational autoencoder in\ncombination with a motion predictor. It compresses the perceived depth images\nto a latent state representation to enable efficient reasoning of the learning\nagent about the robot's dynamic environment. In a detailed analysis and\nablation study, we evaluate different configurations of the perception\npipeline. To further quantify the navigation controller's quality of\npersonalization, we develop and apply a novel metric to measure preference\nreflection based on the Fr\\'echet Distance. We discuss the robot's navigation\nperformance in various virtual scenes and demonstrate the first personalized\nrobot navigation controller that solely relies on depth images. A supplemental\nvideo highlighting our approach is available online."
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.865545108,
    "ROI_percent": -0.2360999473,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -0.8459347379,
    "title": "Multiple Instance Learning for Detecting Anomalies over Sequential Real-World Datasets",
    "abstract": "Detecting anomalies over real-world datasets remains a challenging task. Data\nannotation is an intensive human labor problem, particularly in sequential\ndatasets, where the start and end time of anomalies are not known. As a result,\ndata collected from sequential real-world processes can be largely unlabeled or\ncontain inaccurate labels. These characteristics challenge the application of\nanomaly detection techniques based on supervised learning. In contrast,\nMultiple Instance Learning (MIL) has been shown effective on problems with\nincomplete knowledge of labels in the training dataset, mainly due to the\nnotion of bags. While largely under-leveraged for anomaly detection, MIL\nprovides an appealing formulation for anomaly detection over real-world\ndatasets, and it is the primary contribution of this paper. In this paper, we\npropose an MIL-based formulation and various algorithmic instantiations of this\nframework based on different design decisions for key components of the\nframework. We evaluate the resulting algorithms over four datasets that capture\ndifferent physical processes along different modalities. The experimental\nevaluation draws out several observations. The MIL-based formulation performs\nno worse than single instance learning on easy to moderate datasets and\noutperforms single-instance learning on more challenging datasets. Altogether,\nthe results show that the framework generalizes well over diverse datasets\nresulting from different real-world application domains."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.808212098,
    "ROI_percent": -1.0312392903,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Group Personalized Federated Learning",
    "abstract": "Federated learning (FL) can help promote data privacy by training a shared\nmodel in a de-centralized manner on the physical devices of clients. In the\npresence of highly heterogeneous distributions of local data, personalized FL\nstrategy seeks to mitigate the potential client drift. In this paper, we\npresent the group personalization approach for applications of FL in which\nthere exist inherent partitions among clients that are significantly distinct.\nIn our method, the global FL model is fine-tuned through another FL training\nprocess over each homogeneous group of clients, after which each group-specific\nFL model is further adapted and personalized for any client. The proposed\nmethod can be well interpreted from a Bayesian hierarchical modeling\nperspective. With experiments on two real-world datasets, we demonstrate this\napproach can achieve superior personalization performance than other FL\ncounterparts."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Flexible Instrumental Variable Models With Bayesian Additive Regression Trees",
    "abstract": "Methods utilizing instrumental variables have been a fundamental statistical\napproach to estimation in the presence of unmeasured confounding, usually\noccurring in non-randomized observational data common to fields such as\neconomics and public health. However, such methods usually make constricting\nlinearity and additivity assumptions that are inapplicable to the complex\nmodeling challenges of today. The growing body of observational data being\ncollected will necessitate flexible regression modeling while also being able\nto control for confounding using instrumental variables. Therefore, this\narticle presents a nonlinear instrumental variable regression model based on\nBayesian regression tree ensembles to estimate such relationships, including\ninteractions, in the presence of confounding. One exciting application of this\nmethod is to use genetic variants as instruments, known as Mendelian\nrandomization. Body mass index is one factor that is hypothesized to have a\nnonlinear relationship with cardiovascular risk factors such as blood pressure\nwhile interacting with age. Heterogeneity in patient characteristics such as\nage could be clinically interesting from a precision medicine perspective where\nindividualized treatment is emphasized. We present our flexible Bayesian\ninstrumental variable regression tree method with an example from the UK\nBiobank where body mass index is related to blood pressure using genetic\nvariants as the instruments."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.310959674,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Multi-view Human Body Mesh Translator",
    "abstract": "Existing methods for human mesh recovery mainly focus on single-view\nframeworks, but they often fail to produce accurate results due to the\nill-posed setup. Considering the maturity of the multi-view motion capture\nsystem, in this paper, we propose to solve the prior ill-posed problem by\nleveraging multiple images from different views, thus significantly enhancing\nthe quality of recovered meshes. In particular, we present a novel\n\\textbf{M}ulti-view human body \\textbf{M}esh \\textbf{T}ranslator (MMT) model\nfor estimating human body mesh with the help of vision transformer.\nSpecifically, MMT takes multi-view images as input and translates them to\ntargeted meshes in a single-forward manner. MMT fuses features of different\nviews in both encoding and decoding phases, leading to representations embedded\nwith global information. Additionally, to ensure the tokens are intensively\nfocused on the human pose and shape, MMT conducts cross-view alignment at the\nfeature level by projecting 3D keypoint positions to each view and enforcing\ntheir consistency in geometry constraints. Comprehensive experiments\ndemonstrate that MMT outperforms existing single or multi-view models by a\nlarge margin for human mesh recovery task, notably, 28.8\\% improvement in MPVE\nover the current state-of-the-art method on the challenging HUMBI dataset.\nQualitative evaluation also verifies the effectiveness of MMT in reconstructing\nhigh-quality human mesh. Codes will be made available upon acceptance."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.4664321295,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": -1.2495847072,
    "title": "Learning Video-independent Eye Contact Segmentation from In-the-Wild Videos",
    "abstract": "Human eye contact is a form of non-verbal communication and can have a great\ninfluence on social behavior. Since the location and size of the eye contact\ntargets vary across different videos, learning a generic video-independent eye\ncontact detector is still a challenging task. In this work, we address the task\nof one-way eye contact detection for videos in the wild. Our goal is to build a\nunified model that can identify when a person is looking at his gaze targets in\nan arbitrary input video. Considering that this requires time-series relative\neye movement information, we propose to formulate the task as a temporal\nsegmentation. Due to the scarcity of labeled training data, we further propose\na gaze target discovery method to generate pseudo-labels for unlabeled videos,\nwhich allows us to train a generic eye contact segmentation model in an\nunsupervised way using in-the-wild videos. To evaluate our proposed approach,\nwe manually annotated a test dataset consisting of 52 videos of human\nconversations. Experimental results show that our eye contact segmentation\nmodel outperforms the previous video-dependent eye contact detector and can\nachieve 71.88% framewise accuracy on our annotated test set. Our code and\nevaluation dataset are available at\nhttps:\/\/github.com\/ut-vision\/Video-Independent-ECS."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": -0.5595405096,
    "title": "MOTSLAM: MOT-assisted monocular dynamic SLAM using single-view depth estimation",
    "abstract": "Visual SLAM systems targeting static scenes have been developed with\nsatisfactory accuracy and robustness. Dynamic 3D object tracking has then\nbecome a significant capability in visual SLAM with the requirement of\nunderstanding dynamic surroundings in various scenarios including autonomous\ndriving, augmented and virtual reality. However, performing dynamic SLAM solely\nwith monocular images remains a challenging problem due to the difficulty of\nassociating dynamic features and estimating their positions. In this paper, we\npresent MOTSLAM, a dynamic visual SLAM system with the monocular configuration\nthat tracks both poses and bounding boxes of dynamic objects. MOTSLAM first\nperforms multiple object tracking (MOT) with associated both 2D and 3D bounding\nbox detection to create initial 3D objects. Then, neural-network-based\nmonocular depth estimation is applied to fetch the depth of dynamic features.\nFinally, camera poses, object poses, and both static, as well as dynamic map\npoints, are jointly optimized using a novel bundle adjustment. Our experiments\non the KITTI dataset demonstrate that our system has reached best performance\non both camera ego-motion and object tracking on monocular dynamic SLAM."
  },
  {
    "CAGR": -0.0643795475,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.6054785613,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "GT-GAN: General Purpose Time Series Synthesis with Generative Adversarial Networks",
    "abstract": "Time series synthesis is an important research topic in the field of deep\nlearning, which can be used for data augmentation. Time series data types can\nbe broadly classified into regular or irregular. However, there are no existing\ngenerative models that show good performance for both types without any model\nchanges. Therefore, we present a general purpose model capable of synthesizing\nregular and irregular time series data. To our knowledge, we are the first\ndesigning a general purpose time series synthesis model, which is one of the\nmost challenging settings for time series synthesis. To this end, we design a\ngenerative adversarial network-based method, where many related techniques are\ncarefully integrated into a single framework, ranging from neural\nordinary\/controlled differential equations to continuous time-flow processes.\nOur method outperforms all existing methods."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -0.5342586565,
    "rnd_investment_required_log": 0.0662541385,
    "title": "SIR-HUXt -- a particle filter data assimilation scheme for assimilating CME time-elongation profiles",
    "abstract": "We present the development of SIR-HUXt, the integration of a sequential\nimportance resampling (SIR) data assimilation scheme with the HUXt solar wind\nmodel. SIR-HUXt is designed to assimilate the time-elongation profiles of CME\nfronts in the low heliosphere, such as those typically extracted from\nheliospheric imager data returned by the STEREO, Parker Solar Probe, and Solar\nOrbiter missions. We use Observing System Simulation Experiments to explore the\nperformance of SIR-HUXt for a simple synthetic CME scenario of a fully Earth\ndirected CME flowing through a uniform ambient solar wind, where the CME is\ninitialised with the average observed CME speed and width. These experiments\nare performed for a range of observer locations, from 20 deg to 90 deg behind\nEarth, spanning the L5 point where ESA's future Vigil space weather monitor\nwill return heliospheric imager data for operational space weather forecasting.\n  We show that SIR-HUXt performs well at constraining the CME speed, and has\nsome success at constraining the CME longitude. The CME width is largely\nunconstrained by the SIR-HUXt assimilations, and more experiments are required\nto determine if this is due to this specific CME scenario, or is a general\nfeature of assimilating time-elongation profiles. Rank-histograms suggest that\nthe SIR-HUXt ensembles are well calibrated, with no clear indications of bias\nor under\/over dispersion. Improved constraints on the initial CME speed lead\ndirectly to improvements in the CME transit time to Earth and arrival speed.\nFor an observer in the L5 region, SIR-HUXt returned a 69% reduction in the CME\ntransit time uncertainty, and a 63% reduction in the arrival speed uncertainty.\nThis suggests SIR-HUXt has potential to improve the real-world representivity\nof HUXt simulations, and therefore has potential to reduce the uncertainty of\nCME arrival time hindcasts and forecasts."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.808212098,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.4113890639,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Development of novel single-die hybridisation processes for small-pitch pixel detectors",
    "abstract": "Hybrid pixel detectors require a reliable and cost-effective interconnect\ntechnology adapted to the pitch and die sizes of the respective applications.\nDuring the ASIC and sensor R\\&D phase, especially for small-scale applications,\nsuch interconnect technologies need to be suitable for the assembly of single\ndies, typically available from Multi-Project-Wafer submissions. Within the CERN\nEP R&D programme and the AIDAinnova collaboration, innovative hybridisation\nconcepts targeting vertex-detector applications at future colliders are under\ndevelopment. Recent results of two novel interconnect methods for pixel pitches\nof 25um and 55um are presented in this contribution -- an industrial fine-pitch\nSnAg solder bump-bonding process adapted to single-die processing using support\nwafers, as well as a newly developed in-house single-die interconnection\nprocess based on ACF.\n  The fine-pitch bump-bonding process is qualified with hybrid assemblies from\na recent bonding campaign at Frauenhofer IZM. Individual CLICpix2 ASICs with\n25um pixel pitch were bump-bonded to active-edge silicon sensors with\nthicknesses ranging from 50um to 130um. The device characterisation was\nconducted in the laboratory as well as during a beam test campaign at the CERN\nSPS beam-line, demonstrating an interconnect yield of about 99.7%.\n  The ACF interconnect technology replaces the solder bumps by conductive\nmicro-particles embedded in an epoxy film. The electro-mechanical connection\nbetween the sensor and ASIC is achieved via thermocompression of the ACF using\na flip-chip device bonder. The required pixel pad topology is achieved with an\nin-house ENIG plating process. This newly developed ACF hybridisation process\nis first qualified with the Timepix3 ASICs and sensors with 55um pixel pitch.\nThe technology can be also used for ASIC-PCB\/FPC integration, replacing wire\nbonding or large-pitch solder bumping techniques."
  },
  {
    "CAGR": -0.4786452539,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Design rules for active control of narrowband thermal emission using phase-change materials",
    "abstract": "We propose an analytical framework to design actively tunable narrowband\nthermal emitters at infrared frequencies. We exemplify the proposed design\nrules using phase-change materials (PCM), considering dielectric-to-dielectric\nPCMs (e.g. GSST) and dielectric-to-metal PCMs (e.g. $\\mathrm{VO_2}$). Based on\nthese, we numerically illustrate near-unity ON-OFF switching and arbitrarily\nlarge spectral shifting between two emission wavelengths, respectively. The\nproposed systems are lithography-free and consist of one or several thin\nemitter layers, a spacer layer which includes the PCM, and a back reflector.\nOur model applies to normal incidence, though we show that the behavior is\nessentially angle-independent. The presented formalism is general and can be\nextended to \\textit{any} mechanism that modifies the optical properties of a\nmaterial, such as electrostatic gating or thermo-optical modulation."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.1240877464,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": -0.7662503525,
    "title": "SHINE-Mapping: Large-Scale 3D Mapping Using Sparse Hierarchical Implicit Neural Representations",
    "abstract": "Accurate mapping of large-scale environments is an essential building block\nof most outdoor autonomous systems. Challenges of traditional mapping methods\ninclude the balance between memory consumption and mapping accuracy. This paper\naddresses the problem of achieving large-scale 3D reconstruction using implicit\nrepresentations built from 3D LiDAR measurements. We learn and store implicit\nfeatures through an octree-based, hierarchical structure, which is sparse and\nextensible. The implicit features can be turned into signed distance values\nthrough a shallow neural network. We leverage binary cross entropy loss to\noptimize the local features with the 3D measurements as supervision. Based on\nour implicit representation, we design an incremental mapping system with\nregularization to tackle the issue of forgetting in continual learning. Our\nexperiments show that our 3D reconstructions are more accurate, complete, and\nmemory-efficient than current state-of-the-art 3D mapping methods."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.7562984273,
    "title": "When Physical Layer Key Generation Meets RIS: Opportunities, Challenges, and Road Ahead",
    "abstract": "Physical layer key generation (PLKG) is a promising technology to obtain\nsymmetric keys between a pair of wireless communication users in a\nplug-and-play manner. The shared entropy source almost entirely comes from the\nintrinsic randomness of the radio channel, which is highly dependent on the\nwireless environments. However, in some static\/block fading wireless\nenvironments, the intrinsic randomness of the wireless channel is hard to be\nguaranteed. Very recently, thanks to reconfigurable intelligent surfaces (RISs)\nwith their excellent ability on electromagnetic wave control, the wireless\nchannel environment can be customized. In this article, we overview the\nRISaided PLKG in static indoor environments, including its channel model and\nhardware architectures. Then, we propose potential application scenarios and\nanalyze the design challenges of RIS aided PLKG, including channel reciprocity,\nRIS reconfiguration speed and RIS deployment via proof-of-concept experiments\non a RIS-aided PLKG prototype system. In particular, our experimental results\nshow that the key generation rate is 15-fold higher than that without RIS in a\nstatic indoor environment. Next, we design a RIS jamming attack via a prototype\nexperiment and discuss its possible attack-defense countermeasures. Finally,\nseveral conclusions and future directions are identified."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -1.1323289524,
    "title": "Particle clustering in turbulence: Prediction of spatial and statistical properties with deep learning",
    "abstract": "We investigate the utility of deep learning for modeling the clustering of\nparticles that are aerodynamically coupled to turbulent fluids. Using a\nLagrangian particle module within the Athena++ hydrodynamics code, we simulate\nthe dynamics of particles in the Epstein drag regime within a periodic domain\nof isotropic forced hydrodynamic turbulence. This setup is an idealized model\nrelevant to the collisional growth of micron to mm-sized dust particles in\nearly stage planet formation. The simulation data are used to train a U-Net\ndeep learning model to predict gridded three-dimensional representations of the\nparticle density and velocity fields, given as input the corresponding fluid\nfields. The trained model qualitatively captures the filamentary structure of\nclustered particles in a highly non-linear regime. We assess model fidelity by\ncalculating metrics of the density field (the radial distribution function) and\nof the velocity field (the relative velocity and the relative radial velocity\nbetween particles). Although trained only on the spatial fields, the model\npredicts these statistical quantities with errors that are typically <10%. Our\nresults suggest that, given appropriately expanded training data, deep learning\ncould complement direct numerical simulations in predicting particle clustering\nwithin turbulent flows."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.8278466905,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 2.3858924402,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.0791806145,
    "rnd_investment_required_log": -1.027440103,
    "title": "Visual Backtracking Teleoperation: A Data Collection Protocol for Offline Image-Based Reinforcement Learning",
    "abstract": "We consider how to most efficiently leverage teleoperator time to collect\ndata for learning robust image-based value functions and policies for sparse\nreward robotic tasks. To accomplish this goal, we modify the process of data\ncollection to include more than just successful demonstrations of the desired\ntask. Instead we develop a novel protocol that we call Visual Backtracking\nTeleoperation (VBT), which deliberately collects a dataset of visually similar\nfailures, recoveries, and successes. VBT data collection is particularly useful\nfor efficiently learning accurate value functions from small datasets of\nimage-based observations. We demonstrate VBT on a real robot to perform\ncontinuous control from image observations for the deformable manipulation task\nof T-shirt grasping. We find that by adjusting the data collection process we\nimprove the quality of both the learned value functions and policies over a\nvariety of baseline methods for data collection. Specifically, we find that\noffline reinforcement learning on VBT data outperforms standard behavior\ncloning on successful demonstration data by 13% when both methods are given\nequal-sized datasets of 60 minutes of data from the real robot."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Domain Adaptation for Unknown Image Distortions in Instance Segmentation",
    "abstract": "Data-driven techniques for machine vision heavily depend on the training data\nto sufficiently resemble the data occurring during test and application.\nHowever, in practice unknown distortion can lead to a domain gap between\ntraining and test data, impeding the performance of a machine vision system.\nWith our proposed approach this domain gap can be closed by unpaired learning\nof the pristine-to-distortion mapping function of the unknown distortion. This\nlearned mapping function may then be used to emulate the unknown distortion in\nthe training data. Employing a fixed setup, our approach is independent from\nprior knowledge of the distortion. Within this work, we show that we can\neffectively learn unknown distortions at arbitrary strengths. When applying our\napproach to instance segmentation in an autonomous driving scenario, we achieve\nresults comparable to an oracle with knowledge of the distortion. An average\ngain in mean Average Precision (mAP) of up to 0.19 can be achieved."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Modeling the Solar Wind During Different Phases of the Last Solar Cycle",
    "abstract": "We describe our first attempt to systematically simulate the solar wind\nduring different phases of the last solar cycle with the Alfv\\'en Wave Solar\natmosphere Model (AWSoM) developed at the University of Michigan. Key to this\nstudy is the determination of the optimal values of one of the most important\ninput parameters of the model, the Poynting flux parameter, which prescribes\nthe energy flux passing through the chromospheric boundary of the model in the\nform of Alfv\\'en wave turbulence. It is found that the optimal value of the\nPoynting flux parameter is correlated with the area of the open magnetic field\nregions with the Spearman's correlation coefficient of 0.96 and anti-correlated\nwith the average unsigned radial component of the magnetic field with the\nSpearman's correlation coefficient of -0.91. Moreover, the Poynting flux in the\nopen field regions is approximately constant in the last solar cycle, which\nneeds to be validated with observations and can shed light on how Alfv\\'en wave\nturbulence accelerates the solar wind during different phases of the solar\ncycle. Our results can also be used to set the Poynting flux parameter for\nreal-time solar wind simulations with AWSoM."
  },
  {
    "CAGR": 1.7307718468,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.847481283,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.3930636585,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Toward Knowledge-Driven Speech-Based Models of Depression: Leveraging Spectrotemporal Variations in Speech Vowels",
    "abstract": "Psychomotor retardation associated with depression has been linked with\ntangible differences in vowel production. This paper investigates a\nknowledge-driven machine learning (ML) method that integrates spectrotemporal\ninformation of speech at the vowel-level to identify the depression. Low-level\nspeech descriptors are learned by a convolutional neural network (CNN) that is\ntrained for vowel classification. The temporal evolution of those low-level\ndescriptors is modeled at the high-level within and across utterances via a\nlong short-term memory (LSTM) model that takes the final depression decision. A\nmodified version of the Local Interpretable Model-agnostic Explanations (LIME)\nis further used to identify the impact of the low-level spectrotemporal vowel\nvariation on the decisions and observe the high-level temporal change of the\ndepression likelihood. The proposed method outperforms baselines that model the\nspectrotemporal information in speech without integrating the vowel-based\ninformation, as well as ML models trained with conventional prosodic and\nspectrotemporal features. The conducted explainability analysis indicates that\nspectrotemporal information corresponding to non-vowel segments less important\nthan the vowel-based information. Explainability of the high-level information\ncapturing the segment-by-segment decisions is further inspected for\nparticipants with and without depression. The findings from this work can\nprovide the foundation toward knowledge-driven interpretable decision-support\nsystems that can assist clinicians to better understand fine-grain temporal\nchanges in speech data, ultimately augmenting mental health diagnosis and care."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Photocurrent and photoacoustic detection of plasmonic behavior of CdSe quantum dots grown in Au nanogaps",
    "abstract": "In this work, the influence of Au plasmonics on photocurrent generation in\nthe visible wavelength range in integrated thiol-linked CdSe quantum dot\/Au\nnanogap structures is demonstrated. The plasmonic absorption is sensed\nutilizing photoacoustic (PA) detection technique. The laser diode is modulated\nto generate the PA excitation that oscillates the air-filled cell. When light\nabsorption increases, an enhanced acoustic signal is captured by a microphone.\nThe observed enhancement in the PA response is related to plasmonic absorption\nby the Au layers and the response is further enhanced by about 20% due to CdSe\nQDs. In our structure, the surface plasmon resonance (SPR) wavelength is\napproximately 500 nm. The SPR is utilized for generating photocurrents in CdSe\nquantum dots. Due to energy transfer from the dot to closely spaced Au surface\nthrough thiol links, a smooth transmission channel of electrons is established\nthat forms a detectable photocurrent, which can be tuned by a bias voltage.\nThese plasmonic nanogap structures can enable higher sensitivity in\nphotovoltaics, photodetection and sensing."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.7198564318,
    "ROI_percent": 0.7036101854,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -2.2878707487,
    "annual_revenue_USD_log": 2.0770471924,
    "rnd_investment_required_log": -1.1323289524,
    "title": "Water Simulation and Rendering from a Still Photograph",
    "abstract": "We propose an approach to simulate and render realistic water animation from\na single still input photograph. We first segment the water surface, estimate\nrendering parameters, and compute water reflection textures with a combination\nof neural networks and traditional optimization techniques. Then we propose an\nimage-based screen space local reflection model to render the water surface\noverlaid on the input image and generate real-time water animation. Our\napproach creates realistic results with no user intervention for a wide variety\nof natural scenes containing large bodies of water with different lighting and\nwater surface conditions. Since our method provides a 3D representation of the\nwater surface, it naturally enables direct editing of water parameters and also\nsupports interactive applications like adding synthetic objects to the scene."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6216834693,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.6684873834,
    "title": "Role of Deep Learning in Wireless Communications",
    "abstract": "Traditional communication system design has always been based on the paradigm\nof first establishing a mathematical model of the communication channel, then\ndesigning and optimizing the system according to the model. The advent of\nmodern machine learning techniques, specifically deep neural networks, has\nopened up opportunities for data-driven system design and optimization. This\narticle draws examples from the optimization of reconfigurable intelligent\nsurface, distributed channel estimation and feedback for multiuser beamforming,\nand active sensing for millimeter wave (mmWave) initial alignment to illustrate\nthat a data-driven design that bypasses explicit channel modelling can often\ndiscover excellent solutions to communication system design and optimization\nproblems that are otherwise computationally difficult to solve. We show that by\nperforming an end-to-end training of a deep neural network using a large number\nof channel samples, a machine learning based approach can potentially provide\nsignificant system-level improvements as compared to the traditional\nmodel-based approach for solving optimization problems. The key to the\nsuccessful applications of machine learning techniques is in choosing the\nappropriate neural network architecture to match the underlying problem\nstructure."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.0791806145,
    "rnd_investment_required_log": 0.9097590502,
    "title": "Federated Learning with Server Learning: Enhancing Performance for Non-IID Data",
    "abstract": "Federated Learning (FL) has emerged as a means of distributed learning using\nlocal data stored at clients with a coordinating server. Recent studies showed\nthat FL can suffer from poor performance and slower convergence when training\ndata at clients are not independent and identically distributed. Here we\nconsider a new complementary approach to mitigating this performance\ndegradation by allowing the server to perform auxiliary learning from a small\ndataset. Our analysis and experiments show that this new approach can achieve\nsignificant improvements in both model accuracy and convergence time even when\nthe server dataset is small and its distribution differs from that of the\naggregated data from all clients."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -1.2495847072,
    "title": "TensorAnalyzer: Identification of Urban Patterns in Big Cities using Non-Negative Tensor Factorization",
    "abstract": "Extracting relevant urban patterns from multiple data sources can be\ndifficult using classical clustering algorithms since we have to make a\nsuitable setup of the hyperparameters of the algorithms and deal with outliers.\nIt should be addressed correctly to help urban planners in the decision-making\nprocess for the further development of a big city. For instance, experts' main\ninterest in criminology is comprehending the relationship between crimes and\nthe socio-economic characteristics at specific georeferenced locations. In\naddition, the classical clustering algorithms take little notice of the\nintricate spatial correlations in georeferenced data sources. This paper\npresents a new approach to detecting the most relevant urban patterns from\nmultiple data sources based on tensor decomposition. Compared to classical\nmethods, the proposed approach's performance is attested to validate the\nidentified patterns' quality. The result indicates that the approach can\neffectively identify functional patterns to characterize the data set for\nfurther analysis in achieving good clustering quality. Furthermore, we\ndeveloped a generic framework named TensorAnalyzer, where the effectiveness and\nusefulness of the proposed methodology are tested by a set of experiments and a\nreal-world case study showing the relationship between the crime events around\nschools and students performance and other variables involved in the analysis."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.053041632,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.9086309264,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 2.4921676729,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Operationalizing Specifications, In Addition to Test Sets for Evaluating Constrained Generative Models",
    "abstract": "In this work, we present some recommendations on the evaluation of\nstate-of-the-art generative models for constrained generation tasks. The\nprogress on generative models has been rapid in recent years. These large-scale\nmodels have had three impacts: firstly, the fluency of generation in both\nlanguage and vision modalities has rendered common average-case evaluation\nmetrics much less useful in diagnosing system errors. Secondly, the same\nsubstrate models now form the basis of a number of applications, driven both by\nthe utility of their representations as well as phenomena such as in-context\nlearning, which raise the abstraction level of interacting with such models.\nThirdly, the user expectations around these models and their feted public\nreleases have made the technical challenge of out of domain generalization much\nless excusable in practice. Subsequently, our evaluation methodologies haven't\nadapted to these changes. More concretely, while the associated utility and\nmethods of interacting with generative models have expanded, a similar\nexpansion has not been observed in their evaluation practices. In this paper,\nwe argue that the scale of generative models could be exploited to raise the\nabstraction level at which evaluation itself is conducted and provide\nrecommendations for the same. Our recommendations are based on leveraging\nspecifications as a powerful instrument to evaluate generation quality and are\nreadily applicable to a variety of tasks."
  },
  {
    "CAGR": -1.0033818153,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 3.4504551886,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.9070226202,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 2.4081102092,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": 1.5998033579,
    "title": "Configurational Forces in Penetration Processes",
    "abstract": "With a loose reference to problems of penetration in biomechanics (for\ninstance, a nanoparticle penetrating through a cell's membrane or a cell sucked\nwith a pipette), the role of configurational forces is investigated during the\nprocess in which a compliant intruder is inserted into an elastic structure.\nFor insertion into a rigid constraint, a configurational force proportional to\nthe square of the strain needed to deform the body, which is penetrating, is\nfound. This force has a more complex structure when the compliance of the\nconstraint is kept into account, but in all cases, it tends to expel the\npenetrating body."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.742097711,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.4664321295,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": 1.6684873834,
    "title": "A Framework for Obtaining Accurate Posteriors of Strong Gravitational Lensing Parameters with Flexible Priors and Implicit Likelihoods using Density Estimation",
    "abstract": "We report the application of implicit likelihood inference to the prediction\nof the macro-parameters of strong lensing systems with neural networks. This\nallows us to perform deep learning analysis of lensing systems within a\nwell-defined Bayesian statistical framework to explicitly impose desired priors\non lensing variables, to obtain accurate posteriors, and to guarantee\nconvergence to the optimal posterior in the limit of perfect performance. We\ntrain neural networks to perform a regression task to produce point estimates\nof lensing parameters. We then interpret these estimates as compressed\nstatistics in our inference setup and model their likelihood function using\nmixture density networks. We compare our results with those of approximate\nBayesian neural networks, discuss their significance, and point to future\ndirections. Based on a test set of 100,000 strong lensing simulations, our\namortized model produces accurate posteriors for any arbitrary confidence\ninterval, with a maximum percentage deviation of $1.4\\%$ at $21.8\\%$ confidence\nlevel, without the need for any added calibration procedure. In total,\ninferring 100,000 different posteriors takes a day on a single GPU, showing\nthat the method scales well to the thousands of lenses expected to be\ndiscovered by upcoming sky surveys."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.729673728,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.6432509228,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Dynamic Light Scattering based microrheology of End-functionalised triblock copolymer solutions",
    "abstract": "'Soft' patchy surfactant micelles have become an additional building tool in\nself-assembling systems. The triblock copolymer, Pluronic F108, forms spherical\nmicelles in aqueous solutions upon heating leading to a simple phase diagram\nwith a micellar crystalline solid at higher temperatures and concentrations.\nHere we report the strong influence of end-functionalising the chain ends\neither with an azide or azide-DNA complex on the systems' phase behaviour. We\nfind that the azide(N3)- functionalisation renders the chain ends weakly\nhydrophobic at lower temperatures, causing them to self-assemble into\nflower-micelles. This hydrophobicity increases with increasing temperature and\nposes a competing self-assembling mechanism to the solvent induces hydrophobic\ninteractions between the middle-blocks of F108 at higher temperatures and leads\nto a macroscopic phase separation that is absent in the pure F108 system.\nHowever, when we attached short, hydrophilic single-stranded (ss)DNA to the\nazide groups via click chemistry the chain ends became 'sticky' due to DNA\nhybridisation below the melting temperature of the complementary ssDNA ends\nwhile reverting to hydrophilic behaviour above. We characterise their\nstructural and rheological properties via Dynamic Light Scattering (DLS) and\nDLS-based passive microrheology with an improved time-frequency domain\ninversion step. We present the structural behaviour of dilute and semi-dilute\nsolutions of the original F108 system and compare the results with solutions\ncontaining either the F108- azide (F108-N3) or partially DNA-functionalised\nF108-azide chains. Our DLS and microrheology studies inform us on how the\nattachment of azide groups on F108 changes the mechanical and structural\nproperties of micellar fluids pioneering further characterisation and design of\nthese hybrid systems."
  },
  {
    "CAGR": 0.3775038726,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.4890352234,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.2539029658,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Rogue Emitter Detection Using Hybrid Network of Denoising Autoencoder and Deep Metric Learning",
    "abstract": "Rogue emitter detection (RED) is a crucial technique to maintain secure\ninternet of things applications. Existing deep learning-based RED methods have\nbeen proposed under the friendly environments. However, these methods perform\nunstable under low signal-to-noise ratio (SNR) scenarios. To address this\nproblem, we propose a robust RED method, which is a hybrid network of denoising\nautoencoder and deep metric learning (DML). Specifically, denoising autoencoder\nis adopted to mitigate noise interference and then improve its robustness under\nlow SNR while DML plays an important role to improve the feature\ndiscrimination. Several typical experiments are conducted to evaluate the\nproposed RED method on an automatic dependent surveillance-Broadcast dataset\nand an IEEE 802.11 dataset and also to compare it with existing RED methods.\nSimulation results show that the proposed method achieves better RED\nperformance and higher noise robustness with more discriminative semantic\nvectors than existing methods."
  },
  {
    "CAGR": -1.0033818153,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.2055361568,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.3526483917,
    "title": "MMSpeech: Multi-modal Multi-task Encoder-Decoder Pre-training for Speech Recognition",
    "abstract": "In this paper, we propose a novel multi-modal multi-task encoder-decoder\npre-training framework (MMSpeech) for Mandarin automatic speech recognition\n(ASR), which employs both unlabeled speech and text data. The main difficulty\nin speech-text joint pre-training comes from the significant difference between\nspeech and text modalities, especially for Mandarin speech and text. Unlike\nEnglish and other languages with an alphabetic writing system, Mandarin uses an\nideographic writing system where character and sound are not tightly mapped to\none another. Therefore, we propose to introduce the phoneme modality into\npre-training, which can help capture modality-invariant information between\nMandarin speech and text. Specifically, we employ a multi-task learning\nframework including five self-supervised and supervised tasks with speech and\ntext data. For end-to-end pre-training, we introduce self-supervised\nspeech-to-pseudo-codes (S2C) and phoneme-to-text (P2T) tasks utilizing\nunlabeled speech and text data, where speech-pseudo-codes pairs and\nphoneme-text pairs are a supplement to the supervised speech-text pairs. To\ntrain the encoder to learn better speech representation, we introduce\nself-supervised masked speech prediction (MSP) and supervised phoneme\nprediction (PP) tasks to learn to map speech into phonemes. Besides, we\ndirectly add the downstream supervised speech-to-text (S2T) task into the\npre-training process, which can further improve the pre-training performance\nand achieve better recognition results even without fine-tuning. Experiments on\nAISHELL-1 show that our proposed method achieves state-of-the-art performance,\nwith a more than 40% relative improvement compared with other pre-training\nmethods."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.1799051383,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.692474134,
    "title": "Efficient implementation and performance analysis of the independent electron surface hopping method for dynamics at metal surfaces",
    "abstract": "Independent electron surface hopping (IESH) is a computational algorithm for\nsimulating the mixed quantum-classical molecular dynamics of adsorbate atoms\nand molecules interacting with metal surfaces. It is capable of modelling the\nnonadiabatic effects of electron-hole pair excitations on molecular dynamics.\nHere we present a transparent, reliable, and efficient implementation of IESH,\ndemonstrating its ability to predict scattering and desorption probabilities\nacross a variety of systems, ranging from model Hamiltonians to full\ndimensional atomistic systems. We further show how the algorithm can be\nmodified to account for the application of an external bias potential,\ncomparing its accuracy to results obtained using the hierarchical quantum\nmaster equation. Our results show that IESH is a practical method for modelling\ncoupled electron-nuclear dynamics at metal surfaces, especially for highly\nenergetic scattering events."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.8459347379,
    "title": "Unexpected Scaling in Path Copying Trees",
    "abstract": "Although a wide variety of handcrafted concurrent data structures have been\nproposed, there is considerable interest in universal approaches (henceforth\ncalled Universal Constructions or UCs) for building concurrent data structures.\nThese approaches (semi-)automatically convert a sequential data structure into\na concurrent one. The simplest approach uses locks that protect a sequential\ndata structure and allow only one process to access it at a time. The resulting\ndata structures use locks, and hence are blocking. Most work on UCs instead\nfocuses on obtaining non-blocking progress guarantees such as\nobstruction-freedom, lock-freedom, or wait-freedom. Many non-blocking UCs have\nappeared. Key examples include the seminal wait-free UC by Herlihy, a\nNUMA-aware UC by Yi et al., and an efficient UC for large objects by Fatourou\net al.\n  We borrow ideas from persistent data structures and multi-version concurrency\ncontrol (MVCC), most notably path copying, and use them to implement concurrent\nversions of sequential persistent data structures. Despite our expectation that\nour data structures would not scale under write-heavy workloads, they scale in\npractice. We confirm this scaling analytically in our model with private\nper-process caches."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.310959674,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.3086955919,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.2476060596,
    "annual_revenue_USD_log": 2.1709094741,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Leveraging Single-View Images for Unsupervised 3D Point Cloud Completion",
    "abstract": "Point clouds captured by scanning devices are often incomplete due to\nocclusion. To overcome this limitation, point cloud completion methods have\nbeen developed to predict the complete shape of an object based on its partial\ninput. These methods can be broadly classified as supervised or unsupervised.\nHowever, both categories require a large number of 3D complete point clouds,\nwhich may be difficult to capture. In this paper, we propose Cross-PCC, an\nunsupervised point cloud completion method without requiring any 3D complete\npoint clouds. We only utilize 2D images of the complete objects, which are\neasier to capture than 3D complete and clean point clouds. Specifically, to\ntake advantage of the complementary information from 2D images, we use a\nsingle-view RGB image to extract 2D features and design a fusion module to fuse\nthe 2D and 3D features extracted from the partial point cloud. To guide the\nshape of predicted point clouds, we project the predicted points of the object\nto the 2D plane and use the foreground pixels of its silhouette maps to\nconstrain the position of the projected points. To reduce the outliers of the\npredicted point clouds, we propose a view calibrator to move the points\nprojected to the background into the foreground by the single-view silhouette\nimage. To the best of our knowledge, our approach is the first point cloud\ncompletion method that does not require any 3D supervision. The experimental\nresults of our method are superior to those of the state-of-the-art\nunsupervised methods by a large margin. Moreover, our method even achieves\ncomparable performance to some supervised methods. We will make the source code\npublicly available at https:\/\/github.com\/ltwu6\/cross-pcc."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.4890352234,
    "ROI_percent": -1.6095224489,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": -0.3373958805,
    "title": "ML framework for global river flood predictions based on the Caravan dataset",
    "abstract": "Reliable prediction of river floods in the first 72 hours can reduce harm\nbecause emergency agencies have sufficient time to prepare and deploy for help\nat the scene. Such river flood prediction models already exist and perform\nrelatively well in most high-income countries. But, due to the limited\navailability of data, these models are lacking in low-income countries. Here,\nwe offer the first global river flood prediction framework based on the newly\npublished Caravan dataset. Our framework aims to serve as a benchmark for\nfuture global river flood prediction research. To support generalizability\nclaims we include custom data evaluation splits. Further, we propose and\nevaluate a novel two-path LSTM architecture (2P-LSTM) against three baseline\nmodels. Finally, we evaluate the generated models on different locations in\nAfrica and Asia that were not part of the Caravan dataset."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 1.281893344,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9086309264,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.9725576892,
    "annual_revenue_USD_log": 0.3395304369,
    "rnd_investment_required_log": -0.8459347379,
    "title": "Edge Deep Learning Enabled Freezing of Gait Detection in Parkinson's Patients",
    "abstract": "This paper presents the design of a wireless sensor network for detecting and\nalerting the freezing of gait (FoG) symptoms in patients with Parkinson's\ndisease. Three sensor nodes, each integrating a 3-axis accelerometer, can be\nplaced on a patient at ankle, thigh, and truck. Each sensor node can\nindependently detect FoG using an on-device deep learning (DL) model, featuring\na squeeze and excitation convolutional neural network (CNN). In a validation\nusing a public dataset, the prototype developed achieved a FoG detection\nsensitivity of 88.8% and an F1 score of 85.34%, using less than 20 k trainable\nparameters per sensor node. Once FoG is detected, an auditory signal will be\ngenerated to alert users, and the alarm signal will also be sent to mobile\nphones for further actions if needed. The sensor node can be easily recharged\nwirelessly by inductive coupling. The system is self-contained and processes\nall user data locally without streaming data to external devices or the cloud,\nthus eliminating the cybersecurity risks and power penalty associated with\nwireless data transmission. The developed methodology can be used in a wide\nrange of applications."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.8511525402,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.4193630149,
    "rnd_investment_required_log": 0.0662541385,
    "title": "FuRPE: Learning Full-body Reconstruction from Part Experts",
    "abstract": "In the field of full-body reconstruction, the scarcity of annotated data\noften impedes the efficacy of prevailing methods. To address this issue, we\nintroduce FuRPE, a novel framework that employs part-experts and an ingenious\npseudo ground-truth selection scheme to derive high-quality pseudo labels.\nThese labels, central to our approach, equip our network with the capability to\nefficiently learn from the available data. Integral to FuRPE is a unique\nexponential moving average training strategy and expert-derived feature\ndistillation strategy. These novel elements of FuRPE not only serve to further\nrefine the model but also to reduce potential biases that may arise from\ninaccuracies in pseudo labels, thereby optimizing the network's training\nprocess and enhancing the robustness of the model. We apply FuRPE to train both\ntwo-stage and fully convolutional single-stage full-body reconstruction\nnetworks. Our exhaustive experiments on numerous benchmark datasets illustrate\na substantial performance boost over existing methods, underscoring FuRPE's\npotential to reshape the state-of-the-art in full-body reconstruction."
  },
  {
    "CAGR": -1.3347943804,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.1372752271,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Multi-Class Segmentation from Aerial Views using Recursive Noise Diffusion",
    "abstract": "Semantic segmentation from aerial views is a crucial task for autonomous\ndrones, as they rely on precise and accurate segmentation to navigate safely\nand efficiently. However, aerial images present unique challenges such as\ndiverse viewpoints, extreme scale variations, and high scene complexity. In\nthis paper, we propose an end-to-end multi-class semantic segmentation\ndiffusion model that addresses these challenges. We introduce recursive\ndenoising to allow information to propagate through the denoising process, as\nwell as a hierarchical multi-scale approach that complements the diffusion\nprocess. Our method achieves promising results on the UAVid dataset and\nstate-of-the-art performance on the Vaihingen Building segmentation benchmark.\nBeing the first iteration of this method, it shows great promise for future\nimprovements."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8376639867,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.5152628518,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -1.1058347765,
    "annual_revenue_USD_log": -2.3867657339,
    "rnd_investment_required_log": -1.9396287803,
    "title": "Navigating an Ocean of Video Data: Deep Learning for Humpback Whale Classification in YouTube Videos",
    "abstract": "Image analysis technologies empowered by artificial intelligence (AI) have\nproved images and videos to be an opportune source of data to learn about\nhumpback whale (Megaptera novaeangliae) population sizes and dynamics. With the\nadvent of social media, platforms such as YouTube present an abundance of video\ndata across spatiotemporal contexts documenting humpback whale encounters from\nusers worldwide. In our work, we focus on automating the classification of\nYouTube videos as relevant or irrelevant based on whether they document a true\nhumpback whale encounter or not via deep learning. We use a CNN-RNN\narchitecture pretrained on the ImageNet dataset for classification of YouTube\nvideos as relevant or irrelevant. We achieve an average 85.7% accuracy, and\n84.7% (irrelevant)\/ 86.6% (relevant) F1 scores using five-fold cross validation\nfor evaluation on the dataset. We show that deep learning can be used as a\ntime-efficient step to make social media a viable source of image and video\ndata for biodiversity assessments."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.1725984464,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": 0.3526483917,
    "title": "SimpleMind adds thinking to deep neural networks",
    "abstract": "Deep neural networks (DNNs) detect patterns in data and have shown\nversatility and strong performance in many computer vision applications.\nHowever, DNNs alone are susceptible to obvious mistakes that violate simple,\ncommon sense concepts and are limited in their ability to use explicit\nknowledge to guide their search and decision making. While overall DNN\nperformance metrics may be good, these obvious errors, coupled with a lack of\nexplainability, have prevented widespread adoption for crucial tasks such as\nmedical image analysis. The purpose of this paper is to introduce SimpleMind,\nan open-source software framework for Cognitive AI focused on medical image\nunderstanding. It allows creation of a knowledge base that describes expected\ncharacteristics and relationships between image objects in an intuitive\nhuman-readable form. The SimpleMind framework brings thinking to DNNs by: (1)\nproviding methods for reasoning with the knowledge base about image content,\nsuch as spatial inferencing and conditional reasoning to check DNN outputs; (2)\napplying process knowledge, in the form of general-purpose software agents,\nthat are chained together to accomplish image preprocessing, DNN prediction,\nand result post-processing, and (3) performing automatic co-optimization of all\nknowledge base parameters to adapt agents to specific problems. SimpleMind\nenables reasoning on multiple detected objects to ensure consistency, providing\ncross checking between DNN outputs. This machine reasoning improves the\nreliability and trustworthiness of DNNs through an interpretable model and\nexplainable decisions. Example applications are provided that demonstrate how\nSimpleMind supports and improves deep neural networks by embedding them within\na Cognitive AI framework."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": -1.0804536066,
    "rnd_investment_required_log": 0.0662541385,
    "title": "SoftCorrect: Error Correction with Soft Detection for Automatic Speech Recognition",
    "abstract": "Error correction in automatic speech recognition (ASR) aims to correct those\nincorrect words in sentences generated by ASR models. Since recent ASR models\nusually have low word error rate (WER), to avoid affecting originally correct\ntokens, error correction models should only modify incorrect words, and\ntherefore detecting incorrect words is important for error correction. Previous\nworks on error correction either implicitly detect error words through\ntarget-source attention or CTC (connectionist temporal classification) loss, or\nexplicitly locate specific deletion\/substitution\/insertion errors. However,\nimplicit error detection does not provide clear signal about which tokens are\nincorrect and explicit error detection suffers from low detection accuracy. In\nthis paper, we propose SoftCorrect with a soft error detection mechanism to\navoid the limitations of both explicit and implicit error detection.\nSpecifically, we first detect whether a token is correct or not through a\nprobability produced by a dedicatedly designed language model, and then design\na constrained CTC loss that only duplicates the detected incorrect tokens to\nlet the decoder focus on the correction of error tokens. Compared with implicit\nerror detection with CTC loss, SoftCorrect provides explicit signal about which\nwords are incorrect and thus does not need to duplicate every token but only\nincorrect tokens; compared with explicit error detection, SoftCorrect does not\ndetect specific deletion\/substitution\/insertion errors but just leaves it to\nCTC loss. Experiments on AISHELL-1 and Aidatatang datasets show that\nSoftCorrect achieves 26.1% and 9.4% CER reduction respectively, outperforming\nprevious works by a large margin, while still enjoying fast speed of parallel\ngeneration."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.876511833,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.3604353808,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.027440103,
    "title": "A Multi-Stream Fusion Network for Image Splicing Localization",
    "abstract": "In this paper, we address the problem of image splicing localization with a\nmulti-stream network architecture that processes the raw RGB image in parallel\nwith other handcrafted forensic signals. Unlike previous methods that either\nuse only the RGB images or stack several signals in a channel-wise manner, we\npropose an encoder-decoder architecture that consists of multiple encoder\nstreams. Each stream is fed with either the tampered image or handcrafted\nsignals and processes them separately to capture relevant information from each\none independently. Finally, the extracted features from the multiple streams\nare fused in the bottleneck of the architecture and propagated to the decoder\nnetwork that generates the output localization map. We experiment with two\nhandcrafted algorithms, i.e., DCT and Splicebuster. Our proposed approach is\nbenchmarked on three public forensics datasets, demonstrating competitive\nperformance against several competing methods and achieving state-of-the-art\nresults, e.g., 0.898 AUC on CASIA."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 1.9391692981,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Flip Graphs for Matrix Multiplication",
    "abstract": "We introduce a new method for discovering matrix multiplication schemes based\non random walks in a certain graph, which we call the flip graph. Using this\nmethod, we were able to reduce the number of multiplications for the matrix\nformats (4, 4, 5) and (5, 5, 5), both in characteristic two and for arbitrary\nground fields."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.018090997,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Thermal diode assisted by geometry under cycling temperature",
    "abstract": "Technological progress in electronics usually requires their use in\nincreasingly aggressive environments, such as rapid thermal cycling and high\npower density. Thermal diodes appear as excellent candidates to thermally\nprotect critical electronic components and ensure durability and reliability.\nWe model the heat transport across a square plate with a hole subjected to an\noscillating external temperature, such spatial and temporal symmetries are\nbroken. We find rectification of the heat current that strongly depends on the\nfrequency and the geometry of the hole. This system behaves as a thermal diode\nthat could be used as part of a thermal architecture to dissipate heat under\ncycling temperature conditions."
  },
  {
    "CAGR": -0.5476895383,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": -1.5129768028,
    "rnd_investment_required_log": -1.535978894,
    "title": "Diver Interest via Pointing: Human-Directed Object Inspection for AUVs",
    "abstract": "In this paper, we present the Diver Interest via Pointing (DIP) algorithm, a\nhighly modular method for conveying a diver's area of interest to an autonomous\nunderwater vehicle (AUV) using pointing gestures for underwater human-robot\ncollaborative tasks. DIP uses a single monocular camera and exploits human body\npose, even with complete dive gear, to extract underwater human pointing\ngesture poses and their directions. By extracting 2D scene geometry based on\nthe human body pose and density of salient feature points along the direction\nof pointing, using a low-level feature detector, the DIP algorithm is able to\nlocate objects of interest as indicated by the diver."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 0.6432509228,
    "rnd_investment_required_log": -0.3373958805,
    "title": "ViTAL: Vision-Based Terrain-Aware Locomotion for Legged Robots",
    "abstract": "This work is on vision-based planning strategies for legged robots that\nseparate locomotion planning into foothold selection and pose adaptation.\nCurrent pose adaptation strategies optimize the robot's body pose relative to\ngiven footholds. If these footholds are not reached, the robot may end up in a\nstate with no reachable safe footholds. Therefore, we present a Vision-Based\nTerrain-Aware Locomotion (ViTAL) strategy that consists of novel pose\nadaptation and foothold selection algorithms. ViTAL introduces a different\nparadigm in pose adaptation that does not optimize the body pose relative to\ngiven footholds, but the body pose that maximizes the chances of the legs in\nreaching safe footholds. ViTAL plans footholds and poses based on skills that\ncharacterize the robot's capabilities and its terrain-awareness. We use the 90\nkg HyQ and 140 kg HyQReal quadruped robots to validate ViTAL, and show that\nthey are able to climb various obstacles including stairs, gaps, and rough\nterrains at different speeds and gaits. We compare ViTAL with a baseline\nstrategy that selects the robot pose based on given selected footholds, and\nshow that ViTAL outperforms the baseline."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.2539029658,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Approximate Quantum Circuit Cutting",
    "abstract": "Current and imminent quantum hardware lacks reliability and applicability due\nto noise and limited qubit counts. Quantum circuit cutting -- a technique\ndividing large quantum circuits into smaller subcircuits with sizes appropriate\nfor the limited quantum resource at hand -- is used to mitigate these problems.\nHowever, classical postprocessing involved in circuit cutting generally grows\nexponentially with the number of cuts and quantum counts. This article\nintroduces the notion of approximate circuit reconstruction. Using a\nsampling-based method like Markov Chain Monte Carlo (MCMC), we\nprobabilistically select bit strings of high probability upon reconstruction.\nThis avoids excessive calculations when reconstructing the full probability\ndistribution. Our results show that such a sampling-based postprocessing method\nholds great potential for fast and reliable circuit reconstruction in the NISQ\nera and beyond."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -1.0312392903,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Brain PET-MR attenuation correction with deep learning: method validation in adult and clinical paediatric data",
    "abstract": "Current methods for magnetic resonance-based positron emission tomography\nattenuation correction (PET-MR AC) are time consuming, and less able than\ncomputed tomography (CT)-based AC methods to capture inter-individual\nvariability and skull abnormalities. Deep learning methods have been proposed\nto produce pseudo-CT from MR images, but these methods have not yet been\nevaluated in large clinical cohorts. Methods trained on healthy adult data may\nnot work in clinical cohorts where skull morphometry may be abnormal, or in\npaediatric data where skulls tend to be thinner and smaller. Here, we train a\nconvolutional neural network based on the U-Net to produce pseudo-CT for PET-MR\nAC. We trained our network on a mixed cohort of healthy adults and patients\nundergoing clinical PET scans for neurology investigations. We show that our\nmethod was able to produce pseudo-CT with mean absolute errors (MAE) of 100.4\n$\\pm$ 21.3 HU compared to reference CT, with a Jaccard overlap coefficient of\n0.73 $\\pm$ 0.07 in the skull masks. Linear attenuation maps based on our\npseudo-CT (relative MAE = 8.4 $\\pm$ 2.1\\%) were more accurate than those based\non a well-performing multi-atlas-based AC method (relative MAE = 13.1 $\\pm$\n1.5\\%) when compared with CT-based linear attenuation maps. We refined the\ntrained network in a clinical paediatric cohort. MAE improved from 174.7 $\\pm$\n33.6 HU when using the existing network to 127.3 $\\pm$ 39.9 HU after transfer\nlearning in the paediatric dataset, thus showing that transfer learning can\nimprove pseudo-CT accuracy in paediatric data."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.0192437628,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.2605876197,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Subword-Delimited Downsampling for Better Character-Level Translation",
    "abstract": "Subword-level models have been the dominant paradigm in NLP. However,\ncharacter-level models have the benefit of seeing each character individually,\nproviding the model with more detailed information that ultimately could lead\nto better models. Recent works have shown character-level models to be\ncompetitive with subword models, but costly in terms of time and computation.\nCharacter-level models with a downsampling component alleviate this, but at the\ncost of quality, particularly for machine translation. This work analyzes the\nproblems of previous downsampling methods and introduces a novel downsampling\nmethod which is informed by subwords. This new downsampling method not only\noutperforms existing downsampling methods, showing that downsampling characters\ncan be done without sacrificing quality, but also leads to promising\nperformance compared to subword models for translation."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -1.4664321295,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.3373958805,
    "title": "4D topological textures in light",
    "abstract": "We present 4D topological textures in (quasi)monochromatic nonparaxial\noptical lattices that contain all possible polarization ellipses with every\ncombination of ellipticity and orientation in 3D space. These fields span the\nnonparaxial polarization space (a complex projective plane) and a 4-sphere\nwithin specific spatiotemporal regions, forming 4D skyrmionic structures.\nConstructed from five plane waves with adiabatically varying relative\namplitudes, they are experimentally realizable in free space by focusing a\ntemporally variant beam with a high numerical aperture lens."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Fast Non-Rigid Radiance Fields from Monocularized Data",
    "abstract": "The reconstruction and novel view synthesis of dynamic scenes recently gained\nincreased attention. As reconstruction from large-scale multi-view data\ninvolves immense memory and computational requirements, recent benchmark\ndatasets provide collections of single monocular views per timestamp sampled\nfrom multiple (virtual) cameras. We refer to this form of inputs as\n\"monocularized\" data. Existing work shows impressive results for synthetic\nsetups and forward-facing real-world data, but is often limited in the training\nspeed and angular range for generating novel views. This paper addresses these\nlimitations and proposes a new method for full 360{\\deg} inward-facing novel\nview synthesis of non-rigidly deforming scenes. At the core of our method are:\n1) An efficient deformation module that decouples the processing of spatial and\ntemporal information for accelerated training and inference; and 2) A static\nmodule representing the canonical scene as a fast hash-encoded neural radiance\nfield. In addition to existing synthetic monocularized data, we systematically\nanalyze the performance on real-world inward-facing scenes using a newly\nrecorded challenging dataset sampled from a synchronized large-scale multi-view\nrig. In both cases, our method is significantly faster than previous methods,\nconverging in less than 7 minutes and achieving real-time framerates at 1K\nresolution, while obtaining a higher visual accuracy for generated novel views.\nOur source code and data is available at our project page\nhttps:\/\/graphics.tu-bs.de\/publications\/kappel2022fast."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.8572985792,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -2.1424131503,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Optical Refrigeration for an Optomechanical Amplifier",
    "abstract": "We explore the viability of using optical refrigeration as a low-vibration\ncooling method for a phase-sensitive optomechanical amplifier proposed to\nimprove the sensitivity of future gravitational wave detectors. We find that\nwith moderate improvements on coolants currently available, optical\nrefrigeration can improve the amplifier gain by a factor of 10 relative to what\nis possible with radiative cooling. We also show that the technique does not\nadd significant noise to the amplifier. These results indicate that optical\nrefrigeration can play an important role in cooling optomechanical devices."
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -1.6319355937,
    "rnd_investment_required_log": -0.0024298831,
    "title": "Drones-aided Asset Maintenance in Hospitals",
    "abstract": "The rapid outbreak of COVID-19 pandemic invoked scientists and researchers to\nprepare the world for future disasters. During the pandemic, global authorities\non healthcare urged the importance of disinfection of objects and surfaces. To\nimplement efficient and safe disinfection services during the pandemic, robots\nhave been utilized for indoor assets. In this paper, we envision the use of\ndrones for disinfection of outdoor assets in hospitals and other facilities.\nSuch heterogeneous assets may have different service demands (e.g., service\ntime, quantity of the disinfectant material etc.), whereas drones have\ntypically limited capacity (i.e., travel time, disinfectant carrying capacity).\nTo serve all the facility assets in an efficient manner, the drone to assets\nallocation and drone travel routes must be optimized. In this paper, we\nformulate the capacitated vehicle routing problem (CVRP) to find optimal route\nfor each drone such that the total service time is minimized, while\nsimultaneously the drones meet the demands of each asset allocated to it. The\nproblem is solved using mixed integer programming (MIP). As CVRP is an NP-hard\nproblem, we propose a lightweight heuristic to achieve sub-optimal performance\nwhile reducing the time complexity in solving the problem involving a large\nnumber of assets."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.847481283,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -1.027440103,
    "title": "Objective Assessment of Spatial Audio Quality using Directional Loudness Maps",
    "abstract": "This work introduces a feature extracted from stereophonic\/binaural audio\nsignals aiming to represent a measure of perceived quality degradation in\nprocessed spatial auditory scenes. The feature extraction technique is based on\na simplified stereo signal model considering auditory events positioned towards\na given direction in the stereo field using amplitude panning (AP) techniques.\nWe decompose the stereo signal into a set of directional signals for given AP\nvalues in the Short-Time Fourier Transform domain and calculate their overall\nloudness to form a directional loudness representation or maps. Then, we\ncompare directional loudness maps of a reference signal and a deteriorated\nversion to derive a distortion measure aiming to describe the associated\nperceived degradation scores reported in listening tests. The measure is then\ntested on an extensive listening test database with stereo signals processed by\nstate-of-the-art perceptual audio codecs using non waveform-preserving\ntechniques such as bandwidth extension and joint stereo coding, known for\npresenting a challenge to existing quality predictors. Results suggest that the\nderived distortion measure can be incorporated as an extension to existing\nautomated perceptual quality assessment algorithms for improving prediction on\nspatially coded audio signals."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.847481283,
    "ROI_percent": 3.4504551886,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -1.5504097469,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -1.027440103,
    "title": "CLIP: Train Faster with Less Data",
    "abstract": "Deep learning models require an enormous amount of data for training.\nHowever, recently there is a shift in machine learning from model-centric to\ndata-centric approaches. In data-centric approaches, the focus is to refine and\nimprove the quality of the data to improve the learning performance of the\nmodels rather than redesigning model architectures. In this paper, we propose\nCLIP i.e., Curriculum Learning with Iterative data Pruning. CLIP combines two\ndata-centric approaches i.e., curriculum learning and dataset pruning to\nimprove the model learning accuracy and convergence speed. The proposed scheme\napplies loss-aware dataset pruning to iteratively remove the least significant\nsamples and progressively reduces the size of the effective dataset in the\ncurriculum learning training. Extensive experiments performed on crowd density\nestimation models validate the notion behind combining the two approaches by\nreducing the convergence time and improving generalization. To our knowledge,\nthe idea of data pruning as an embedded process in curriculum learning is\nnovel."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.7885775055,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Microstructure Evolution of Solid Oxide Fuel Cell Anodes Characterized by Persistent Homology",
    "abstract": "Uncovering microstructure evolution mechanisms that accompany the long-term\noperation of solid oxide fuel cells is a fundamental challenge in designing a\nmore durable energy system for the future. To date, the study of fuel cell\nstack degradation has focused mainly on electrochemical performance and, more\nrarely, on averaged microstructural parameters. Here we show an alternative\napproach in which an evolution of three-dimensional microstructural features is\nstudied using electron tomography coupled with topological data analysis. The\nlatter produces persistent images of microstructure before and after long-term\noperation of electrodes. Those images unveil a new insight into the degradation\nprocess of three involved phases: nickel, pores, and yttrium-stabilized\nzirconium."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Secrecy-Verifiability Paradox in Smart Contracts",
    "abstract": "The trade-off of secrecy is the difficulty of verification. This trade-off\nmeans that contracts must be kept private, yet their compliance needs to be\nverified, which we call the secrecy-verifiability paradox. However, the\nexisting smart contracts are not designed to provide secrecy in this context\nwithout sacrificing verifiability. Without a trusted third party for\nnotarization, the protocol for the verification of smart contracts has to be\nbuilt on cryptographic primitives. We propose a blockchain-based solution that\novercomes this challenge by storing the verifiable evidence as accessible data\non a blockchain in an appropriate manner. This solution allows for\ncryptographic data verification but not revealing the data itself. In addition,\nwith our proposal, it is possible to verify contracts whose form of existence\nhas been destroyed as long as the contract is real and the people involved\nremember it."
  },
  {
    "CAGR": -1.4452652355,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -2.9778732615,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.6546111698,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Unsupervised Fine-Tuning Data Selection for ASR Using Self-Supervised Speech Models",
    "abstract": "Self-supervised learning (SSL) has been able to leverage unlabeled data to\nboost the performance of automatic speech recognition (ASR) models when we have\naccess to only a small amount of transcribed speech data. However, this raises\nthe question of which subset of the available unlabeled data should be selected\nfor transcription. Our work investigates different unsupervised data selection\ntechniques for fine-tuning the HuBERT model under a limited transcription\nbudget. We investigate the impact of speaker diversity, gender bias, and topic\ndiversity on the downstream ASR performance. We also devise two novel\ntechniques for unsupervised data selection: pre-training loss based data\nselection and the perplexity of byte pair encoded clustered units (PBPE) and we\nshow how these techniques compare to pure random data selection. Finally, we\nanalyze the correlations between the inherent characteristics of the selected\nfine-tuning subsets as well as how these characteristics correlate with the\nresultant word error rate. We demonstrate the importance of token diversity,\nspeaker diversity, and topic diversity in achieving the best performance in\nterms of WER."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Recognition and Prediction of Surgical Gestures and Trajectories Using Transformer Models in Robot-Assisted Surgery",
    "abstract": "Surgical activity recognition and prediction can help provide important\ncontext in many Robot-Assisted Surgery (RAS) applications, for example,\nsurgical progress monitoring and estimation, surgical skill evaluation, and\nshared control strategies during teleoperation. Transformer models were first\ndeveloped for Natural Language Processing (NLP) to model word sequences and\nsoon the method gained popularity for general sequence modeling tasks. In this\npaper, we propose the novel use of a Transformer model for three tasks: gesture\nrecognition, gesture prediction, and trajectory prediction during RAS. We\nmodify the original Transformer architecture to be able to generate the current\ngesture sequence, future gesture sequence, and future trajectory sequence\nestimations using only the current kinematic data of the surgical robot\nend-effectors. We evaluate our proposed models on the JHU-ISI Gesture and Skill\nAssessment Working Set (JIGSAWS) and use Leave-One-User-Out (LOUO)\ncross-validation to ensure the generalizability of our results. Our models\nachieve up to 89.3\\% gesture recognition accuracy, 84.6\\% gesture prediction\naccuracy (1 second ahead) and 2.71mm trajectory prediction error (1 second\nahead). Our models are comparable to and able to outperform state-of-the-art\nmethods while using only the kinematic data channel. This approach can enable\nnear-real time surgical activity recognition and prediction."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.2698978165,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "3D Object Aided Self-Supervised Monocular Depth Estimation",
    "abstract": "Monocular depth estimation has been actively studied in fields such as robot\nvision, autonomous driving, and 3D scene understanding. Given a sequence of\ncolor images, unsupervised learning methods based on the framework of\nStructure-From-Motion (SfM) simultaneously predict depth and camera relative\npose. However, dynamically moving objects in the scene violate the static world\nassumption, resulting in inaccurate depths of dynamic objects. In this work, we\npropose a new method to address such dynamic object movements through monocular\n3D object detection. Specifically, we first detect 3D objects in the images and\nbuild the per-pixel correspondence of the dynamic pixels with the detected\nobject pose while leaving the static pixels corresponding to the rigid\nbackground to be modeled with camera motion. In this way, the depth of every\npixel can be learned via a meaningful geometry model. Besides, objects are\ndetected as cuboids with absolute scale, which is used to eliminate the scale\nambiguity problem inherent in monocular vision. Experiments on the KITTI depth\ndataset show that our method achieves State-of-The-Art performance for depth\nestimation. Furthermore, joint training of depth, camera motion and object pose\nalso improves monocular 3D object detection performance. To the best of our\nknowledge, this is the first work that allows a monocular 3D object detection\nnetwork to be fine-tuned in a self-supervised manner."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.5175734475,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.8551118345,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -1.4717292989,
    "title": "MiLMo:Minority Multilingual Pre-trained Language Model",
    "abstract": "Pre-trained language models are trained on large-scale unsupervised data, and\nthey can fine-turn the model only on small-scale labeled datasets, and achieve\ngood results. Multilingual pre-trained language models can be trained on\nmultiple languages, and the model can understand multiple languages at the same\ntime. At present, the search on pre-trained models mainly focuses on rich\nresources, while there is relatively little research on low-resource languages\nsuch as minority languages, and the public multilingual pre-trained language\nmodel can not work well for minority languages. Therefore, this paper\nconstructs a multilingual pre-trained model named MiLMo that performs better on\nminority language tasks, including Mongolian, Tibetan, Uyghur, Kazakh and\nKorean. To solve the problem of scarcity of datasets on minority languages and\nverify the effectiveness of the MiLMo model, this paper constructs a minority\nmultilingual text classification dataset named MiTC, and trains a word2vec\nmodel for each language. By comparing the word2vec model and the pre-trained\nmodel in the text classification task, this paper provides an optimal scheme\nfor the downstream task research of minority languages. The final experimental\nresults show that the performance of the pre-trained model is better than that\nof the word2vec model, and it has achieved the best results in minority\nmultilingual text classification. The multilingual pre-trained model MiLMo,\nmultilingual word2vec model and multilingual text classification dataset MiTC\nare published on http:\/\/milmo.cmli-nlp.com\/."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 2.0047472922,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 1.247070394,
    "annual_revenue_USD_log": 0.9708450549,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Axial-LOB: High-Frequency Trading with Axial Attention",
    "abstract": "Previous attempts to predict stock price from limit order book (LOB) data are\nmostly based on deep convolutional neural networks. Although convolutions offer\nefficiency by restricting their operations to local interactions, it is at the\ncost of potentially missing out on the detection of long-range dependencies.\nRecent studies address this problem by employing additional recurrent or\nattention layers that increase computational complexity. In this work, we\npropose Axial-LOB, a novel fully-attentional deep learning architecture for\npredicting price movements of stocks from LOB data. By utilizing gated\nposition-sensitive axial attention layers our architecture is able to construct\nfeature maps that incorporate global interactions, while significantly reducing\nthe size of the parameter space. Unlike previous works, Axial-LOB does not rely\non hand-crafted convolutional kernels and hence has stable performance under\ninput permutations and the capacity to incorporate additional LOB features. The\neffectiveness of Axial-LOB is demonstrated on a large benchmark dataset,\ncontaining time series representations of millions of high-frequency trading\nevents, where our model establishes a new state of the art, achieving an\nexcellent directional classification performance at all tested prediction\nhorizons."
  },
  {
    "CAGR": 1.3165061404,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 3.0890282145,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.5710893717,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Approximate Boltzmann Distributions in Quantum Approximate Optimization",
    "abstract": "Approaches to compute or estimate the output probability distributions from\nthe quantum approximate optimization algorithm (QAOA) are needed to assess the\nlikelihood it will obtain a quantum computational advantage. We analyze output\nfrom QAOA circuits solving 7,200 random MaxCut instances, with $n=14-23$ qubits\nand depth parameter $p \\leq 12$, and find that the average basis state\nprobabilities follow approximate Boltzmann distributions: The average\nprobabilities scale exponentially with their energy (cut value), with a peak at\nthe optimal solution. We describe the rate of exponential scaling or \"effective\ntemperature\" in terms of a series with a leading order term $T \\sim\nC_\\mathrm{min}\/n\\sqrt{p}$, with $C_\\mathrm{min}$ the optimal solution energy.\nUsing this scaling we generate approximate output distributions with up to 38\nqubits and find these give accurate accounts of important performance metrics\nin cases we can simulate exactly."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Melody transcription via generative pre-training",
    "abstract": "Despite the central role that melody plays in music perception, it remains an\nopen challenge in music information retrieval to reliably detect the notes of\nthe melody present in an arbitrary music recording. A key challenge in melody\ntranscription is building methods which can handle broad audio containing any\nnumber of instrument ensembles and musical styles - existing strategies work\nwell for some melody instruments or styles but not all. To confront this\nchallenge, we leverage representations from Jukebox (Dhariwal et al. 2020), a\ngenerative model of broad music audio, thereby improving performance on melody\ntranscription by $20$% relative to conventional spectrogram features. Another\nobstacle in melody transcription is a lack of training data - we derive a new\ndataset containing $50$ hours of melody transcriptions from crowdsourced\nannotations of broad music. The combination of generative pre-training and a\nnew dataset for this task results in $77$% stronger performance on melody\ntranscription relative to the strongest available baseline. By pairing our new\nmelody transcription approach with solutions for beat detection, key\nestimation, and chord recognition, we build Sheet Sage, a system capable of\ntranscribing human-readable lead sheets directly from music audio.\n  Audio examples can be found at https:\/\/chrisdonahue.com\/sheetsage and code at\nhttps:\/\/github.com\/chrisdonahue\/sheetsage ."
  },
  {
    "CAGR": -1.4452652355,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -2.1304791372,
    "rnd_investment_required_log": -1.2495847072,
    "title": "Speech MOS multi-task learning and rater bias correction",
    "abstract": "Perceptual speech quality is an important performance metric for\nteleconferencing applications. The mean opinion score (MOS) is standardized for\nthe perceptual evaluation of speech quality and is obtained by asking listeners\nto rate the quality of a speech sample. Recently, there has been increasing\nresearch interest in developing models for estimating MOS blindly. Here we\npropose a multi-task framework to include additional labels and data in\ntraining to improve the performance of a blind MOS estimation model.\nExperimental results indicate that the proposed model can be trained to jointly\nestimate MOS, reverberation time (T60), and clarity (C50) by combining two\ndisjoint data sets in training, one containing only MOS labels and the other\ncontaining only T60 and C50 labels. Furthermore, we use a semi-supervised\nframework to combine two MOS data sets in training, one containing only MOS\nlabels (per ITU-T Recommendation P.808), and the other containing separate\nscores for speech signal, background noise, and overall quality (per ITU-T\nRecommendation P.835). Finally, we present preliminary results for addressing\nindividual rater bias in the MOS labels."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.742097711,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Query-Driven Knowledge Base Completion using Multimodal Path Fusion over Multimodal Knowledge Graph",
    "abstract": "Over the past few years, large knowledge bases have been constructed to store\nmassive amounts of knowledge. However, these knowledge bases are highly\nincomplete, for example, over 70% of people in Freebase have no known place of\nbirth. To solve this problem, we propose a query-driven knowledge base\ncompletion system with multimodal fusion of unstructured and structured\ninformation. To effectively fuse unstructured information from the Web and\nstructured information in knowledge bases to achieve good performance, our\nsystem builds multimodal knowledge graphs based on question answering and rule\ninference. We propose a multimodal path fusion algorithm to rank candidate\nanswers based on different paths in the multimodal knowledge graphs, achieving\nmuch better performance than question answering, rule inference and a baseline\nfusion algorithm. To improve system efficiency, query-driven techniques are\nutilized to reduce the runtime of our system, providing fast responses to user\nqueries. Extensive experiments have been conducted to demonstrate the\neffectiveness and efficiency of our system."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.9391692981,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Deep reinforcement learning of event-triggered communication and consensus-based control for distributed cooperative transport",
    "abstract": "In this paper, we present a solution to a design problem of control\nstrategies for multi-agent cooperative transport. Although existing\nlearning-based methods assume that the number of agents is the same as that in\nthe training environment, the number might differ in reality considering that\nthe robots' batteries may completely discharge, or additional robots may be\nintroduced to reduce the time required to complete a task. Therefore, it is\ncrucial that the learned strategy be applicable to scenarios wherein the number\nof agents differs from that in the training environment. In this paper, we\npropose a novel multi-agent reinforcement learning framework of event-triggered\ncommunication and consensus-based control for distributed cooperative\ntransport. The proposed policy model estimates the resultant force and torque\nin a consensus manner using the estimates of the resultant force and torque\nwith the neighborhood agents. Moreover, it computes the control and\ncommunication inputs to determine when to communicate with the neighboring\nagents under local observations and estimates of the resultant force and\ntorque. Therefore, the proposed framework can balance the control performance\nand communication savings in scenarios wherein the number of agents differs\nfrom that in the training environment. We confirm the effectiveness of our\napproach by using a maximum of eight and six robots in the simulations and\nexperiments, respectively."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Field-Effect Josephson Diode via Asymmetric Spin-Momentum-Locking States",
    "abstract": "Recent breakthroughs in Josephson diodes dangle the possibility of extending\nconventional non-reciprocal electronics into the realm of superconductivity.\nWhile a strong magnetic field is recognized for enhancing diode efficiency, it\nconcurrently poses a risk of undermining the essential superconductivity\nrequired for non-dissipative devices. To circumvent the need for magnetic-based\ntuning, we propose a field-effect Josephson diode based on the electrostatic\ngate control of finite momentum Cooper pairs in asymmetric\nspin-momentum-locking states. We propose two possible implementations of our\ngate-controlled mechanism: (i) a topological field-effect Josephson diode in\ntime-reversal-broken quantum spin Hall insulators; and (ii) semiconductor-based\nfield-effect Josephson diodes attainable in current experimental setups\ninvolving a Zeeman field and spin-orbit coupling. Notably, the diode efficiency\nis highly enhanced in the topological field-effect Josephson diode because the\ncurrent carried by the asymmetric helical edge states is topologically\nprotected and can be tuned by local gates. In the proposed Josephson diode, the\ncombination of gates and asymmetric spin-momentum-locking nature is equivalent\nto that of a magnetic field, thus providing an alternative electrical operation\nin designing nonreciprocal superconducting devices."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.745381402,
    "ROI_percent": -1.2480954748,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Double U-Net for Super-Resolution and Segmentation of Live Cell Images",
    "abstract": "Accurate segmentation of live cell images has broad applications in clinical\nand research contexts. Deep learning methods have been able to perform cell\nsegmentations with high accuracy; however developing machine learning models to\ndo this requires access to high fidelity images of live cells. This is often\nnot available due to resource constraints like limited accessibility to high\nperformance microscopes or due to the nature of the studied organisms.\nSegmentation on low resolution images of live cells is a difficult task. This\npaper proposes a method to perform live cell segmentation with low resolution\nimages by performing super-resolution as a pre-processing step in the\nsegmentation pipeline."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.1799051383,
    "ROI_percent": -1.8986640282,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.5173724297,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 1.7327369984,
    "title": "Propagating spin-wave spectroscopy in nanometer-thick YIG films at millikelvin temperatures",
    "abstract": "Performing propagating spin-wave spectroscopy of thin films at millikelvin\ntemperatures is the next step towards the realisation of large-scale integrated\nmagnonic circuits for quantum applications. Here we demonstrate spin-wave\npropagation in a $100\\,\\mathrm{nm}$-thick yttrium-iron-garnet film at the\ntemperatures down to $45 \\,\\mathrm{mK}$, using stripline nanoantennas deposited\non YIG surface for the electrical excitation and detection. The clear\ntransmission characteristics over the distance of $10\\,\\mu \\mathrm{m}$ are\nmeasured and the subtracted spin-wave group velocity and the YIG saturation\nmagnetisation agree well with the theoretical values. We show that the\ngadolinium-gallium-garnet substrate influences the spin-wave propagation\ncharacteristics only for the applied magnetic fields beyond $75\\,\\mathrm{mT}$,\noriginating from a GGG magnetisation up to $47 \\,\\mathrm{kA\/m}$ at $45\n\\,\\mathrm{mK}$. Our results show that the developed fabrication and measurement\nmethodologies enable the realisation of integrated magnonic quantum\nnanotechnologies at millikelvin temperatures."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -1.3926662644,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Emotion in Cognitive Architecture: Emergent Properties from Interactions with Human Emotion",
    "abstract": "This document presents endeavors to represent emotion in a computational\ncognitive architecture. The first part introduces research organizing with two\naxes of emotional affect: pleasantness and arousal. Following this basic of\nemotional components, the document discusses an aspect of emergent properties\nof emotion, showing interaction studies with human users. With these past\nauthor's studies, the document concludes that the advantage of the cognitive\nhuman-agent interaction approach is in representing human internal states and\nprocesses."
  },
  {
    "CAGR": -0.7548223915,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": -0.742097711,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.5245551397,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Parameter-free analytic continuation for quantum many-body calculations",
    "abstract": "We develop a reliable parameter-free analytic continuation method for quantum\nmany-body calculations. Our method is based on a kernel grid, a causal spline,\na regularization using the second-derivative roughness penalty, and the L-curve\ncriterion. We also develop the L-curve averaged deviation to estimate the\nprecision of our analytic continuation. To deal with statistically obtained\ndata more efficiently, we further develop a bootstrap-averaged analytic\ncontinuation method. In the test using the exact imaginary-frequency Green's\nfunction with added statistical error, our method produces the spectral\nfunction that converges systematically to the exact one as the statistical\nerror decreases. As an application, we simulate the two-orbital Hubbard model\nfor various electron numbers with the dynamical-mean field theory in the\nimaginary time and obtain the real-frequency self-energy with our analytic\ncontinuation method, clearly identifying a non-Fermi liquid behavior as the\nelectron number approaches the half filling from the quarter filling. Our\nanalytic continuation can be used widely and it will facilitate drawing clear\nconclusions from imaginary-time quantum many-body calculations."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": -2.3867657339,
    "rnd_investment_required_log": -1.535978894,
    "title": "An implementation of the density functional perturbation theory in the PAW framework",
    "abstract": "Quantifying materials' dynamical responses to external electromagnetic fields\nis central to understanding their physical properties. Here we present an\nimplementation of the density functional perturbation theory for the\ncomputation of linear susceptibilities using the projector augmented-wave\nmethod. The Sternheimer equations are solved self-consistently through a nested\niterative procedure to compute the first-order wavefunctions, from which the\nlinear susceptibilities are obtained. As a demonstration, we compute the spin\nwave spectral functions of two magnetic metals. The computed magnon spectra for\nhalf-metallic CrO$_2$ and a Heusler intermetallic Cu$_2$MnAl show gapless\nGoldstone modes when spin rotation symmetry is preserved and display reasonable\nagreement with available experimental data. The Landau damping is computed to\nbe small in CrO$_2$, but significant in Cu$_2$MnAl producing an asymmetric\nLorentzian spectral lineshape. The access to linear susceptibilities as well as\nfirst-order wavefunctions offers a range of novel possibilities in quantitative\nunderstanding of materials' electronic properties from \\textit{ab initio}\nmethods."
  },
  {
    "CAGR": -0.4510275401,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8523899311,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": -1.027440103,
    "title": "Towards Proactively Forecasting Sentence-Specific Information Popularity within Online News Documents",
    "abstract": "Multiple studies have focused on predicting the prospective popularity of an\nonline document as a whole, without paying attention to the contributions of\nits individual parts. We introduce the task of proactively forecasting\npopularities of sentences within online news documents solely utilizing their\nnatural language content. We model sentence-specific popularity forecasting as\na sequence regression task. For training our models, we curate InfoPop, the\nfirst dataset containing popularity labels for over 1.7 million sentences from\nover 50,000 online news documents. To the best of our knowledge, this is the\nfirst dataset automatically created using streams of incoming search engine\nqueries to generate sentence-level popularity annotations. We propose a novel\ntransfer learning approach involving sentence salience prediction as an\nauxiliary task. Our proposed technique coupled with a BERT-based neural model\nexceeds nDCG values of 0.8 for proactive sentence-specific popularity\nforecasting. Notably, our study presents a non-trivial takeaway: though\npopularity and salience are different concepts, transfer learning from salience\nprediction enhances popularity forecasting. We release InfoPop and make our\ncode publicly available: https:\/\/github.com\/sayarghoshroy\/InfoPopularity"
  },
  {
    "CAGR": -1.4452652355,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.7100391355,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Nuclear Magnetic Resonance Measurements in High Flat-top Pulsed Magnetic Field up to 40 T at WHMFC",
    "abstract": "Nuclear magnetic resonance (NMR) technique benefits from high magnetic field\nnot only due to the field-enhanced measurement sensitivity and resolution, but\nalso because it is a powerful tool to investigate field-induced physics in\nmodern material science. In this study, we successfully performed NMR\nmeasurements in high flat-top pulsed magnetic field (FTPMF) up to 40 T. A\ntwo-stage corrected FTPMF with fluctuation less than 10 mT and duration longer\nthan 9 ms was established. Besides, a Giga-Hz NMR spectrometer and a sample\nprobe suitable for pulsed-field condition were developed. Both\nfree-induction-decay and spin-echo sequences were exploited for the\nmeasurements. The derived $^{93}$Nb NMR results show that the stability and\nhomogeneity of the FTPMF reach an order of 10$^2$ ppm \/ 10 ms and 10$^2$ ppm \/\n10 mm$^3$ respectively, which is approaching a degree of maturity for some\nresearches on condensed matter physics."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.2977126932,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Spin Hall Induced Magnetization Dynamics in Multiferroic Tunnel Junction",
    "abstract": "The combination of spin-orbit coupling driven effects and multiferroic\ntunneling properties was explored experimentally in thin Pt\/Co\/BTO\/LSMO\nmultilayers. The presence of a Pt heavy metal allows for the spin\ncurrent-induced magnetization precession of Co upon radio-frequency charge\ncurrent injection. The utilization of a BTO ferroelectric tunnel barrier\nseparating the Co and LSMO ferromagnetic electrodes gives rise to both\ntunneling-magnetoresistance and electroresistance. Using the spin-orbit torque\nferromagnetic resonance, the maganetization dynamics of the Co\/Pt bilayers was\nstudied at room temperature. Unexpectedly the magnetization dynamics study in\nthe same geometry performed at low temperature reveals the existence of both Co\nand LSMO resonance peaks indicating efficient spin current generation both\nusing the spin Hall effect in Pt and spin pumping in LSMO that tunnel via the\nBTO barrier."
  },
  {
    "CAGR": -0.9619552447,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.5465747839,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": -1.7692634366,
    "rnd_investment_required_log": -1.9396287803,
    "title": "FEVA: Fast Event Video Annotation Tool",
    "abstract": "Video Annotation is a crucial process in computer science and social science\nalike. Many video annotation tools (VATs) offer a wide range of features for\nmaking annotation possible. We conducted an extensive survey of over 59 VATs\nand interviewed interdisciplinary researchers to evaluate the usability of\nVATs. Our findings suggest that most current VATs have overwhelming user\ninterfaces, poor interaction techniques, and difficult-to-understand features.\nThese often lead to longer annotation time, label inconsistencies, and user\nfatigue. We introduce FEVA, a video annotation tool with streamlined\ninteraction techniques and a dynamic interface that makes labeling tasks easy\nand fast. FEVA focuses on speed, accuracy, and simplicity to make annotation\nquick, consistent, and straightforward. For example, annotators can control the\nspeed and direction of the video and mark the onset and the offset of a label\nin real time with single key presses. In our user study, FEVA users, on\naverage, require 36% less interaction than the most popular annotation tools\n(Advene, ANVIL, ELAN, VIA, and VIAN). The participants (N=32) rated FEVA as\nmore intuitive and required less mental demand. The code and demo are available\nat http:\/\/www.snehesh.com\/feva."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.535978894,
    "title": "Lightweight Image Inpainting by Stripe Window Transformer with Joint Attention to CNN",
    "abstract": "Image inpainting is an important task in computer vision. As admirable\nmethods are presented, the inpainted image is getting closer to reality.\nHowever, the result is still not good enough in the reconstructed texture and\nstructure based on human vision. Although recent advances in computer hardware\nhave enabled the development of larger and more complex models, there is still\na need for lightweight models that can be used by individuals and small-sized\ninstitutions. Therefore, we propose a lightweight model that combines a\nspecialized transformer with a traditional convolutional neural network (CNN).\nFurthermore, we have noticed most researchers only consider three primary\ncolors (RGB) in inpainted images, but we think this is not enough. So we\npropose a new loss function to intensify color details. Extensive experiments\non commonly seen datasets (Places2 and CelebA) validate the efficacy of our\nproposed model compared with other state-of-the-art methods.\n  Index Terms: HSV color space, image inpainting, joint attention, stripe\nwindow, transformer"
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.3469684869,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 2.1363870464,
    "title": "Noise-resistant quantum memory enabled by Hamiltonian engineering",
    "abstract": "Nuclear spins in quantum dots are promising candidates for fast and scalable\nquantum memory. By utilizing the hyperfine interaction between the central\nelectron and its surrounding nuclei, quantum information can be transferred to\nthe collective state of the nuclei and be stored for a long time. However,\nnuclear spin fluctuations in a partially polarized nuclear bath deteriorate the\nquantum memory fidelity. Here we introduce a noise-resistant protocol to\nrealize fast and high-fidelity quantum memory through Hamiltonian engineering.\nWith analytics and numerics, we show that high-fidelity quantum state transfer\nbetween the electron and the nuclear spins is achievable at relatively low\nnuclear polarizations, due to the strong suppression of nuclear spin noises.\nFor a realistic quantum dot with $10^4$ nuclear spins, a fidelity surpassing\n80% is possible at a polarization as low as 30%. Our approach reduces the\ndemand for high nuclear polarization, making experimentally realizing quantum\nmemory in quantum dots more feasible."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": 0.3526483917,
    "title": "TriNet: stabilizing self-supervised learning from complete or slow collapse on ASR",
    "abstract": "Self-supervised learning (SSL) models confront challenges of abrupt\ninformational collapse or slow dimensional collapse. We propose TriNet, which\nintroduces a novel triple-branch architecture for preventing collapse and\nstabilizing the pre-training. TriNet learns the SSL latent embedding space and\nincorporates it to a higher level space for predicting pseudo target vectors\ngenerated by a frozen teacher. Our experimental results show that the proposed\nmethod notably stabilizes and accelerates pre-training and achieves a relative\nword error rate reduction (WERR) of 6.06% compared to the state-of-the-art\n(SOTA) Data2vec for a downstream benchmark ASR task. We will release our code\nat https:\/\/github.com\/tencent-ailab\/."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": -0.8459347379,
    "title": "FlatENN: Train Flat for Enhanced Fault Tolerance of Quantized Deep Neural Networks",
    "abstract": "Model compression via quantization and sparsity enhancement has gained an\nimmense interest to enable the deployment of deep neural networks (DNNs) in\nresource-constrained edge environments. Although these techniques have shown\npromising results in reducing the energy, latency and memory requirements of\nthe DNNs, their performance in non-ideal real-world settings (such as in the\npresence of hardware faults) is yet to be completely understood. In this paper,\nwe investigate the impact of bit-flip and stuck-at faults on activation-sparse\nquantized DNNs (QDNNs). We show that a high level of activation sparsity comes\nat the cost of larger vulnerability to faults. For instance, activation-sparse\nQDNNs exhibit up to 17.32% lower accuracy than the standard QDNNs. We also\nestablish that one of the major cause of the degraded accuracy is sharper\nminima in the loss landscape for activation-sparse QDNNs, which makes them more\nsensitive to perturbations in the weight values due to faults. Based on this\nobservation, we propose the mitigation of the impact of faults by employing a\nsharpness-aware quantization (SAQ) training scheme. The activation-sparse and\nstandard QDNNs trained with SAQ have up to 36.71% and 24.76% higher inference\naccuracy, respectively compared to their conventionally trained equivalents.\nMoreover, we show that SAQ-trained activation-sparse QDNNs show better accuracy\nin faulty settings than standard QDNNs trained conventionally. Thus the\nproposed technique can be instrumental in achieving sparsity-related\nenergy\/latency benefits without compromising on fault tolerance."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Learning Invariance from Generated Variance for Unsupervised Person Re-identification",
    "abstract": "This work focuses on unsupervised representation learning in person\nre-identification (ReID). Recent self-supervised contrastive learning methods\nlearn invariance by maximizing the representation similarity between two\naugmented views of a same image. However, traditional data augmentation may\nbring to the fore undesirable distortions on identity features, which is not\nalways favorable in id-sensitive ReID tasks. In this paper, we propose to\nreplace traditional data augmentation with a generative adversarial network\n(GAN) that is targeted to generate augmented views for contrastive learning. A\n3D mesh guided person image generator is proposed to disentangle a person image\ninto id-related and id-unrelated features. Deviating from previous GAN-based\nReID methods that only work in id-unrelated space (pose and camera style), we\nconduct GAN-based augmentation on both id-unrelated and id-related features. We\nfurther propose specific contrastive losses to help our network learn\ninvariance from id-unrelated and id-related augmentations. By jointly training\nthe generative and the contrastive modules, our method achieves new\nstate-of-the-art unsupervised person ReID performance on mainstream large-scale\nbenchmarks."
  },
  {
    "CAGR": 2.1450375532,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.4890352234,
    "ROI_percent": -1.0312392903,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Training Differentially Private Graph Neural Networks with Random Walk Sampling",
    "abstract": "Deep learning models are known to put the privacy of their training data at\nrisk, which poses challenges for their safe and ethical release to the public.\nDifferentially private stochastic gradient descent is the de facto standard for\ntraining neural networks without leaking sensitive information about the\ntraining data. However, applying it to models for graph-structured data poses a\nnovel challenge: unlike with i.i.d. data, sensitive information about a node in\na graph cannot only leak through its gradients, but also through the gradients\nof all nodes within a larger neighborhood. In practice, this limits\nprivacy-preserving deep learning on graphs to very shallow graph neural\nnetworks. We propose to solve this issue by training graph neural networks on\ndisjoint subgraphs of a given training graph. We develop three\nrandom-walk-based methods for generating such disjoint subgraphs and perform a\ncareful analysis of the data-generating distributions to provide strong privacy\nguarantees. Through extensive experiments, we show that our method greatly\noutperforms the state-of-the-art baseline on three large graphs, and matches or\noutperforms it on four smaller ones."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.8278466905,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.7129330908,
    "annual_revenue_USD_log": -2.3292704675,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Reduced Reference Quality Assessment for Point Cloud Compression",
    "abstract": "In this paper, we propose a reduced reference (RR) point cloud quality\nassessment (PCQA) model named R-PCQA to quantify the distortions introduced by\nthe lossy compression. Specifically, we use the attribute and geometry\nquantization steps of different compression methods (i.e., V-PCC, G-PCC and\nAVS) to infer the point cloud quality, assuming that the point clouds have no\nother distortions before compression. First, we analyze the compression\ndistortion of point clouds under separate attribute compression and geometry\ncompression to avoid their mutual masking, for which we consider 5 point clouds\nas references to generate a compression dataset (PCCQA) containing independent\nattribute compression and geometry compression samples. Then, we develop the\nproposed R-PCQA via fitting the relationship between the quantization steps and\nthe perceptual quality. We evaluate the performance of R-PCQA on both the\nestablished dataset and another independent dataset. The results demonstrate\nthat the proposed R-PCQA can exhibit reliable performance and high\ngeneralization ability."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.1472391536,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.3861709233,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -1.535978894,
    "title": "Uptrendz: API-Centric Real-time Recommendations in Multi-Domain Settings",
    "abstract": "In this work, we tackle the problem of adapting a real-time recommender\nsystem to multiple application domains, and their underlying data models and\ncustomization requirements. To do that, we present Uptrendz, a multi-domain\nrecommendation platform that can be customized to provide real-time\nrecommendations in an API-centric way. We demonstrate (i) how to set up a\nreal-time movie recommender using the popular MovieLens-100k dataset, and (ii)\nhow to simultaneously support multiple application domains based on the\nuse-case of recommendations in entrepreneurial start-up founding. For that, we\ndifferentiate between domains on the item- and system-level. We believe that\nour demonstration shows a convenient way to adapt, deploy and evaluate a\nrecommender system in an API-centric way. The source-code and documentation\nthat demonstrates how to utilize the configured Uptrendz API is available on\nGitHub."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.2927067131,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.9786301475,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.8459347379,
    "title": "MGTAB: A Multi-Relational Graph-Based Twitter Account Detection Benchmark",
    "abstract": "The development of social media user stance detection and bot detection\nmethods rely heavily on large-scale and high-quality benchmarks. However, in\naddition to low annotation quality, existing benchmarks generally have\nincomplete user relationships, suppressing graph-based account detection\nresearch. To address these issues, we propose a Multi-Relational Graph-Based\nTwitter Account Detection Benchmark (MGTAB), the first standardized graph-based\nbenchmark for account detection. To our knowledge, MGTAB was built based on the\nlargest original data in the field, with over 1.55 million users and 130\nmillion tweets. MGTAB contains 10,199 expert-annotated users and 7 types of\nrelationships, ensuring high-quality annotation and diversified relations. In\nMGTAB, we extracted the 20 user property features with the greatest information\ngain and user tweet features as the user features. In addition, we performed a\nthorough evaluation of MGTAB and other public datasets. Our experiments found\nthat graph-based approaches are generally more effective than feature-based\napproaches and perform better when introducing multiple relations. By analyzing\nexperiment results, we identify effective approaches for account detection and\nprovide potential future research directions in this field. Our benchmark and\nstandardized evaluation procedures are freely available at:\nhttps:\/\/github.com\/GraphDetec\/MGTAB."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 3.0890282145,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.9391417136,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "AmbieGen: A Search-based Framework for Autonomous Systems Testing",
    "abstract": "Thorough testing of safety-critical autonomous systems, such as self-driving\ncars, autonomous robots, and drones, is essential for detecting potential\nfailures before deployment. One crucial testing stage is model-in-the-loop\ntesting, where the system model is evaluated by executing various scenarios in\na simulator. However, the search space of possible parameters defining these\ntest scenarios is vast, and simulating all combinations is computationally\ninfeasible. To address this challenge, we introduce AmbieGen, a search-based\ntest case generation framework for autonomous systems. AmbieGen uses\nevolutionary search to identify the most critical scenarios for a given system,\nand has a modular architecture that allows for the addition of new systems\nunder test, algorithms, and search operators. Currently, AmbieGen supports test\ncase generation for autonomous robots and autonomous car lane keeping assist\nsystems. In this paper, we provide a high-level overview of the framework's\narchitecture and demonstrate its practical use cases."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.7885775055,
    "ROI_percent": 0.053041632,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.9786301475,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -1.2495847072,
    "title": "Average Is Not Enough: Caveats of Multilingual Evaluation",
    "abstract": "This position paper discusses the problem of multilingual evaluation. Using\nsimple statistics, such as average language performance, might inject\nlinguistic biases in favor of dominant language families into evaluation\nmethodology. We argue that a qualitative analysis informed by comparative\nlinguistics is needed for multilingual results to detect this kind of bias. We\nshow in our case study that results in published works can indeed be\nlinguistically biased and we demonstrate that visualization based on URIEL\ntypological database can detect it."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -1.7270042027,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.5073055989,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Frequency-aware Learned Image Compression for Quality Scalability",
    "abstract": "Spatial frequency analysis and transforms serve a central role in most\nengineered image and video lossy codecs, but are rarely employed in neural\nnetwork (NN)-based approaches. We propose a novel NN-based image coding\nframework that utilizes forward wavelet transforms to decompose the input\nsignal by spatial frequency. Our encoder generates separate bitstreams for each\nlatent representation of low and high frequencies. This enables our decoder to\nselectively decode bitstreams in a quality-scalable manner. Hence, the decoder\ncan produce an enhanced image by using an enhancement bitstream in addition to\nthe base bitstream. Furthermore, our method is able to enhance only a specific\nregion of interest (ROI) by using a corresponding part of the enhancement\nlatent representation. Our experiments demonstrate that the proposed method\nshows competitive rate-distortion performance compared to several non-scalable\nimage codecs. We also showcase the effectiveness of our two-level quality\nscalability, as well as its practicality in ROI quality enhancement."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.2047175397,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.4256317728,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Network-theoretic modeling of fluid-structure interactions",
    "abstract": "The coupling interactions between deformable structures and unsteady fluid\nflows occur across a wide range of spatial and temporal scales in many\nengineering applications. These fluid-structure interactions (FSI) pose\nsignificant challenges in accurately predicting flow physics. In the present\nwork, two multi-layer network approaches are proposed that characterize the\ninteractions between the fluid and structural layers for an incompressible\nlaminar flow over a two-dimensional compliant flat plate at a 35-degrees angle\nof attack. In the first approach, the network nodes are formed by wake vortices\nand bound vortexlets, and the edges of the network are defined by the induced\nvelocity between these elements. In the second approach, coherent structures\n(fluid modes), contributing to the kinetic energy of the flow and structural\nmodes, contributing to the kinetic energy of the compliant structure constitute\nthe network nodes. The energy transfers between the modes are extracted using a\nperturbation approach. Furthermore, the network structure of the FSI system is\nsimplified using the community detection algorithm in the vortical approach and\nby selecting dominant modes in the modal approach. Network measures are used to\nreveal the temporal behavior of the individual nodes within the simplified FSI\nsystem. Predictive models are then built using both data-driven and\nphysics-based methods. Overall, this work sets the foundation for\nnetwork-theoretic reduced-order modeling of fluid-structure interactions,\ngeneralizable to other multi-physics systems."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.0915291576,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 1.1349646314,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Task-sequencing Simulator: Integrated Machine Learning to Execution Simulation for Robot Manipulation",
    "abstract": "A task-sequencing simulator in robotics manipulation to integrate\nsimulation-for-learning and simulation-for-execution is introduced. Unlike\nexisting machine-learning simulation where a non-decomposed simulation is used\nto simulate a training scenario, the task-sequencing simulator runs a composed\nsimulation using building blocks. This way, the simulation-for-learning is\nstructured similarly to a multi-step simulation-for-execution. To compose both\nlearning and execution scenarios, a unified trainable-and-composable\ndescription of blocks called a concept model is proposed and used. Using the\nsimulator design and concept models, a reusable simulator for learning\ndifferent tasks, a common-ground system for learning-to-execution,\nsimulation-to-real is achieved and shown."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 3.0890282145,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1334390599,
    "annual_revenue_USD_log": -1.5129768028,
    "rnd_investment_required_log": -1.535978894,
    "title": "A Scalable Gaussian Process for Large-Scale Periodic Data",
    "abstract": "The periodic Gaussian process (PGP) has been increasingly used to model\nperiodic data due to its high accuracy. Yet, computing the likelihood of PGP\nhas a high computational complexity of $\\mathcal{O}\\left(n^{3}\\right)$ ($n$ is\nthe data size), which hinders its wide application. To address this issue, we\npropose a novel circulant PGP (CPGP) model for large-scale periodic data\ncollected at grids that are commonly seen in signal processing applications.\nThe proposed CPGP decomposes the log-likelihood of PGP into the sum of two\ncomputationally scalable composite log-likelihoods, which do not involve any\napproximations. Computing the likelihood of CPGP requires only\n$\\mathcal{O}\\left(p^{2}\\right)$ (or $\\mathcal{O}\\left(p\\log p\\right)$ in some\nspecial cases) time for grid observations, where the segment length $p$ is\nindependent of and much smaller than $n$. Simulations and real case studies are\npresented to show the superiority of CPGP over some state-of-the-art methods,\nespecially for applications requiring periodicity estimation. This new modeling\ntechnique can greatly advance the applicability of PGP in many areas and allow\nthe modeling of many previously intractable problems."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.8018244863,
    "ROI_percent": -1.1035246851,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.4664321295,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Machine Learning technique for isotopic determination of radioisotopes using HPGe $\\mathrm\u03b3$-ray spectra",
    "abstract": "$\\mathrm{\\gamma}$-ray spectroscopy is a quantitative, non-destructive\ntechnique that may be utilized for the identification and quantitative isotopic\nestimation of radionuclides. Traditional methods of isotopic determination have\nvarious challenges that contribute to statistical and systematic uncertainties\nin the estimated isotopics. Furthermore, these methods typically require\nnumerous pre-processing steps, and have only been rigorously tested in\nlaboratory settings with limited shielding. In this work, we examine the\napplication of a number of machine learning based regression algorithms as\nalternatives to conventional approaches for analyzing $\\mathrm{\\gamma}$-ray\nspectroscopy data in the Emergency Response arena. This approach not only\neliminates many steps in the analysis procedure, and therefore offers potential\nto reduce this source of systematic uncertainty, but is also shown to offer\ncomparable performance to conventional approaches in the Emergency Response\nApplication."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -1.0312392903,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.4256317728,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Semi-MAE: Masked Autoencoders for Semi-supervised Vision Transformers",
    "abstract": "Vision Transformer (ViT) suffers from data scarcity in semi-supervised\nlearning (SSL). To alleviate this issue, inspired by masked autoencoder (MAE),\nwhich is a data-efficient self-supervised learner, we propose Semi-MAE, a pure\nViT-based SSL framework consisting of a parallel MAE branch to assist the\nvisual representation learning and make the pseudo labels more accurate. The\nMAE branch is designed as an asymmetric architecture consisting of a\nlightweight decoder and a shared-weights encoder. We feed the weakly-augmented\nunlabeled data with a high masking ratio to the MAE branch and reconstruct the\nmissing pixels. Semi-MAE achieves 75.9% top-1 accuracy on ImageNet with 10%\nlabels, surpassing prior state-of-the-art in semi-supervised image\nclassification. In addition, extensive experiments demonstrate that Semi-MAE\ncan be readily used for other ViT models and masked image modeling methods."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 2.3858924402,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Scalable Optimal Design of Incremental Volt\/VAR Control using Deep Neural Networks",
    "abstract": "Volt\/VAR control rules facilitate the autonomous operation of distributed\nenergy resources (DER) to regulate voltage in power distribution grids.\nAccording to non-incremental control rules, such as the one mandated by the\nIEEE Standard 1547, the reactive power setpoint of each DER is computed as a\npiecewise-linear curve of the local voltage. However, the slopes of such curves\nare upper-bounded to ensure stability. On the other hand, incremental rules add\na memory term into the setpoint update, rendering them universally stable. They\ncan thus attain enhanced steady-state voltage profiles. Optimal rule design\n(ORD) for incremental rules can be formulated as a bilevel program. We put\nforth a scalable solution by reformulating ORD as training a deep neural\nnetwork (DNN). This DNN emulates the Volt\/VAR dynamics for incremental rules\nderived as iterations of proximal gradient descent (PGD). Analytical findings\nand numerical tests corroborate that the proposed ORD solution can be neatly\nadapted to single\/multi-phase feeders."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.5886243196,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Identifying Personal Data Processing for Code Review",
    "abstract": "Code review is a critical step in the software development life cycle, which\nassesses and boosts the code's effectiveness and correctness, pinpoints\nsecurity issues, and raises its quality by adhering to best practices. Due to\nthe increased need for personal data protection motivated by legislation, code\nreviewers need to understand where personal data is located in software systems\nand how it is handled. Although most recent work on code review focuses on\nsecurity vulnerabilities, privacy-related techniques are not easy for code\nreviewers to implement, making their inclusion in the code review process\nchallenging. In this paper, we present ongoing work on a new approach to\nidentifying personal data processing, enabling developers and code reviewers in\ndrafting privacy analyses and complying with regulations such as the General\nData Protection Regulation (GDPR)."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.742097711,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.4686850597,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 1.5534070302,
    "rnd_investment_required_log": 1.6684873834,
    "title": "Finding Needles in Haystack: Formal Generative Models for Efficient Massive Parallel Simulations",
    "abstract": "The increase in complexity of autonomous systems is accompanied by a need of\ndata-driven development and validation strategies. Advances in computer\ngraphics and cloud clusters have opened the way to massive parallel high\nfidelity simulations to qualitatively address the large number of operational\nscenarios. However, exploration of all possible scenarios is still\nprohibitively expensive and outcomes of scenarios are generally unknown\napriori. To this end, the authors propose a method based on bayesian\noptimization to efficiently learn generative models on scenarios that would\ndeliver desired outcomes (e.g. collisions) with high probability. The\nmethodology is integrated in an end-to-end framework, which uses the\nOpenSCENARIO standard to describe scenarios, and deploys highly configurable\ndigital twins of the scenario participants on a Virtual Test Bed cluster."
  },
  {
    "CAGR": -1.4452652355,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": -1.1517610651,
    "rnd_investment_required_log": -1.535978894,
    "title": "A Voigt laser operating on $^{87}$Rb 780 nm transition",
    "abstract": "We report the development of laser systems -- a \"Voigt laser\" -- using a\nVoigt anomalous dispersion optical filter as the frequency-selective element,\nworking at the wavelength of 780 nm of $^{87}$Rb-D2 resonance line. Compared\nwith Faraday anomalous dispersion optical filter, the Voigt anomalous\ndispersion optical filter can generate a stronger and more uniform magnetic\nfield with a compact size of magnet, and obtains a transmission spectrum with\nnarrower linewidth and more stable lineprofile. In this case, the frequency\nstability of the Voigt laser reaches 5$\\times$10$^{-9}$ at the averaging time\nof 200 s, and the wavelength fluctuation of 8-hours free operation is $\\pm$0.1\npm. Besides, the Voigt laser has greater immunity to diode current than the\nFaraday laser, with a wavelength fluctuation of $\\pm$0.5 pm in the current\nrange from 73 mA to 150 mA. Finally, the Voigt laser frequency can be\ncontrolled by the cell temperature of the Voigt optical filter, which is\nexpected to achieve a frequency detuning of 20 GHz. Consequently, the Voigt\nlaser, whose frequency could correspond to the atomic transition frequency by\ntuning the cell temperature, obtains good robustness to the current and\ntemperature fluctuation of laser diode, and could realize a compact optical\nstandard for precise measurement once stabilized by modulation transfer\nspectroscopy."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -1.1517610651,
    "rnd_investment_required_log": 2.1363870464,
    "title": "Process Variation-Aware Compact Model of Strip Waveguides for Photonic Circuit Simulation",
    "abstract": "We report a novel process variation-aware compact model of strip waveguides\nthat is suitable for circuit-level simulation of waveguide-based process design\nkit (PDK) elements. The model is shown to describe both loss and -- using a\nnovel expression for the thermo-optic effect in high index contrast materials\n-- the thermo-optic behavior of strip waveguides. A novel group extraction\nmethod enables modeling the effective index's ($n_{\\mathrm{eff}}$) sensitivity\nto local process variations without the presumption of variation source. Use of\nEuler-bend Mach-Zehnder interferometers (MZIs) fabricated in a 300~mm wafer run\nallow model parameter extraction at widths up to 2.5~$\\mu$m (highly multi-mode)\nwith strong suppression of higher-order mode excitation. Experimental results\nprove the reported model can self-consistently describe waveguide phase, loss,\nand thermo-optic behavior across all measured devices over an unprecedented\nrange of optical bandwidth, waveguide widths, and temperatures."
  },
  {
    "CAGR": -0.0643795475,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.6751741936,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.7327369984,
    "title": "On-chip Hong-Ou-Mandel interference from separate quantum dot emitters in an integrated circuit",
    "abstract": "Scalable quantum photonic technologies require low-loss integration of many\nidentical single-photon sources with photonic circuitry on a chip. Relatively\ncomplex quantum photonic circuits have already been demonstrated; however,\nsources used so far relied on parametric-down-conversion. Hence, the efficiency\nand scalability are intrinsically limited by the probabilistic nature of the\nsources. Quantum emitter-based single-photon sources are free of this\nlimitation, but frequency matching of multiple emitters within a single circuit\nremains a challenge. In this work, we demonstrate a key component in this\nregard in the form of a fully monolithic GaAs circuit combing two\nfrequency-matched quantum dot single-photon sources interconnected with a\nlow-loss on-chip beamsplitter connected via single-mode ridge waveguides. This\ndevice enabled us to perform a two-photon interference experiment on-chip with\nvisibility reaching 66%, limited by the coherence of the emitters. Our device\ncould be further scaled up, providing a clear path to increase the complexity\nof quantum circuits toward fully scalable integrated quantum technologies."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.5175734475,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Comprehensive analysis of gene expression profiles to radiation exposure reveals molecular signatures of low-dose radiation response",
    "abstract": "There are various sources of ionizing radiation exposure, where medical\nexposure for radiation therapy or diagnosis is the most common human-made\nsource. Understanding how gene expression is modulated after ionizing radiation\nexposure and investigating the presence of any dose-dependent gene expression\npatterns have broad implications for health risks from radiotherapy, medical\nradiation diagnostic procedures, as well as other environmental exposure. In\nthis paper, we perform a comprehensive pathway-based analysis of gene\nexpression profiles in response to low-dose radiation exposure, in order to\nexamine the potential mechanism of gene regulation underlying such responses.\nTo accomplish this goal, we employ a statistical framework to determine whether\na specific group of genes belonging to a known pathway display coordinated\nexpression patterns that are modulated in a manner consistent with the\nradiation level. Findings in our study suggest that there exist complex yet\nconsistent signatures that reflect the molecular response to radiation\nexposure, which differ between low-dose and high-dose radiation."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Fully Automated Artery-Vein ratio and vascular tortuosity measurement in retinal fundus images",
    "abstract": "Accurate measurements of abnormalities like Artery-Vein ratio and tortuosity\nin fundus images is an actively researched task. Most of the research seems to\ncompute such features independently. However, in this work, we have devised a\nfully automated technique to measure any vascular abnormalities. This paper is\na follow-up paper on vessel topology estimation and extraction, we use the\nextracted topology to perform A-V state-of-the-art Artery-Vein classification,\nAV ratio calculation, and vessel tortuosity measurement, all fully automated.\nExisting techniques tend to only work on the partial region, but we extract the\ncomplete vascular structure. We have shown the usability of this topology by\nextracting two of the most important vascular features; Artery-Vein ratio, and\nvessel tortuosity."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.552836402,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.5595405096,
    "title": "fintech-kMC: Agent based simulations of financial platforms for design and testing of machine learning systems",
    "abstract": "We discuss our simulation tool, fintech-kMC, which is designed to generate\nsynthetic data for machine learning model development and testing. fintech-kMC\nis an agent-based model driven by a kinetic Monte Carlo (a.k.a. continuous time\nMonte Carlo) engine which simulates the behaviour of customers using an online\ndigital financial platform. The tool provides an interpretable, reproducible,\nand realistic way of generating synthetic data which can be used to validate\nand test AI\/ML models and pipelines to be used in real-world customer-facing\nfinancial applications."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 1.0650371595,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.5550659269,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.9391692981,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": -1.027440103,
    "title": "Detecting Neighborhood Gentrification at Scale via Street-level Visual Data",
    "abstract": "Neighborhood gentrification plays a significant role in shaping the social\nand economic well-being of both individuals and communities at large. While\nsome efforts have been made to detect gentrification in cities, existing\napproaches rely mainly on estimated measures from survey data, require\nsubstantial work of human labeling, and are limited in characterizing the\nneighborhood as a whole. We propose a novel approach to detecting neighborhood\ngentrification at a large-scale based on the physical appearance of\nneighborhoods by incorporating historical street-level visual data. We show the\neffectiveness of the proposed method by comparing results from our approach\nwith gentrification measures from previous literature and case studies. Our\napproach has the potential to supplement existing indicators of gentrification\nand become a valid resource for urban researchers and policy makers."
  },
  {
    "CAGR": -0.2991301145,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 2.1363870464,
    "title": "An almost deterministic cooling by measurements",
    "abstract": "Nondeterministic measurement-based techniques are efficient in reshaping the\npopulation distribution of a quantum system but suffer from a limited success\nprobability of holding the system in the target state. To reduce the\nexperimental cost, we exploit the state-engineering mechanisms of both\nconditional and unconditional measurements and propose a two-step protocol\nassisted by a qubit to cool a resonator down to the ground state with a\nnear-unit probability. In the first step, the unconditional measurements on the\nancillary qubit are applied to reshape the target resonator from a thermal\nstate to a reserved Fock state. The measurement sequence is optimized by\nreinforcement learning for a maximum fidelity. In the second step, the\npopulation on the reserved state can be faithfully transferred in a stepwise\nway to the resonator's ground state with a near-unit fidelity by the\nconditional measurements on the qubit. Intrinsic nondeterminacy of the\nprojection-based conditional measurement is effectively inhibited by properly\nspacing the measurement sequence, which makes the Kraus operator act as a\nlowering operator for neighboring Fock states. Through dozens of measurements,\nthe initial thermal average occupation of the resonator can be reduced by five\norders in magnitude with a success probability over $95\\%$."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.7551986982,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.5871850202,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Enabling Augmented Segmentation and Registration in Ultrasound-Guided Spinal Surgery via Realistic Ultrasound Synthesis from Diagnostic CT Volume",
    "abstract": "This paper aims to tackle the issues on unavailable or insufficient clinical\nUS data and meaningful annotation to enable bone segmentation and registration\nfor US-guided spinal surgery. While the US is not a standard paradigm for\nspinal surgery, the scarcity of intra-operative clinical US data is an\ninsurmountable bottleneck in training a neural network. Moreover, due to the\ncharacteristics of US imaging, it is difficult to clearly annotate bone\nsurfaces which causes the trained neural network missing its attention to the\ndetails. Hence, we propose an In silico bone US simulation framework that\nsynthesizes realistic US images from diagnostic CT volume. Afterward, using\nthese simulated bone US we train a lightweight vision transformer model that\ncan achieve accurate and on-the-fly bone segmentation for spinal sonography. In\nthe validation experiments, the realistic US simulation was conducted by\nderiving from diagnostic spinal CT volume to facilitate a radiation-free\nUS-guided pedicle screw placement procedure. When it is employed for training\nbone segmentation task, the Chamfer distance achieves 0.599mm; when it is\napplied for CT-US registration, the associated bone segmentation accuracy\nachieves 0.93 in Dice, and the registration accuracy based on the segmented\npoint cloud is 0.13~3.37mm in a complication-free manner. While bone US images\nexhibit strong echoes at the medium interface, it may enable the model\nindistinguishable between thin interfaces and bone surfaces by simply relying\non small neighborhood information. To overcome these shortcomings, we propose\nto utilize a Long-range Contrast Learning Module to fully explore the\nLong-range Contrast between the candidates and their surrounding pixels."
  },
  {
    "CAGR": 1.7307718468,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Single-round Self-supervised Distributed Learning using Vision Transformer",
    "abstract": "Despite the recent success of deep learning in the field of medicine, the\nissue of data scarcity is exacerbated by concerns about privacy and data\nownership. Distributed learning approaches, including federated learning, have\nbeen investigated to address these issues. However, they are hindered by the\nneed for cumbersome communication overheads and weaknesses in privacy\nprotection. To tackle these challenges, we propose a self-supervised masked\nsampling distillation method for the vision transformer. This method can be\nimplemented without continuous communication and can enhance privacy by\nutilizing a vision transformer-specific encryption technique. We conducted\nextensive experiments on two different tasks, which demonstrated the\neffectiveness of our method. We achieved superior performance compared to the\nexisting distributed learning strategy as well as the fine-tuning only\nbaseline. Furthermore, since the self-supervised model created using our\nproposed method can achieve a general semantic understanding of the image, we\ndemonstrate its potential as a task-agnostic self-supervised foundation model\nfor various downstream tasks, thereby expanding its applicability in the\nmedical domain."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8042851795,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.4664321295,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -1.535978894,
    "title": "Singing voice synthesis based on frame-level sequence-to-sequence models considering vocal timing deviation",
    "abstract": "This paper proposes singing voice synthesis (SVS) based on frame-level\nsequence-to-sequence models considering vocal timing deviation. In SVS, it is\nessential to synchronize the timing of singing with temporal structures\nrepresented by scores, taking into account that there are differences between\nactual vocal timing and note start timing. In many SVS systems including our\nprevious work, phoneme-level score features are converted into frame-level ones\non the basis of phoneme boundaries obtained by external aligners to take into\naccount vocal timing deviations. Therefore, the sound quality is affected by\nthe aligner accuracy in this system. To alleviate this problem, we introduce an\nattention mechanism with frame-level features. In the proposed system, the\nattention mechanism absorbs alignment errors in phoneme boundaries.\nAdditionally, we evaluate the system with pseudo-phoneme-boundaries defined by\nheuristic rules based on musical scores when there is no aligner. The\nexperimental results show the effectiveness of the proposed system."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Polar Codes with Local-Global Decoding",
    "abstract": "In this paper, we investigate a coupled polar code architecture that supports\nboth local and global decoding. This local-global construction is motivated by\npractical applications in data storage and transmission where reduced-latency\nrecovery of sub-blocks of the coded information is required. Local decoding\nallows random access to sub-blocks of the full code block. When local decoding\nperformance is insufficient, global decoding provides improved data\nreliability. The coupling scheme incorporates a systematic outer polar code and\na partitioned mapping of the outer codeword to semipolarized bit-channels of\nthe inner polar codes. Error rate simulation results are presented for 2 and 4\nsub-blocks. Design issues affecting the trade-off between local and global\ndecoding performance are also discussed."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -1.5372370541,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.0592499803,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": -1.535978894,
    "title": "Text2Poster: Laying out Stylized Texts on Retrieved Images",
    "abstract": "Poster generation is a significant task for a wide range of applications,\nwhich is often time-consuming and requires lots of manual editing and artistic\nexperience. In this paper, we propose a novel data-driven framework, called\n\\textit{Text2Poster}, to automatically generate visually-effective posters from\ntextual information. Imitating the process of manual poster editing, our\nframework leverages a large-scale pretrained visual-textual model to retrieve\nbackground images from given texts, lays out the texts on the images\niteratively by cascaded auto-encoders, and finally, stylizes the texts by a\nmatching-based method. We learn the modules of the framework by weakly- and\nself-supervised learning strategies, mitigating the demand for labeled data.\nBoth objective and subjective experiments demonstrate that our Text2Poster\noutperforms state-of-the-art methods, including academic research and\ncommercial software, on the quality of generated posters."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.4463427327,
    "title": "Applications of elastic instability and elastic turbulence: Review, limitations, and future directions",
    "abstract": "Viscoelastic fluids are a subclass of complex fluids used in widespread\napplications ranging from biological to large-scale industrial settings. These\nfluids are often associated with various complex flow phenomena due to the\npresence of non-linear elastic stresses, originating due to the stretching and\nrelaxation phenomena of microstructure (such as polymer molecules in the case\nof a viscoelastic polymer solution) in a deformed flow field. One such\nphenomenon is elastic instability (EI) which emerges due to the interaction\nbetween elastic stresses and streamline curvature present in a flow system at\nsmall values of the Renolds number (ratio of the inertial to that of the\nviscous forces) when the Weissenberg number (ratio of the microstructure\nrelaxation time to that of the rate of flow deformation) exceeds a critical\nvalue. On further increasing this Weissenberg number to higher values, the\nunstable flow field caused due to this elastic instability transits to a more\nchaotic and turbulent-like flow structure called elastic turbulence (ET). Over\nthe last two decades or so, an extensive investigation has been performed on\nthis particular topic in the complex fluids research community. Some excellent\narticles recently present this ET phenomenon's development, understanding, and\nprogress in the literature. This article focuses on the application\nperspectives of this phenomenon. In particular, this article aims to provide a\ncomprehensive review of the investigations conducted so far in the literature\nto demonstrate the potential of these EI and ET phenomena in three main\napplication areas, namely, microfluidic mixing, microscale heat transfer, and\nchemically enhanced oil recovery (EOR) process. Additionally, a detailed\ndiscussion of the limitations and future directions of these EI and ET\nphenomena from an application point of view is also presented in this article."
  },
  {
    "CAGR": -0.9619552447,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -1.1035246851,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -1.6319355937,
    "rnd_investment_required_log": -1.7174842259,
    "title": "Codepod: A Namespace-Aware, Hierarchical Jupyter for Interactive Development at Scale",
    "abstract": "Jupyter is a browser-based interactive development environment that has been\npopular recently. Jupyter models programs in code blocks, and makes it easy to\ndevelop code blocks interactively by running the code blocks and attaching rich\nmedia output. However, Jupyter provides no support for module systems and\nnamespaces. Code blocks are linear and live in the global namespace; therefore,\nit is hard to develop large projects that require modularization in Jupyter. As\na result, large-code projects are still developed in traditional text files,\nand Jupyter is only used as a surface presentation. We present Codepod, a\nnamespace-aware Jupyter that is suitable for interactive development at scale.\nInstead of linear code blocks, Codepod models code blocks as hierarchical code\npods, and provides a simple yet powerful module system for namespace-aware\nincremental evaluation. Codepod is open source at\nhttps:\/\/github.com\/codepod-io\/codepod."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.692474134,
    "title": "Conformal Loss-Controlling Prediction",
    "abstract": "Conformal prediction is a learning framework controlling prediction coverage\nof prediction sets, which can be built on any learning algorithm for point\nprediction. This work proposes a learning framework named conformal\nloss-controlling prediction, which extends conformal prediction to the\nsituation where the value of a loss function needs to be controlled. Different\nfrom existing works about risk-controlling prediction sets and conformal risk\ncontrol with the purpose of controlling the expected values of loss functions,\nthe proposed approach in this paper focuses on the loss for any test object,\nwhich is an extension of conformal prediction from miscoverage loss to some\ngeneral loss. The controlling guarantee is proved under the assumption of\nexchangeability of data in finite-sample cases and the framework is tested\nempirically for classification with a class-varying loss and statistical\npostprocessing of numerical weather forecasting applications, which are\nintroduced as point-wise classification and point-wise regression problems. All\ntheoretical analysis and experimental results confirm the effectiveness of our\nloss-controlling approach."
  },
  {
    "CAGR": 2.1450375532,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": 1.9038179693,
    "title": "Why do Nearest Neighbor Language Models Work?",
    "abstract": "Language models (LMs) compute the probability of a text by sequentially\ncomputing a representation of an already-seen context and using this\nrepresentation to predict the next word. Currently, most LMs calculate these\nrepresentations through a neural network consuming the immediate previous\ncontext. However recently, retrieval-augmented LMs have shown to improve over\nstandard neural LMs, by accessing information retrieved from a large datastore,\nin addition to their standard, parametric, next-word prediction. In this paper,\nwe set out to understand why retrieval-augmented language models, and\nspecifically why k-nearest neighbor language models (kNN-LMs) perform better\nthan standard parametric LMs, even when the k-nearest neighbor component\nretrieves examples from the same training set that the LM was originally\ntrained on. To this end, we perform a careful analysis of the various\ndimensions over which kNN-LM diverges from standard LMs, and investigate these\ndimensions one by one. Empirically, we identify three main reasons why kNN-LM\nperforms better than standard LMs: using a different input representation for\npredicting the next tokens, approximate kNN search, and the importance of\nsoftmax temperature for the kNN distribution. Further, we incorporate these\ninsights into the model architecture or the training procedure of the standard\nparametric LM, improving its results without the need for an explicit retrieval\ncomponent. The code is available at https:\/\/github.com\/frankxu2004\/knnlm-why."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -1.7270042027,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 1.1725984464,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 2.3858924402,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": -1.5129768028,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Multiclass Semantic Segmentation to Identify Anatomical Sub-Regions of Brain and Measure Neuronal Health in Parkinson's Disease",
    "abstract": "Automated segmentation of anatomical sub-regions with high precision has\nbecome a necessity to enable the quantification and characterization of cells\/\ntissues in histology images. Currently, a machine learning model to analyze\nsub-anatomical regions of the brain to analyze 2D histological images is not\navailable. The scientists rely on manually segmenting anatomical sub-regions of\nthe brain which is extremely time-consuming and prone to labeler-dependent\nbias. One of the major challenges in accomplishing such a task is the lack of\nhigh-quality annotated images that can be used to train a generic artificial\nintelligence model. In this study, we employed a UNet-based architecture,\ncompared model performance with various combinations of encoders, image sizes,\nand sample selection techniques. Additionally, to increase the sample set we\nresorted to data augmentation which provided data diversity and robust\nlearning. In this study, we trained our best fit model on approximately one\nthousand annotated 2D brain images stained with Nissl\/ Haematoxylin and\nTyrosine Hydroxylase enzyme (TH, indicator of dopaminergic neuron viability).\nThe dataset comprises of different animal studies enabling the model to be\ntrained on different datasets. The model effectively is able to detect two\nsub-regions compacta (SNCD) and reticulata (SNr) in all the images. In spite of\nlimited training data, our best model achieves a mean intersection over union\n(IOU) of 79% and a mean dice coefficient of 87%. In conclusion, the UNet-based\nmodel with EffiecientNet as an encoder outperforms all other encoders,\nresulting in a first of its kind robust model for multiclass segmentation of\nsub-brain regions in 2D images."
  },
  {
    "CAGR": -1.3762209511,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.1558904989,
    "title": "SpeeChain: A Speech Toolkit for Large-Scale Machine Speech Chain",
    "abstract": "This paper introduces SpeeChain, an open-source Pytorch-based toolkit\ndesigned to develop the machine speech chain for large-scale use. This first\nrelease focuses on the TTS-to-ASR chain, a core component of the machine speech\nchain, that refers to the TTS data augmentation by unspoken text for ASR. To\nbuild an efficient pipeline for the large-scale TTS-to-ASR chain, we implement\neasy-to-use multi-GPU batch-level model inference, multi-dataloader batch\ngeneration, and on-the-fly data selection techniques. In this paper, we first\nexplain the overall procedure of the TTS-to-ASR chain and the difficulties of\neach step. Then, we present a detailed ablation study on different types of\nunlabeled data, data filtering thresholds, batch composition, and\nreal-synthetic data ratios. Our experimental results on train_clean_460 of\nLibriSpeech demonstrate that our TTS-to-ASR chain can significantly improve WER\nin a semi-supervised setting."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 3.4504551886,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.2927067131,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Transceiver Cooperative Learning-aided Semantic Communications Against Mismatched Background Knowledge Bases",
    "abstract": "Semantic communications learned on background knowledge bases (KBs) have been\nidentified as a promising technology for communications between intelligent\nagents. Existing works assume that transceivers of semantic communications\nshare the same KB. However, intelligent transceivers may suffer from the\ncommunication burden or worry about privacy leakage to exchange data in KBs.\nBesides, the transceivers may independently learn from the environment and\ndynamically update their KBs, leading to timely sharing of the KBs infeasible.\nAll these cause the mismatch between the KBs, which may result in a\nsemantic-level misunderstanding on the receiver side. To address this issue, we\npropose a transceiver cooperative learning-assisted semantic communication\n(TCL-SC) scheme against mismatched KBs. In TCL-SC, the transceivers\ncooperatively train semantic encoder and decoder neuron networks (NNs) of the\nsame structure based on their own KBs. They periodically share the parameters\nof NNs. To reduce the communication overhead of parameter sharing, parameter\nquantization is adopted. Moreover, we discuss the impacts of the number of\ncommunication rounds on the performance of semantic communication systems.\nExperiments on real-world data demonstrate that our proposed TCL-SC can reduce\nthe semantic-level misunderstanding on the receiver side caused by the mismatch\nbetween the KBs, especially at the low signal-to-noise (SNR) ratio regime."
  },
  {
    "CAGR": -0.4786452539,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.2539029658,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.7930902346,
    "title": "Ion sensors with crown ether-functionalized nanodiamonds",
    "abstract": "Alkali metal ions such as sodium and potassium cations play fundamental roles\nin biology. Developing highly sensitive and selective methods to both detect\nand quantify these ions is of considerable importance for medical diagnostics\nand bioimaging. Fluorescent nanoparticles have emerged as powerful tools for\nnanoscale imaging, but their optical properties need to be supplemented with\nspecificity to particular chemical and biological signals in order to provide\nfurther information about biological processes. Nitrogen-vacancy (NV) centers\nin diamond are particularly attractive as fluorescence markers, thanks to their\noptical stability, biocompatibility and further ability to serve as highly\nsensitive quantum sensors of temperature, magnetic and electric fields in\nambient conditions. In this work, by covalently grafting crown ether structures\non the surface of nanodiamonds (NDs), we build sensors that are capable of\ndetecting specific alkali ions such as sodium cations. We will show that the\npresence of these metal ions modifies the charge state of NV centers inside the\nND, which can then be read out by measuring their photoluminescence spectrum.\nOur work paves the way for designing selective biosensors based on NV centers\nin diamond."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.7018568771,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.5595405096,
    "title": "EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset",
    "abstract": "Visual object tracking is a key component to many egocentric vision problems.\nHowever, the full spectrum of challenges of egocentric tracking faced by an\nembodied AI is underrepresented in many existing datasets; these tend to focus\non relatively short, third-person videos. Egocentric video has several\ndistinguishing characteristics from those commonly found in past datasets:\nfrequent large camera motions and hand interactions with objects commonly lead\nto occlusions or objects exiting the frame, and object appearance can change\nrapidly due to widely different points of view, scale, or object states.\nEmbodied tracking is also naturally long-term, and being able to consistently\n(re-)associate objects to their appearances and disappearances over as long as\na lifetime is critical. Previous datasets under-emphasize this re-detection\nproblem, and their \"framed\" nature has led to adoption of various\nspatiotemporal priors that we find do not necessarily generalize to egocentric\nvideo. We thus introduce EgoTracks, a new dataset for long-term egocentric\nvisual object tracking. Sourced from the Ego4D dataset, this new dataset\npresents a significant challenge to recent state-of-the-art single-object\ntracking models, which we find score poorly on traditional tracking metrics for\nour new dataset, compared to popular benchmarks. We further show improvements\nthat can be made to a STARK tracker to significantly increase its performance\non egocentric data, resulting in a baseline model we call EgoSTARK. We publicly\nrelease our annotations and benchmark, hoping our dataset leads to further\nadvancements in tracking."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.2648373378,
    "title": "X-ray detected ferromagnetic resonance techniques for the study of magnetization dynamics",
    "abstract": "Element-specific spectroscopies using synchrotron-radiation can provide\nunique insights into materials properties. The recently developed technique of\nX-ray detected ferromagnetic resonance (XFMR) allows studying the magnetization\ndynamics of magnetic spin structures. Magnetic sensitivity in XFMR is obtained\nfrom the X-ray magnetic circular dichroism (XMCD) effect, where the phase of\nthe magnetization precession of each magnetic layer with respect to the\nexciting radio frequency is obtained using stroboscopic probing of the spin\nprecession. Measurement of both amplitude and phase response in the magnetic\nlayers as a function of bias field can give a clear signature of spin-transfer\ntorque (STT) coupling between ferromagnetic layers due to spin pumping. Over\nthe last few years, there have been new developments utilizing X-ray scattering\ntechniques to reveal the precessional magnetization dynamics of ordered spin\nstructures in the GHz frequency range. The techniques of diffraction and\nreflectometry ferromagnetic resonance (DFMR and RFMR) provide novel ways for\nthe probing of the dynamics of chiral and multilayered magnetic materials,\nthereby opening up new pathways for the development of high-density and\nlow-energy consumption data processing solutions."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.7257468095,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.5152628518,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.2659314651,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Observation of magnetic state dependent thermoelectricity in superconducting spin valves",
    "abstract": "Superconductor-ferromagnet tunnel junctions demonstrate giant thermoelectric\neffects which are being exploited to engineer ultra-sensitive terahertz\nradiation detectors. Here, we experimentally observe the recently predicted\ncomplete magnetic control over thermoelectric effects in a superconducting spin\nvalve, including the dependence of its sign on the magnetic state of the spin\nvalve. The description of the experimental results is improved by the\nintroduction of an interfacial domain wall in the spin filter layer interfacing\nthe superconductor. Surprisingly, the application of high in-plane magnetic\nfields induces a double sign inversion of the thermoelectric effect, which\nexhibits large values even at applied fields twice the superconducting critical\nfield."
  },
  {
    "CAGR": 2.1450375532,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Magneto-optical chirality in a coherently coupled exciton-plasmon system",
    "abstract": "Chirality is a fundamental asymmetry phenomenon, with chiral optical elements\nexhibiting asymmetric response in reflection or absorption of circularly\npolarized light. Recent realizations of such elements include nanoplasmonic\nsystems with broken mirror symmetry and polarization-contrasting optical\nabsorption known as circular dichroism. An alternative route to circular\ndichroism is provided by spin-valley polarized excitons in atomically thin\nsemiconductors. In the presence of magnetic fields, they exhibit an imbalanced\ncoupling to circularly polarized photons and thus circular dichroism. Here, we\ndemonstrate that polarization-contrasting optical transitions associated with\nexcitons in monolayer WSe$_2$ can be transferred to proximal plasmonic\nnanodisks by coherent coupling. The coupled exciton-plasmon system exhibits\nmagneto-induced circular dichroism in a spectrally narrow window of Fano\ninterference, which we model in a master equation framework. Our work motivates\nexciton-plasmon interfaces as building blocks of chiral metasurfaces for\napplications in information processing, non-linear optics and sensing."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 3.1229303951,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 2.3585316987,
    "title": "Entangling microwaves with optical light",
    "abstract": "Entanglement is a genuine quantum mechanical property and the key resource in\ncurrently developed quantum technologies. Sharing this fragile property between\nsuperconducting microwave circuits and optical or atomic systems would enable\nnew functionalities but has been hindered by the tremendous energy mismatch of\n$\\sim10^5$ and the resulting mutually imposed loss and noise. In this work we\ncreate and verify entanglement between microwave and optical fields in a\nmillikelvin environment. Using an optically pulsed superconducting\nelectro-optical device, we deterministically prepare an itinerant\nmicrowave-optical state that is squeezed by $0.72^{+0.31}_{-0.25}$\\,dB and\nviolates the Duan-Simon separability criterion by $>5$ standard deviations.\nThis establishes the long-sought non-classical correlations between\nsuperconducting circuits and telecom wavelength light with wide-ranging\nimplications for hybrid quantum networks in the context of modularization,\nscaling, sensing and cross-platform verification."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.2605876197,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.5831178716,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 0.9097590502,
    "title": "A Novel Waveform Design for OFDM-Based Joint Sensing and Communication System",
    "abstract": "The dominating waveform in 5G is orthogonal frequency division multiplexing\n(OFDM). OFDM will remain a promising waveform candidate for joint communication\nand sensing (JCAS) in 6G since OFDM can provide excellent data transmission\ncapability and accurate sensing information. This paper proposes a novel\nOFDM-based diagonal waveform structure and corresponding signal processing\nalgorithm. This approach allocates the sensing signals along the diagonal of\nthe time-frequency resource block. Therefore, the sensing signals in a linear\nstructure span both the frequency and time domains. The range and velocity of\nthe object can be estimated simultaneously by applying 1D-discrete Fourier\ntransform (DFT) to the diagonal sensing signals. Compared to the conventional\n2D-DFT OFDM radar algorithm, the computational complexity of the proposed\nalgorithm is low. In addition, the sensing overhead can be substantially\nreduced. The performance of the proposed waveform is evaluated using simulation\nand analysis of results."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 0.7036101854,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.9786301475,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.692474134,
    "title": "DRL-GAN: A Hybrid Approach for Binary and Multiclass Network Intrusion Detection",
    "abstract": "Our increasingly connected world continues to face an ever-growing amount of\nnetwork-based attacks. Intrusion detection systems (IDS) are an essential\nsecurity technology for detecting these attacks. Although numerous machine\nlearning-based IDS have been proposed for the detection of malicious network\ntraffic, the majority have difficulty properly detecting and classifying the\nmore uncommon attack types. In this paper, we implement a novel hybrid\ntechnique using synthetic data produced by a Generative Adversarial Network\n(GAN) to use as input for training a Deep Reinforcement Learning (DRL) model.\nOur GAN model is trained with the NSL-KDD dataset for four attack categories as\nwell as normal network flow. Ultimately, our findings demonstrate that training\nthe DRL on specific synthetic datasets can result in better performance in\ncorrectly classifying minority classes over training on the true imbalanced\ndataset."
  },
  {
    "CAGR": -0.7548223915,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.5175734475,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.5998033579,
    "title": "Charged domain walls in BaTiO$_3$ crystals emerging from superdomain boundaries",
    "abstract": "Previous experiments with BaTiO$_3$ single crystals have shown that\napplication of the electric field in the vicinity of the ferroelectric phase\ntransition can be used to introduce peculiar persisting ferroelectric domain\nwalls, accompanied by the compensating charge in the form of two-dimensional\nelectron gas. The present in-situ optical observations of such electric poling\nprocess reveal formation of a transient coexistence of the cubic and\nferroelectric phases, the latter one being broken into multiple martensitic\nsuperdomains, separated by superdomain walls. It is revealed that as the\ntransient superdomains convert into the regular ferroelectric domains, the\nsuperdomain boundaries transform into the desired charged domain walls. In\norder to assign the observed transient domain patterns, to understand the\nshapes of the observed ferrolectric precipitates and their agglomerates as well\nas to provide the overall interpretation of the observed domain formation\nprocess, the implications of the mechanical compatibility of the coexisting\nsuperdomain states is derived in the framework of the Wechsler-Lieberman-Read\ntheory. The results also suggest that the transport of the compensating charge\ncarriers towards the final charged domain wall location is directly associated\nwith the electric conductivity and interlinked motion and growth of the\nsuperdomain walls and phase fronts."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.4484018214,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.2476060596,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 2.6449259669,
    "title": "Physics-separating artificial neural networks for predicting sputtering and thin film deposition of AlN in Ar\/N$_2$ discharges on experimental timescales",
    "abstract": "Understanding and modeling plasma-surface interactions frame a multi-scale as\nwell as multi-physics problem. Scale-bridging machine learning surface\nsurrogate models have been demonstrated to perceive the fundamental atomic\nfidelity for the physical vapor deposition of pure metals. However, the immense\ncomputational cost of the data-generating simulations render a practical\napplication with predictions on relevant timescales impracticable. This issue\nis resolved in this work for the sputter deposition of AlN in Ar\/N$_2$\ndischarges by developing a scheme that populates the parameter spaces\neffectively. Hybrid reactive molecular dynamics \/ time-stamped force-bias Monte\nCarlo simulations of randomized plasma-surface interactions \/ diffusion\nprocesses are used to setup a physics-separating artificial neural network. The\napplication of this generic machine learning model to a specific experimental\nreference case study enables the systematic analysis of the particle flux\nemission as well as underlying system state (e.g., composition, mass density,\nstress, point defect structure) evolution within process times of up to 45\nminutes."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.8435543645,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Pre-merger sky localization of gravitational waves from binary neutron star mergers using deep learning",
    "abstract": "The simultaneous observation of gravitational waves (GW) and prompt\nelectromagnetic counterparts from the merger of two neutron stars can help\nreveal the properties of extreme matter and gravity during and immediately\nafter the final plunge. Rapid sky localization of these sources is crucial to\nfacilitate such multi-messenger observations. Since GWs from binary neutron\nstar (BNS) mergers can spend up to 10-15 mins in the frequency bands of the\ndetectors at design sensitivity, early warning alerts and pre-merger sky\nlocalization can be achieved for sufficiently bright sources, as demonstrated\nin recent studies. In this work, we present pre-merger BNS sky localization\nresults using CBC-SkyNet, a deep learning model capable of inferring sky\nlocation posterior distributions of GW sources at orders of magnitude faster\nspeeds than standard Markov Chain Monte Carlo methods. We test our model's\nperformance on a catalog of simulated injections from Sachdev et al. (2020),\nrecovered at 0-60 secs before merger, and obtain comparable sky localization\nareas to the rapid localization tool BAYESTAR. These results show the\nfeasibility of our model for rapid pre-merger sky localization and the\npossibility of follow-up observations for precursor emissions from BNS mergers."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 1.5534070302,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Explainable, Physics Aware, Trustworthy AI Paradigm Shift for Synthetic Aperture Radar",
    "abstract": "The recognition or understanding of the scenes observed with a SAR system\nrequires a broader range of cues, beyond the spatial context. These encompass\nbut are not limited to: imaging geometry, imaging mode, properties of the\nFourier spectrum of the images or the behavior of the polarimetric signatures.\nIn this paper, we propose a change of paradigm for explainability in data\nscience for the case of Synthetic Aperture Radar (SAR) data to ground the\nexplainable AI for SAR. It aims to use explainable data transformations based\non well-established models to generate inputs for AI methods, to provide\nknowledgeable feedback for training process, and to learn or improve\nhigh-complexity unknown or un-formalized models from the data. At first, we\nintroduce a representation of the SAR system with physical layers: i)\ninstrument and platform, ii) imaging formation, iii) scattering signatures and\nobjects, that can be integrated with an AI model for hybrid modeling.\nSuccessively, some illustrative examples are presented to demonstrate how to\nachieve hybrid modeling for SAR image understanding. The perspective of\ntrustworthy model and supplementary explanations are discussed later. Finally,\nwe draw the conclusion and we deem the proposed concept has applicability to\nthe entire class of coherent imaging sensors and other computational imaging\nsystems."
  },
  {
    "CAGR": -1.5833538043,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.053041632,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 1.5534070302,
    "rnd_investment_required_log": -1.027440103,
    "title": "Enabling Listening Suspension in the Time Slotted Channel Hopping Protocol",
    "abstract": "Time slotted channel hopping provides reliable and deterministic\ncommunication in IEEE 802.15.4 mesh networks. Although slotted access is able\nto lower energy consumption drastically by reducing the duty cycle of the radio\nmodule, it usually leads to significant idle listening experienced by\nreceivers, which makes it a sub-optimal solution when ultra low-power wireless\nis sought for. In this paper a listening suspension mechanism is described,\nwhich operates at the MAC layer and is part of a more general approach aimed at\ncutting down energy consumption by proactively reducing idle listening. Links\ncan be temporarily disabled, that convey slow-rate data streams whose\ncharacteristics, e.g., the generation period, are either known in advance to\nsome extent or can be inferred by traffic inspection."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 1.2607533636,
    "rnd_investment_required_log": -0.3373958805,
    "title": "WKB Across Caustics: The Screened-WKB Method",
    "abstract": "We present a new methodology, based on the WKB approximation and Fast Fourier\nTransforms, for the evaluation of wave propagation through inhomogeneous media.\nThis method can accurately resolve fields containing caustics, while still\nenjoying the computational advantages of the WKB approximation, namely, the\nability to resolve arbitrarily high-frequency problems in computing times which\nare orders-of-magnitude shorter than those required by other algorithms\npresently available. For example, the proposed approach can simulate with high\naccuracy (with errors such as e.g. 0.1\\%--0.001\\%) the propagation of 5 cm\nradar signals across two-dimensional configurations resembling atmospheric\nducting conditions, spanning hundreds of kilometers and millions of wavelengths\nin electrical size, in computing times of a few minutes in a single CPU core.\n[Preliminary version]"
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -1.7270042027,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.0817321758,
    "ROI_percent": 0.9204663698,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.692474134,
    "title": "Dynamic Grained Encoder for Vision Transformers",
    "abstract": "Transformers, the de-facto standard for language modeling, have been recently\napplied for vision tasks. This paper introduces sparse queries for vision\ntransformers to exploit the intrinsic spatial redundancy of natural images and\nsave computational costs. Specifically, we propose a Dynamic Grained Encoder\nfor vision transformers, which can adaptively assign a suitable number of\nqueries to each spatial region. Thus it achieves a fine-grained representation\nin discriminative regions while keeping high efficiency. Besides, the dynamic\ngrained encoder is compatible with most vision transformer frameworks. Without\nbells and whistles, our encoder allows the state-of-the-art vision transformers\nto reduce computational complexity by 40%-60% while maintaining comparable\nperformance on image classification. Extensive experiments on object detection\nand segmentation further demonstrate the generalizability of our approach. Code\nis available at https:\/\/github.com\/StevenGrove\/vtpack."
  },
  {
    "CAGR": 1.4545947092,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.5923303378,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Video Semantic Segmentation with Inter-Frame Feature Fusion and Inner-Frame Feature Refinement",
    "abstract": "Video semantic segmentation aims to generate accurate semantic maps for each\nvideo frame. To this end, many works dedicate to integrate diverse information\nfrom consecutive frames to enhance the features for prediction, where a feature\nalignment procedure via estimated optical flow is usually required. However,\nthe optical flow would inevitably suffer from inaccuracy, and then introduce\nnoises in feature fusion and further result in unsatisfactory segmentation\nresults. In this paper, to tackle the misalignment issue, we propose a\nspatial-temporal fusion (STF) module to model dense pairwise relationships\namong multi-frame features. Different from previous methods, STF uniformly and\nadaptively fuses features at different spatial and temporal positions, and\navoids error-prone optical flow estimation. Besides, we further exploit feature\nrefinement within a single frame and propose a novel memory-augmented\nrefinement (MAR) module to tackle difficult predictions among semantic\nboundaries. Specifically, MAR can store the boundary features and prototypes\nextracted from the training samples, which together form the task-specific\nmemory, and then use them to refine the features during inference. Essentially,\nMAR can move the hard features closer to the most likely category and thus make\nthem more discriminative. We conduct extensive experiments on Cityscapes and\nCamVid, and the results show that our proposed methods significantly outperform\nprevious methods and achieves the state-of-the-art performance. Code and\npretrained models are available at https:\/\/github.com\/jfzhuang\/ST_Memory."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 2.3858924402,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Apodized photonic crystals: A non-dissipative system hosting multiple exceptional points",
    "abstract": "Optical systems obeying non-Hermitian dynamics have been the subject of\nintense and concerted investigation over the last two decades owing to their\nbroad implications in photonics, acoustics, electronics as well as atomic\nphysics. A vast majority of such investigations rely on a dissipative, balanced\nloss-gain system which introduces unavoidable noise and consequently, this\nlimits the coherent control of propagation dynamics. Here, we show that an\nall-dielectric, non-dissipative photonic crystal (PC) could host, at least two\nexceptional points in its eigenvalue spectrum. By introducing optimum\napodization in the PC architecture, namely 1D-APC, we show that such a\nconfiguration supports a spectrum of exceptional points which distinctly\ndemarcates the PT-symmetric region from the region where PT -symmetry is broken\nin the parameter space. The analytical framework allows us to estimate the\ngeometric phase of the reflected beam and derive the constraint that governs\nthe excitation of topologically-protected optical Tamm-plasmon modes in\n1D-APCs."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.2737660429,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Deep Reinforcement Learning for Autonomous Ground Vehicle Exploration Without A-Priori Maps",
    "abstract": "Autonomous Ground Vehicles (AGVs) are essential tools for a wide range of\napplications stemming from their ability to operate in hazardous environments\nwith minimal human operator input. Effective motion planning is paramount for\nsuccessful operation of AGVs. Conventional motion planning algorithms are\ndependent on prior knowledge of environment characteristics and offer limited\nutility in information poor, dynamically altering environments such as areas\nwhere emergency hazards like fire and earthquake occur, and unexplored\nsubterranean environments such as tunnels and lava tubes on Mars. We propose a\nDeep Reinforcement Learning (DRL) framework for intelligent AGV exploration\nwithout a-priori maps utilizing Actor-Critic DRL algorithms to learn policies\nin continuous and high-dimensional action spaces directly from raw sensor data.\nThe DRL architecture comprises feedforward neural networks for the critic and\nactor representations in which the actor network strategizes linear and angular\nvelocity control actions given current state inputs, that are evaluated by the\ncritic network which learns and estimates Q-values to maximize an accumulated\nreward. Three off-policy DRL algorithms, DDPG, TD3 and SAC, are trained and\ncompared in two environments of varying complexity, and further evaluated in a\nthird with no prior training or knowledge of map characteristics. The agent is\nshown to learn optimal policies at the end of each training period to chart\nquick, collision-free exploration trajectories, and is extensible, capable of\nadapting to an unknown environment without changes to network architecture or\nhyperparameters. The best algorithm is further evaluated in a realistic 3D\nenvironment."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 1.281893344,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Proactive and Automatic Underfrequency Load Shedding via PMUs and Particle Filters",
    "abstract": "Underfrequency (UF) load shedding schemes are traditionally implemented in\ntwo ways: One approach is based on manual load shedding, with system operators\nrequesting loads to be shed ahead of anticipated stressful operating\nconditions. Manual load shedding is usually done through phone calls. The\nsecond method is automatic load shedding via underfrequency relays. Using\nstatic settings, these schemes can be designed to operate in stages and drop\npreviously identified loads. The main limitation of traditional load shedding\nschemes is that they are reactive and leave little room for optimized\ncorrective actions. This work presents a proactive and automatic underfrequency\nload shedding solution for power systems. Measurements are captured via phasor\nmeasurement units (PMUs) at relatively low sampling rates of 30 Hz. These\nmeasurements are then processed by particle filters who predict the future\nstate of the system's frequency. Based on these predictions excess load is\ndetermined and shed. Comparative case studies are performed in simulated\nenvironments. Easy-to-implement models, without hard-to-derive parameters,\nhighlight potential aspects for real-life implementation."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.8278466905,
    "ROI_percent": -0.3083853421,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -0.1558904989,
    "title": "High-Impedance Non-Linear Fault Detection via Eigenvalue Analysis with low PMU Sampling Rates",
    "abstract": "This technique holds several advantages over contemporary techniques: It\nutilizes technology that is already deployed in the field, it offers a\nsignificant degree of generality, and so far it has displayed a very high-level\nof sensitivity without sacrificing accuracy. Validation is performed in the\nform of simulations based in the IEEE 13 Node System and non-linear fault\nmodels. Test results are encouraging, indicating potential for real-life\napplications."
  },
  {
    "CAGR": -0.4510275401,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Continuous Scatterplot Operators for Bivariate Analysis and Study of Electronic Transitions",
    "abstract": "Electronic transitions in molecules due to the absorption or emission of\nlight is a complex quantum mechanical process. Their study plays an important\nrole in the design of novel materials. A common yet challenging task in the\nstudy is to determine the nature of electronic transitions, namely which\nsubgroups of the molecule are involved in the transition by donating or\naccepting electrons, followed by an investigation of the variation in the\ndonor-acceptor behavior for different transitions or conformations of the\nmolecules. In this paper, we present a novel approach for the analysis of a\nbivariate field and show its applicability to the study of electronic\ntransitions. This approach is based on two novel operators, the continuous\nscatterplot (CSP) lens operator and the CSP peel operator, that enable\neffective visual analysis of bivariate fields. Both operators can be applied\nindependently or together to facilitate analysis. The operators motivate the\ndesign of control polygon inputs to extract fiber surfaces of interest in the\nspatial domain. The CSPs are annotated with a quantitative measure to further\nsupport the visual analysis. We study different molecular systems and\ndemonstrate how the CSP peel and CSP lens operators help identify and study\ndonor and acceptor characteristics in molecular systems."
  },
  {
    "CAGR": -0.9481463878,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -2.1424131503,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.3526483917,
    "title": "A newly-designed femtosecond KBe$_2$BO$_3$F$_2$ device with pulse duration down to 55 fs for time- and angle-resolved photoemission spectroscopy",
    "abstract": "Developing a widely tunable vacuum ultraviolet (VUV) source with sub-100\nfemtoseconds (fs) pulse duration is critical for ultrafast pump-probe\ntechniques such as time- and angle-resolved photoemission spectroscopy\n(TrARPES). While a tunable probe source with photon energy of 5.3 - 7.0 eV has\nbeen recently implemented for TrARPES by using a KBe$_2$BO$_3$F$_2$ (KBBF)\ndevice, the time resolution of 280 - 320 fs is still not ideal, which is mainly\nlimited by the duration of the VUV probe pulse generated by the KBBF device.\nHere, by designing a new KBBF device which is specially optimized for fs\napplications, an optimum pulse duration of 55 fs is obtained after systematic\ndiagnostics and optimization. More importantly, a high time resolution of 81 -\n95 fs is achieved for TrARPES measurements covering the probe photon energy\nrange of 5.3 - 7.0 eV, making it particularly useful for investigating the\nultrafast dynamics of quantum materials. Our work extends the application of\nKBBF device to ultrafast pump-probe techniques with the advantages of both\nwidely tunable VUV source and ultimate time resolution."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.1799051383,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": -0.0791806145,
    "rnd_investment_required_log": -1.2495847072,
    "title": "Uncertain Quality-Diversity: Evaluation methodology and new methods for Quality-Diversity in Uncertain Domains",
    "abstract": "Quality-Diversity optimisation (QD) has proven to yield promising results\nacross a broad set of applications. However, QD approaches struggle in the\npresence of uncertainty in the environment, as it impacts their ability to\nquantify the true performance and novelty of solutions. This problem has been\nhighlighted multiple times independently in previous literature. In this work,\nwe propose to uniformise the view on this problem through four main\ncontributions. First, we formalise a common framework for uncertain domains:\nthe Uncertain QD setting, a special case of QD in which fitness and descriptors\nfor each solution are no longer fixed values but distribution over possible\nvalues. Second, we propose a new methodology to evaluate Uncertain QD\napproaches, relying on a new per-generation sampling budget and a set of\nexisting and new metrics specifically designed for Uncertain QD. Third, we\npropose three new Uncertain QD algorithms: Archive-sampling,\nParallel-Adaptive-sampling and Deep-Grid-sampling. We propose these approaches\ntaking into account recent advances in the QD community toward the use of\nhardware acceleration that enable large numbers of parallel evaluations and\nmake sampling an affordable approach to uncertainty. Our final and fourth\ncontribution is to use this new framework and the associated comparison methods\nto benchmark existing and novel approaches. We demonstrate once again the\nlimitation of MAP-Elites in uncertain domains and highlight the performance of\nthe existing Deep-Grid approach, and of our new algorithms. The goal of this\nframework and methods is to become an instrumental benchmark for future works\nconsidering Uncertain QD."
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.6488403974,
    "ROI_percent": -0.742097711,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.7611435848,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Upper-limb Geometric MyoPassivity Map for Physical Human-Robot Interaction",
    "abstract": "The intrinsic biomechanical characteristic of the human upper limb plays a\ncentral role in absorbing the interactive energy during physical human-robot\ninteraction (pHRI). We have recently shown that based on the concept of\n``Excess of Passivity (EoP),\" from nonlinear control theory, it is possible to\ndecode such energetic behavior for both upper and lower limbs. The extracted\nknowledge can be used in the design of controllers for optimizing the\ntransparency and fidelity of force fields in human-robot interaction and in\nhaptic systems. In this paper, for the first time, we investigate the frequency\nbehavior of the passivity map for the upper limb when the muscle co-activation\nwas controlled in real-time through visual electromyographic feedback. Five\nhealthy subjects (age: 27 +\/- 5) were included in this study. The energetic\nbehavior was evaluated at two stimulation frequencies at eight interaction\ndirections over two controlled muscle co-activation levels. Electromyography\n(EMG) was captured using the Delsys Wireless Trigno system. Results showed a\ncorrelation between EMG and EoP, which was further altered by increasing the\nfrequency. The proposed energetic behavior is named the Geometric MyoPassivity\n(GMP) map. The findings indicate that the GMP map has the potential to be used\nin real-time to quantify the absorbable energy, thus passivity margin of\nstability for upper limb interaction during pHRI."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.2561485476,
    "ROI_percent": 0.053041632,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Towards Implementing Energy-aware Data-driven Intelligence for Smart Health Applications on Mobile Platforms",
    "abstract": "Recent breakthrough technological progressions of powerful mobile computing\nresources such as low-cost mobile GPUs along with cutting-edge, open-source\nsoftware architectures have enabled high-performance deep learning on mobile\nplatforms. These advancements have revolutionized the capabilities of today's\nmobile applications in different dimensions to perform data-driven intelligence\nlocally, particularly for smart health applications. Unlike traditional machine\nlearning (ML) architectures, modern on-device deep learning frameworks are\nproficient in utilizing computing resources in mobile platforms seamlessly, in\nterms of producing highly accurate results in less inference time. However, on\nthe flip side, energy resources in a mobile device are typically limited.\nHence, whenever a complex Deep Neural Network (DNN) architecture is fed into\nthe on-device deep learning framework, while it achieves high prediction\naccuracy (and performance), it also urges huge energy demands during the\nruntime. Therefore, managing these resources efficiently within the spectrum of\nperformance and energy efficiency is the newest challenge for any mobile\napplication featuring data-driven intelligence beyond experimental evaluations.\nIn this paper, first, we provide a timely review of recent advancements in\non-device deep learning while empirically evaluating the performance metrics of\ncurrent state-of-the-art ML architectures and conventional ML approaches with\nthe emphasis given on energy characteristics by deploying them on a smart\nhealth application. With that, we are introducing a new framework through an\nenergy-aware, adaptive model comprehension and realization (EAMCR) approach\nthat can be utilized to make more robust and efficient inference decisions\nbased on the available computing\/energy resources in the mobile device during\nthe runtime."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.5073055989,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.1981394181,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Quantum-inspired classical algorithm for graph problems by Gaussian boson sampling",
    "abstract": "We present a quantum-inspired classical algorithm that can be used for\ngraph-theoretical problems, such as finding the densest $k$-subgraph and\nfinding the maximum weight clique, which are proposed as applications of a\nGaussian boson sampler. The main observation from Gaussian boson samplers is\nthat a given graph's adjacency matrix to be encoded in a Gaussian boson sampler\nis nonnegative, which does not necessitate quantum interference. We first\nprovide how to program a given graph problem into our efficient classical\nalgorithm. We then numerically compare the performance of ideal and lossy\nGaussian boson samplers, our quantum-inspired classical sampler, and the\nuniform sampler for finding the densest $k$-subgraph and finding the maximum\nweight clique and show that the advantage from Gaussian boson samplers is not\nsignificant in general. We finally discuss the potential advantage of a\nGaussian boson sampler over the proposed sampler."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8572985792,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -1.5504097469,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Epic-Sounds: A Large-scale Dataset of Actions That Sound",
    "abstract": "We introduce Epic-Sounds, a large-scale dataset of audio annotations\ncapturing temporal extents and class labels within the audio stream of the\negocentric videos. We propose an annotation pipeline where annotators\ntemporally label distinguishable audio segments and describe the action that\ncould have caused this sound. We identify actions that can be discriminated\npurely from audio, through grouping these free-form descriptions of audio into\nclasses. For actions that involve objects colliding, we collect human\nannotations of the materials of these objects (e.g. a glass object being placed\non a wooden surface), which we verify from video, discarding ambiguities.\nOverall, Epic-Sounds includes 78.4k categorised segments of audible events and\nactions, distributed across 44 classes as well as 39.2k non-categorised\nsegments. We train and evaluate state-of-the-art audio recognition and\ndetection models on our dataset, for both audio-only and audio-visual methods.\nWe also conduct analysis on: the temporal overlap between audio events, the\ntemporal and label correlations between audio and visual modalities, the\nambiguities in annotating materials from audio-only input, the importance of\naudio-only labels and the limitations of current models to understand actions\nthat sound. Project page : https:\/\/epic-kitchens.github.io\/epic-sounds\/"
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.8143831059,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.0271308869,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 2.1484856106,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": -0.3373958805,
    "title": "QMP: Q-switch Mixture of Policies for Multi-Task Behavior Sharing",
    "abstract": "Multi-task reinforcement learning (MTRL) aims to learn several tasks\nsimultaneously for better sample efficiency than learning them separately.\nTraditional methods achieve this by sharing parameters or relabeled data\nbetween tasks. In this work, we introduce a new framework for sharing\nbehavioral policies across tasks, which can be used in addition to existing\nMTRL methods. The key idea is to improve each task's off-policy data collection\nby employing behaviors from other task policies. Selectively sharing helpful\nbehaviors acquired in one task to collect training data for another task can\nlead to higher-quality trajectories, leading to more sample-efficient MTRL.\nThus, we introduce a simple and principled framework called Q-switch mixture of\npolicies (QMP) that selectively shares behavior between different task policies\nby using the task's Q-function to evaluate and select useful shareable\nbehaviors. We theoretically analyze how QMP improves the sample efficiency of\nthe underlying RL algorithm. Our experiments show that QMP's behavioral policy\nsharing provides complementary gains over many popular MTRL algorithms and\noutperforms alternative ways to share behaviors in various manipulation,\nlocomotion, and navigation environments. Videos are available at\nhttps:\/\/qmp-mtrl.github.io."
  },
  {
    "CAGR": 2.0069489844,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.8624035732,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.7327369984,
    "title": "SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis",
    "abstract": "For the deployment of artificial intelligence (AI) in high-risk settings,\nsuch as healthcare, methods that provide interpretability\/explainability or\nallow fine-grained error analysis are critical. Many recent methods for\ninterpretability\/explainability and fine-grained error analysis use concepts,\nwhich are meta-labels that are semantically meaningful to humans. However,\nthere are only a few datasets that include concept-level meta-labels and most\nof these meta-labels are relevant for natural images that do not require domain\nexpertise. Densely annotated datasets in medicine focused on meta-labels that\nare relevant to a single disease such as melanoma. In dermatology, skin disease\nis described using an established clinical lexicon that allows clinicians to\ndescribe physical exam findings to one another. To provide a medical dataset\ndensely annotated by domain experts with annotations useful across multiple\ndisease processes, we developed SkinCon: a skin disease dataset densely\nannotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick\n17k dataset densely annotated with 48 clinical concepts, 22 of which have at\nleast 50 images representing the concept. The concepts used were chosen by two\ndermatologists considering the clinical descriptor terms used to describe skin\nlesions. Examples include \"plaque\", \"scale\", and \"erosion\". The same concepts\nwere also used to label 656 skin disease images from the Diverse Dermatology\nImages dataset, providing an additional external dataset with diverse skin tone\nrepresentations. We review the potential applications for the SkinCon dataset,\nsuch as probing models, concept-based explanations, and concept bottlenecks.\nFurthermore, we use SkinCon to demonstrate two of these use cases: debugging\nmistakes of an existing dermatology AI model with concepts and developing\ninterpretable models with post-hoc concept bottleneck models."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.5871850202,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.9396287803,
    "title": "The Contextual Lasso: Sparse Linear Models via Deep Neural Networks",
    "abstract": "Sparse linear models are one of several core tools for interpretable machine\nlearning, a field of emerging importance as predictive models permeate\ndecision-making in many domains. Unfortunately, sparse linear models are far\nless flexible as functions of their input features than black-box models like\ndeep neural networks. With this capability gap in mind, we study a not-uncommon\nsituation where the input features dichotomize into two groups: explanatory\nfeatures, which are candidates for inclusion as variables in an interpretable\nmodel, and contextual features, which select from the candidate variables and\ndetermine their effects. This dichotomy leads us to the contextual lasso, a new\nstatistical estimator that fits a sparse linear model to the explanatory\nfeatures such that the sparsity pattern and coefficients vary as a function of\nthe contextual features. The fitting process learns this function\nnonparametrically via a deep neural network. To attain sparse coefficients, we\ntrain the network with a novel lasso regularizer in the form of a projection\nlayer that maps the network's output onto the space of $\\ell_1$-constrained\nlinear models. An extensive suite of experiments on real and synthetic data\nsuggests that the learned models, which remain highly transparent, can be\nsparser than the regular lasso without sacrificing the predictive power of a\nstandard deep neural network."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": -0.1558904989,
    "title": "AOP-Net: All-in-One Perception Network for Joint LiDAR-based 3D Object Detection and Panoptic Segmentation",
    "abstract": "LiDAR-based 3D object detection and panoptic segmentation are two crucial\ntasks in the perception systems of autonomous vehicles and robots. In this\npaper, we propose All-in-One Perception Network (AOP-Net), a LiDAR-based\nmulti-task framework that combines 3D object detection and panoptic\nsegmentation. In this method, a dual-task 3D backbone is developed to extract\nboth panoptic- and detection-level features from the input LiDAR point cloud.\nAlso, a new 2D backbone that intertwines Multi-Layer Perceptron (MLP) and\nconvolution layers is designed to further improve the detection task\nperformance. Finally, a novel module is proposed to guide the detection head by\nrecovering useful features discarded during down-sampling operations in the 3D\nbackbone. This module leverages estimated instance segmentation masks to\nrecover detailed information from each candidate object. The AOP-Net achieves\nstate-of-the-art performance for published works on the nuScenes benchmark for\nboth 3D object detection and panoptic segmentation tasks. Also, experiments\nshow that our method easily adapts to and significantly improves the\nperformance of any BEV-based 3D object detection method."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -2.1424131503,
    "annual_revenue_USD_log": -1.458968291,
    "rnd_investment_required_log": -1.535978894,
    "title": "Visual Realism Assessment for Face-swap Videos",
    "abstract": "Deep-learning based face-swap videos, also known as deep fakes, are becoming\nmore and more realistic and deceiving. The malicious usage of these face-swap\nvideos has caused wide concerns. The research community has been focusing on\nthe automatic detection of these fake videos, but the assessment of their\nvisual realism, as perceived by human eyes, is still an unexplored dimension.\nVisual realism assessment, or VRA, is essential for assessing the potential\nimpact that may be brought by a specific face-swap video, and it is also\nimportant as a quality assessment metric to compare different face-swap\nmethods. In this paper, we make a small step towards this new VRA direction by\nbuilding a benchmark for evaluating the effectiveness of different automatic\nVRA models, which range from using traditional hand-crafted features to\ndifferent kinds of deep-learning features. The evaluations are based on a\nrecent competition dataset named DFGC 2022, which contains 1400 diverse\nface-swap videos that are annotated with Mean Opinion Scores (MOS) on visual\nrealism. Comprehensive experiment results using 11 models and 3 protocols are\nshown and discussed. We demonstrate the feasibility of devising effective VRA\nmodels for assessing face-swap videos and methods. The particular usefulness of\nexisting deepfake detection features for VRA is also noted. The code can be\nfound at https:\/\/github.com\/XianyunSun\/VRA.git."
  },
  {
    "CAGR": -0.7548223915,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.9786301475,
    "annual_revenue_USD_log": -0.1981394181,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Explainable Human-Robot Training and Cooperation with Augmented Reality",
    "abstract": "The current spread of social and assistive robotics applications is\nincreasingly highlighting the need for robots that can be easily taught and\ninteracted with, even by users with no technical background. Still, it is often\ndifficult to grasp what such robots know or to assess if a correct\nrepresentation of the task is being formed. Augmented Reality (AR) has the\npotential to bridge this gap. We demonstrate three use cases where AR design\nelements enhance the explainability and efficiency of human-robot interaction:\n1) a human teaching a robot some simple kitchen tasks by demonstration, 2) the\nrobot showing its plan for solving novel tasks in AR to a human for validation,\nand 3) a robot communicating its intentions via AR while assisting people with\nlimited mobility during daily activities."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.7585345313,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Randomized prior wavelet neural operator for uncertainty quantification",
    "abstract": "In this paper, we propose a novel data-driven operator learning framework\nreferred to as the \\textit{Randomized Prior Wavelet Neural Operator} (RP-WNO).\nThe proposed RP-WNO is an extension of the recently proposed wavelet neural\noperator, which boasts excellent generalizing capabilities but cannot estimate\nthe uncertainty associated with its predictions. RP-WNO, unlike the vanilla\nWNO, comes with inherent uncertainty quantification module and hence, is\nexpected to be extremely useful for scientists and engineers alike. RP-WNO\nutilizes randomized prior networks, which can account for prior information and\nis easier to implement for large, complex deep-learning architectures than its\nBayesian counterpart. Four examples have been solved to test the proposed\nframework, and the results produced advocate favorably for the efficacy of the\nproposed framework."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.027440103,
    "title": "Site-specific Deep Learning Path Loss Models based on the Method of Moments",
    "abstract": "This paper describes deep learning models based on convolutional neural\nnetworks applied to the problem of predicting EM wave propagation over rural\nterrain. A surface integral equation formulation, solved with the method of\nmoments and accelerated using the Fast Far Field approximation, is used to\ngenerate synthetic training data which comprises path loss computed over\nrandomly generated 1D terrain profiles. These are used to train two networks,\none based on fractal profiles and one based on profiles generated using a\nGaussian process. The models show excellent agreement when applied to test\nprofiles generated using the same statistical process used to create the\ntraining data and very good accuracy when applied to real life problems."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 2.1709094741,
    "rnd_investment_required_log": -1.027440103,
    "title": "Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial Defense",
    "abstract": "Recent advancements in masked image modeling (MIM) have made it a prevailing\nframework for self-supervised visual representation learning. The MIM\npretrained models, like most deep neural network methods, remain vulnerable to\nadversarial attacks, limiting their practical application, and this issue has\nreceived little research attention. In this paper, we investigate how this\npowerful self-supervised learning paradigm can provide adversarial robustness\nto downstream classifiers. During the exploration, we find that noisy image\nmodeling (NIM), a simple variant of MIM that adopts denoising as the pre-text\ntask, reconstructs noisy images surprisingly well despite severe corruption.\nMotivated by this observation, we propose an adversarial defense method,\nreferred to as De^3, by exploiting the pretrained decoder for denoising.\nThrough De^3, NIM is able to enhance adversarial robustness beyond providing\npretrained features. Furthermore, we incorporate a simple modification,\nsampling the noise scale hyperparameter from random distributions, and enable\nthe defense to achieve a better and tunable trade-off between accuracy and\nrobustness. Experimental results demonstrate that, in terms of adversarial\nrobustness, NIM is superior to MIM thanks to its effective denoising\ncapability. Moreover, the defense provided by NIM achieves performance on par\nwith adversarial training while offering the extra tunability advantage. Source\ncode and models are available at https:\/\/github.com\/youzunzhi\/NIM-AdvDef."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.3469684869,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 2.1363870464,
    "title": "Using k-means assistant event selection strategy to study anomalous quartic gauge couplings at muon colliders",
    "abstract": "The search for new physics beyond the Standard Model is one of the central\nproblems of current high energy physics interest. As the luminosities of\ncurrent and near-future colliders continue to increase, the search for new\nphysics has increased the requirements for processing large amounts of data.\nMeanwhile, quantum computing which is rapidly evolving, has great potential to\nbecome a powerful tool to help search for new physics signals. Since the\nk-means algorithm is known to be able to be accelerated with the help of\nquantum computing, we investigate and propose an event selection strategy based\non k-means algorithm to search for new physics signals. Taking the case of\ntri-photon processes at the muon colliders as an example, the event selection\nstrategy is shown to be effective in helping to search for the signals of\ndimension-8 operators contributing to anomalous quartic gauge couplings.\nCompared with traditional event selection strategy, the expected constraints\nare generally tighter."
  },
  {
    "CAGR": -1.5833538043,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.7493083205,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 1.6546111698,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": 0.0662541385,
    "title": "SPADE: Self-supervised Pretraining for Acoustic DisEntanglement",
    "abstract": "Self-supervised representation learning approaches have grown in popularity\ndue to the ability to train models on large amounts of unlabeled data and have\ndemonstrated success in diverse fields such as natural language processing,\ncomputer vision, and speech. Previous self-supervised work in the speech domain\nhas disentangled multiple attributes of speech such as linguistic content,\nspeaker identity, and rhythm. In this work, we introduce a self-supervised\napproach to disentangle room acoustics from speech and use the acoustic\nrepresentation on the downstream task of device arbitration. Our results\ndemonstrate that our proposed approach significantly improves performance over\na baseline when labeled training data is scarce, indicating that our\npretraining scheme learns to encode room acoustic information while remaining\ninvariant to other attributes of the speech signal."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.2476060596,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": -0.5595405096,
    "title": "LazyGNN: Large-Scale Graph Neural Networks via Lazy Propagation",
    "abstract": "Recent works have demonstrated the benefits of capturing long-distance\ndependency in graphs by deeper graph neural networks (GNNs). But deeper GNNs\nsuffer from the long-lasting scalability challenge due to the neighborhood\nexplosion problem in large-scale graphs. In this work, we propose to capture\nlong-distance dependency in graphs by shallower models instead of deeper\nmodels, which leads to a much more efficient model, LazyGNN, for graph\nrepresentation learning. Moreover, we demonstrate that LazyGNN is compatible\nwith existing scalable approaches (such as sampling methods) for further\naccelerations through the development of mini-batch LazyGNN. Comprehensive\nexperiments demonstrate its superior prediction performance and scalability on\nlarge-scale benchmarks. The implementation of LazyGNN is available at\nhttps:\/\/github.com\/RXPHD\/Lazy_GNN."
  },
  {
    "CAGR": 2.5593032596,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.6546111698,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Lateralization in Agents' Decision Making: Evidence of Benefits\/Costs from Artificial Intelligence",
    "abstract": "Lateralization is ubiquitous in vertebrate brains which, as well as its role\nin locomotion, is considered an important factor in biological intelligence.\nLateralization has been associated with both poor and good performance. It has\nbeen hypothesized that lateralization has benefits that may counterbalance its\ncosts. Given that lateralization is ubiquitous, it likely has advantages that\ncan benefit artificial intelligence. In turn, lateralized artificial\nintelligent systems can be used as tools to advance the understanding of\nlateralization in biological intelligence. Recently lateralization has been\nincorporated into artificially intelligent systems to solve complex problems in\ncomputer vision and navigation domains. Here we describe and test two novel\nlateralized artificial intelligent systems that simultaneously represent and\naddress given problems at constituent and holistic levels. The experimental\nresults demonstrate that the lateralized systems outperformed state-of-the-art\nnon-lateralized systems in resolving complex problems. The advantages arise\nfrom the abilities, (i) to represent an input signal at both the constituent\nlevel and holistic level simultaneously, such that the most appropriate\nviewpoint controls the system; (ii) to avoid extraneous computations by\ngenerating excite and inhibit signals. The computational costs associated with\nthe lateralized AI systems are either less than the conventional AI systems or\ncountered by providing better solutions."
  },
  {
    "CAGR": 1.8688604156,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": 0.053041632,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.5871850202,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -1.6319355937,
    "rnd_investment_required_log": -1.535978894,
    "title": "A geometrically aware auto-encoder for multi-texture synthesis",
    "abstract": "We propose an auto-encoder architecture for multi-texture synthesis. The\napproach relies on both a compact encoder accounting for second order neural\nstatistics and a generator incorporating adaptive periodic content. Images are\nembedded in a compact and geometrically consistent latent space, where the\ntexture representation and its spatial organisation are disentangled. Texture\nsynthesis and interpolation tasks can be performed directly from these latent\ncodes. Our experiments demonstrate that our model outperforms state-of-the-art\nfeed-forward methods in terms of visual quality and various texture related\nmetrics."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.0817321758,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Transcending shift-invariance in the paraxial regime via end-to-end inverse design of freeform nanophotonics",
    "abstract": "Traditional optical elements and conventional metasurfaces obey\nshift-invariance in the paraxial regime. For imaging systems obeying paraxial\nshift-invariance, a small shift in input angle causes a corresponding shift in\nthe sensor image. Shift-invariance has deep implications for the design and\nfunctionality of optical devices, such as the necessity of free space between\ncomponents (as in compound objectives made of several curved surfaces). We\npresent a method for nanophotonic inverse design of compact imaging systems\nwhose resolution is not constrained by paraxial shift-invariance. Our method is\nend-to-end, in that it integrates density-based full-Maxwell topology\noptimization with a fully iterative elastic-net reconstruction algorithm. By\nthe design of nanophotonic structures that scatter light in a\nnon-shift-invariant manner, our optimized nanophotonic imaging system overcomes\nthe limitations of paraxial shift-invariance, achieving accurate, noise-robust\nimage reconstruction beyond shift-invariant resolution."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.4991958469,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 0.447531913,
    "title": "IMPORTANT-Net: Integrated MRI Multi-Parameter Reinforcement Fusion Generator with Attention Network for Synthesizing Absent Data",
    "abstract": "Magnetic resonance imaging (MRI) is highly sensitive for lesion detection in\nthe breasts. Sequences obtained with different settings can capture the\nspecific characteristics of lesions. Such multi-parameter MRI information has\nbeen shown to improve radiologist performance in lesion classification, as well\nas improving the performance of artificial intelligence models in various\ntasks. However, obtaining multi-parameter MRI makes the examination costly in\nboth financial and time perspectives, and there may be safety concerns for\nspecial populations, thus making acquisition of the full spectrum of MRI\nsequences less durable. In this study, different than naive input fusion or\nfeature concatenation from existing MRI parameters, a novel\n$\\textbf{I}$ntegrated MRI $\\textbf{M}$ulti-$\\textbf{P}$arameter\nreinf$\\textbf{O}$rcement fusion generato$\\textbf{R}$ wi$\\textbf{T}$h\n$\\textbf{A}$tte$\\textbf{NT}$ion Network (IMPORTANT-Net) is developed to\ngenerate missing parameters. First, the parameter reconstruction module is used\nto encode and restore the existing MRI parameters to obtain the corresponding\nlatent representation information at any scale level. Then the multi-parameter\nfusion with attention module enables the interaction of the encoded information\nfrom different parameters through a set of algorithmic strategies, and applies\ndifferent weights to the information through the attention mechanism after\ninformation fusion to obtain refined representation information. Finally, a\nreinforcement fusion scheme embedded in a $V^{-}$-shape generation module is\nused to combine the hierarchical representations to generate the missing MRI\nparameter. Results showed that our IMPORTANT-Net is capable of generating\nmissing MRI parameters and outperforms comparable state-of-the-art networks.\nOur code is available at\nhttps:\/\/github.com\/Netherlands-Cancer-Institute\/MRI_IMPORTANT_NET."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -1.2480954748,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.8459347379,
    "title": "Nonconvex Distributed Feedback Optimization for Aggregative Cooperative Robotics",
    "abstract": "Distributed aggregative optimization is a recently emerged framework in which\nthe agents of a network want to minimize the sum of local objective functions,\neach one depending on the agent decision variable (e.g., the local position of\na team of robots) and an aggregation of all the agents' variables (e.g., the\nteam barycentre). In this paper, we address a distributed feedback optimization\nframework in which agents implement a local (distributed) policy to reach a\nsteady-state minimizing an aggregative cost function. We propose Aggregative\nTracking Feedback, i.e., a novel distributed feedback optimization law in which\neach agent combines a closed-loop gradient flow with a consensus-based dynamic\ncompensator reconstructing the missing global information. By using tools from\nsystem theory, we prove that Aggregative Tracking Feedback steers the network\nto a stationary point of an aggregative optimization problem with (possibly)\nnonconvex objective function. The effectiveness of the proposed method is\nvalidated through numerical simulations on a multi-robot surveillance scenario."
  },
  {
    "CAGR": 1.8688604156,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -3.0614283806,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Variational waveguide QED simulators",
    "abstract": "Waveguide QED simulators are analogue quantum simulators made by quantum\nemitters interacting with one-dimensional photonic band-gap materials. One of\ntheir remarkable features is that they can be used to engineer tunable-range\nemitter interactions. Here, we demonstrate how these interactions can be a\nresource to develop more efficient variational quantum algorithms for certain\nproblems. In particular, we illustrate their power in creating wavefunction\nans\\\"atze that capture accurately the ground state of quantum critical spin\nmodels (XXZ and Ising) with less gates and optimization parameters than other\nvariational ans\\\"atze based on nearest-neighbor or infinite-range entangling\ngates. Finally, we study the potential advantages of these waveguide ans\\\"atze\nin the presence of noise. Overall, these results evidence the potential of\nusing the interaction range as a variational parameter and place waveguide QED\nsimulators as a promising platform for variational quantum algorithms."
  },
  {
    "CAGR": -0.0643795475,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.6054785613,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.876511833,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.8000687688,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": -1.535978894,
    "title": "IoT Botnet Detection Using an Economic Deep Learning Model",
    "abstract": "The rapid progress in technology innovation usage and distribution has\nincreased in the last decade. The rapid growth of the Internet of Things (IoT)\nsystems worldwide has increased network security challenges created by\nmalicious third parties. Thus, reliable intrusion detection and network\nforensics systems that consider security concerns and IoT systems limitations\nare essential to protect such systems. IoT botnet attacks are one of the\nsignificant threats to enterprises and individuals. Thus, this paper proposed\nan economic deep learning-based model for detecting IoT botnet attacks along\nwith different types of attacks. The proposed model achieved higher accuracy\nthan the state-of-the-art detection models using a smaller implementation\nbudget and accelerating the training and detecting processes."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.5529623956,
    "ROI_percent": 2.9444574248,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.9097590502,
    "title": "Self-Supervised Transformer Architecture for Change Detection in Radio Access Networks",
    "abstract": "Radio Access Networks (RANs) for telecommunications represent large\nagglomerations of interconnected hardware consisting of hundreds of thousands\nof transmitting devices (cells). Such networks undergo frequent and often\nheterogeneous changes caused by network operators, who are seeking to tune\ntheir system parameters for optimal performance. The effects of such changes\nare challenging to predict and will become even more so with the adoption of\n5G\/6G networks. Therefore, RAN monitoring is vital for network operators. We\npropose a self-supervised learning framework that leverages self-attention and\nself-distillation for this task. It works by detecting changes in Performance\nMeasurement data, a collection of time-varying metrics which reflect a set of\ndiverse measurements of the network performance at the cell level. Experimental\nresults show that our approach outperforms the state of the art by 4% on a\nreal-world based dataset consisting of about hundred thousands timeseries. It\nalso has the merits of being scalable and generalizable. This allows it to\nprovide deep insight into the specifics of mode of operation changes while\nrelying minimally on expert knowledge."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.8121390165,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -1.027440103,
    "title": "Learning the Night Sky with Deep Generative Priors",
    "abstract": "Recovering sharper images from blurred observations, referred to as\ndeconvolution, is an ill-posed problem where classical approaches often produce\nunsatisfactory results. In ground-based astronomy, combining multiple exposures\nto achieve images with higher signal-to-noise ratios is complicated by the\nvariation of point-spread functions across exposures due to atmospheric\neffects. We develop an unsupervised multi-frame method for denoising,\ndeblurring, and coadding images inspired by deep generative priors. We use a\ncarefully chosen convolutional neural network architecture that combines\ninformation from multiple observations, regularizes the joint likelihood over\nthese observations, and allows us to impose desired constraints, such as\nnon-negativity of pixel values in the sharp, restored image. With an eye\ntowards the Rubin Observatory, we analyze 4K by 4K Hyper Suprime-Cam exposures\nand obtain preliminary results which yield promising restored images and\nextracted source lists."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 1.0846092731,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 0.2045195276,
    "rnd_investment_required_log": 1.1599484684,
    "title": "AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis",
    "abstract": "Can machines recording an audio-visual scene produce realistic, matching\naudio-visual experiences at novel positions and novel view directions? We\nanswer it by studying a new task -- real-world audio-visual scene synthesis --\nand a first-of-its-kind NeRF-based approach for multimodal learning.\nConcretely, given a video recording of an audio-visual scene, the task is to\nsynthesize new videos with spatial audios along arbitrary novel camera\ntrajectories in that scene. We propose an acoustic-aware audio generation\nmodule that integrates prior knowledge of audio propagation into NeRF, in which\nwe implicitly associate audio generation with the 3D geometry and material\nproperties of a visual environment. Furthermore, we present a coordinate\ntransformation module that expresses a view direction relative to the sound\nsource, enabling the model to learn sound source-centric acoustic fields. To\nfacilitate the study of this new task, we collect a high-quality Real-World\nAudio-Visual Scene (RWAVS) dataset. We demonstrate the advantages of our method\non this real-world dataset and the simulation-based SoundSpaces dataset."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": 1.3597208618,
    "title": "MOMA:Distill from Self-Supervised Teachers",
    "abstract": "Contrastive Learning and Masked Image Modelling have demonstrated exceptional\nperformance on self-supervised representation learning, where Momentum Contrast\n(i.e., MoCo) and Masked AutoEncoder (i.e., MAE) are the state-of-the-art,\nrespectively. In this work, we propose MOMA to distill from pre-trained MoCo\nand MAE in a self-supervised manner to collaborate the knowledge from both\nparadigms. We introduce three different mechanisms of knowledge transfer in the\npropsoed MOMA framework. : (1) Distill pre-trained MoCo to MAE. (2) Distill\npre-trained MAE to MoCo (3) Distill pre-trained MoCo and MAE to a random\ninitialized student. During the distillation, the teacher and the student are\nfed with original inputs and masked inputs, respectively. The learning is\nenabled by aligning the normalized representations from the teacher and the\nprojected representations from the student. This simple design leads to\nefficient computation with extremely high mask ratio and dramatically reduced\ntraining epochs, and does not require extra considerations on the distillation\ntarget. The experiments show MOMA delivers compact student models with\ncomparable performance to existing state-of-the-art methods, combining the\npower of both self-supervised learning paradigms. It presents competitive\nresults against different benchmarks in computer vision. We hope our method\nprovides an insight on transferring and adapting the knowledge from large-scale\npre-trained models in a computationally efficient way."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 2.084626897,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Concave Pro-rata Games",
    "abstract": "In this paper, we introduce a family of games called concave pro-rata games.\nIn such a game, players place their assets into a pool, and the pool pays out\nsome concave function of all assets placed into it. Each player then receives a\npro-rata share of the payout; i.e., each player receives an amount proportional\nto how much they placed in the pool. Such games appear in a number of practical\nscenarios, including as a simplified version of batched decentralized\nexchanges, such as those proposed by Penumbra. We show that this game has a\nnumber of interesting properties, including a symmetric pure equilibrium that\nis the unique equilibrium of this game, and we prove that its price of anarchy\nis $\\Omega(n)$ in the number of players. We also show some numerical results in\nthe iterated setting which suggest that players quickly converge to an\nequilibrium in iterated play."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.1799051383,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -2.9778732615,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Interaction Order Prediction for Temporal Graphs",
    "abstract": "Link prediction in graphs is a task that has been widely investigated. It has\nbeen applied in various domains such as knowledge graph completion,\ncontent\/item recommendation, social network recommendations and so on. The\ninitial focus of most research was on link prediction in static graphs.\nHowever, there has recently been abundant work on modeling temporal graphs, and\nconsequently one of the tasks that has been researched is link prediction in\ntemporal graphs. However, most of the existing work does not focus on the order\nof link formation, and only predicts the existence of links. In this study, we\naim to predict the order of node interactions."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.729673728,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.9391692981,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": 1.7930902346,
    "title": "CLiNet: Joint Detection of Road Network Centerlines in 2D and 3D",
    "abstract": "This work introduces a new approach for joint detection of centerlines based\non image data by localizing the features jointly in 2D and 3D. In contrast to\nexisting work that focuses on detection of visual cues, we explore feature\nextraction methods that are directly amenable to the urban driving task. To\ndevelop and evaluate our approach, a large urban driving dataset dubbed AV\nBreadcrumbs is automatically labeled by leveraging vector map representations\nand projective geometry to annotate over 900,000 images. Our results\ndemonstrate potential for dynamic scene modeling across various urban driving\nscenarios. Our model achieves an F1 score of 0.684 and an average normalized\ndepth error of 2.083. The code and data annotations are publicly available."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.9391417136,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.5173724297,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.692474134,
    "title": "Achieving Robust Generalization for Wireless Channel Estimation Neural Networks by Designed Training Data",
    "abstract": "In this paper, we propose a method to design the training data that can\nsupport robust generalization of trained neural networks to unseen channels.\nThe proposed design that improves the generalization is described and analysed.\nIt avoids the requirement of online training for previously unseen channels, as\nthis is a memory and processing intensive solution, especially for battery\npowered mobile terminals. To prove the validity of the proposed method, we use\nthe channels modelled by different standards and fading modelling for\nsimulation. We also use an attention-based structure and a convolutional neural\nnetwork to evaluate the generalization results achieved. Simulation results\nshow that the trained neural networks maintain almost identical performance on\nthe unseen channels."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.4091326364,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.018090997,
    "annual_revenue_USD_log": -0.1981394181,
    "rnd_investment_required_log": 1.5998033579,
    "title": "Contrast with Reconstruct: Contrastive 3D Representation Learning Guided by Generative Pretraining",
    "abstract": "Mainstream 3D representation learning approaches are built upon contrastive\nor generative modeling pretext tasks, where great improvements in performance\non various downstream tasks have been achieved. However, we find these two\nparadigms have different characteristics: (i) contrastive models are\ndata-hungry that suffer from a representation over-fitting issue; (ii)\ngenerative models have a data filling issue that shows inferior data scaling\ncapacity compared to contrastive models. This motivates us to learn 3D\nrepresentations by sharing the merits of both paradigms, which is non-trivial\ndue to the pattern difference between the two paradigms. In this paper, we\npropose Contrast with Reconstruct (ReCon) that unifies these two paradigms.\nReCon is trained to learn from both generative modeling teachers and\nsingle\/cross-modal contrastive teachers through ensemble distillation, where\nthe generative student guides the contrastive student. An encoder-decoder style\nReCon-block is proposed that transfers knowledge through cross attention with\nstop-gradient, which avoids pretraining over-fitting and pattern difference\nissues. ReCon achieves a new state-of-the-art in 3D representation learning,\ne.g., 91.26% accuracy on ScanObjectNN. Codes have been released at\nhttps:\/\/github.com\/qizekun\/ReCon."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.7121989407,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Bichromatic UV detection system for atomically-resolved imaging of ions",
    "abstract": "We present a compact and bichromatic imaging system, located outside of the\nvacuum chamber of a trapped ion apparatus, that collects the fluorescence of\n230.6 nm and 369.5 nm photons simultaneously on a shared EMCCD camera. The\nsystem contains two lens doublets, consisting of a sphere and an asphere. It\nprovides a numerical aperture of 0.45 and 0.40 at 230.6 nm and 369.5 nm,\nrespectively, and enables spatially resolved state detection with a large field\nof view of 300 $\\mu$m for long $^{115}$In$^+$\/$^{172}$Yb$^+$ Coulomb crystals.\nInstead of diffraction limited imaging for one wavelength, the focus in this\nsystem is on simultaneous single-ion resolved imaging of both species over a\nlarge field with special attention to the deep UV wavelength (230.6 nm) and the\nlow scattering rate of In$^+$ ions. The introduced concept is applicable to\nother dual-species applications."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.2388089157,
    "ROI_percent": 2.0047472922,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": 1.8499927794,
    "title": "Exploiting Partial Common Information Microstructure for Multi-Modal Brain Tumor Segmentation",
    "abstract": "Learning with multiple modalities is crucial for automated brain tumor\nsegmentation from magnetic resonance imaging data. Explicitly optimizing the\ncommon information shared among all modalities (e.g., by maximizing the total\ncorrelation) has been shown to achieve better feature representations and thus\nenhance the segmentation performance. However, existing approaches are\noblivious to partial common information shared by subsets of the modalities. In\nthis paper, we show that identifying such partial common information can\nsignificantly boost the discriminative power of image segmentation models. In\nparticular, we introduce a novel concept of partial common information mask\n(PCI-mask) to provide a fine-grained characterization of what partial common\ninformation is shared by which subsets of the modalities. By solving a masked\ncorrelation maximization and simultaneously learning an optimal PCI-mask, we\nidentify the latent microstructure of partial common information and leverage\nit in a self-attention module to selectively weight different feature\nrepresentations in multi-modal data. We implement our proposed framework on the\nstandard U-Net. Our experimental results on the Multi-modal Brain Tumor\nSegmentation Challenge (BraTS) datasets outperform those of state-of-the-art\nsegmentation baselines, with validation Dice similarity coefficients of 0.920,\n0.897, 0.837 for the whole tumor, tumor core, and enhancing tumor on\nBraTS-2020."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.8612254977,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -1.1372752271,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.6546111698,
    "annual_revenue_USD_log": 2.4706617266,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Mobile Cell-Free Massive MIMO: Challenges, Solutions, and Future Directions",
    "abstract": "Cell-free (CF) massive multiple-input multiple-output (MIMO) systems, which\nexploit many geographically distributed access points to coherently serve user\nequipments via spatial multiplexing on the same time-frequency resource, has\nbecome a vital component of the next-generation mobile communication networks.\nTheoretically, CF massive MIMO systems have many advantages, such as large\ncapacity, great coverage, and high reliability, but several obstacles must be\novercome. In this article, we study the paradigm of CF massive MIMO-aided\nmobile communications, including the main application scenarios and associated\ndeployment architectures. Furthermore, we thoroughly investigate the challenges\nof CF massive MIMO-aided mobile communications. We then exploit a novel\npredictor antenna, hierarchical cancellation, rate-splitting and dynamic\nclustering system for CF massive MIMO. Finally, several important research\ndirections regarding CF massive MIMO for mobile communications are presented to\nfacilitate further investigation."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -1.7270042027,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.0369520687,
    "annual_revenue_USD_log": 0.5603196712,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Cluster-aware Contrastive Learning for Unsupervised Out-of-distribution Detection",
    "abstract": "Unsupervised out-of-distribution (OOD) Detection aims to separate the samples\nfalling outside the distribution of training data without label information.\nAmong numerous branches, contrastive learning has shown its excellent\ncapability of learning discriminative representation in OOD detection. However,\nfor its limited vision, merely focusing on instance-level relationship between\naugmented samples, it lacks attention to the relationship between samples with\nsame semantics. Based on the classic contrastive learning, we propose\nCluster-aware Contrastive Learning (CCL) framework for unsupervised OOD\ndetection, which considers both instance-level and semantic-level information.\nSpecifically, we study a cooperation strategy of clustering and contrastive\nlearning to effectively extract the latent semantics and design a cluster-aware\ncontrastive loss function to enhance OOD discriminative ability. The loss\nfunction can simultaneously pay attention to the global and local relationships\nby treating both the cluster centers and the samples belonging to the same\ncluster as positive samples. We conducted sufficient experiments to verify the\neffectiveness of our framework and the model achieves significant improvement\non various image benchmarks."
  },
  {
    "CAGR": -1.0724260997,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.8551118345,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Effective Mid-Range Wireless Power Transfer with Compensated Radiation Loss",
    "abstract": "In conventional inductive wireless power devices, the energy is transferred\nvia only reactive near fields, which is equivalent to non-radiative F\\\"orster\nenergy transfer in optics. Radiation from transmitting and receiving coils is\nusually considered as a parasitic effect that reduces the power transfer\nefficiency. As long as the distance between the two antennas is small as\ncompared to the antenna size, conventional WPT devices offer rather high power\ntransfer efficiency, of the order of 80-90\\%. However, for larger distances,\nthe transfer efficiency dramatically drops, making such devices not practical.\nIn this paper, we develop a dynamic theory of wireless power transfer between\ntwo small loop antennas, clarify the role of far-field radiation, and find a\npossibility to realize efficient wireless power transfer at large distances\nutilizing the regime of radiation suppression due to optimized mutual dynamic\ninteractions between the transmitting and receiving antennas. The analytical\nresults have been validated by simulations and measurements, and they open a\npossibility to greatly expand the range of distances of compact wireless power\ntransfer devices. The developed theory can be applied also to coupling between\nantennas of different types and to energy transfer between nano-objects."
  },
  {
    "CAGR": 0.1427533057,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": -0.742097711,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.7885226597,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": -0.3373958805,
    "title": "INCREASE: Inductive Graph Representation Learning for Spatio-Temporal Kriging",
    "abstract": "Spatio-temporal kriging is an important problem in web and social\napplications, such as Web or Internet of Things, where things (e.g., sensors)\nconnected into a web often come with spatial and temporal properties. It aims\nto infer knowledge for (the things at) unobserved locations using the data from\n(the things at) observed locations during a given time period of interest. This\nproblem essentially requires \\emph{inductive learning}. Once trained, the model\nshould be able to perform kriging for different locations including newly given\nones, without retraining. However, it is challenging to perform accurate\nkriging results because of the heterogeneous spatial relations and diverse\ntemporal patterns. In this paper, we propose a novel inductive graph\nrepresentation learning model for spatio-temporal kriging. We first encode\nheterogeneous spatial relations between the unobserved and observed locations\nby their spatial proximity, functional similarity, and transition probability.\nBased on each relation, we accurately aggregate the information of most\ncorrelated observed locations to produce inductive representations for the\nunobserved locations, by jointly modeling their similarities and differences.\nThen, we design relation-aware gated recurrent unit (GRU) networks to\nadaptively capture the temporal correlations in the generated sequence\nrepresentations for each relation. Finally, we propose a multi-relation\nattention mechanism to dynamically fuse the complex spatio-temporal information\nat different time steps from multiple relations to compute the kriging output.\nExperimental results on three real-world datasets show that our proposed model\noutperforms state-of-the-art methods consistently, and the advantage is more\nsignificant when there are fewer observed locations. Our code is available at\nhttps:\/\/github.com\/zhengchuanpan\/INCREASE."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4155202482,
    "ROI_percent": -0.0192437628,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.4193630149,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Density of photonic states in aperiodic structures",
    "abstract": "Periodicity is usually assumed to be the necessary and sufficient condition\nfor the formation of band gaps, i.e., energy bands with a suppressed density of\nstates. Here, we check this premise by analyzing the band gap properties of\nthree structures that differ in the degree of periodicity and ordering. We\nconsider a photonic crystal, disordered lattice, and ordered but nonperiodic\nquasicrystalline structure. A real-space metric allows us to compare the degree\nof periodicity of these different structures. Using this metric, we reveal that\nthe disordered lattice and the ordered quasicrystal can be attributed to the\nsame group of material structures. We examine the density of their photonic\nstates both theoretically and experimentally. The analysis reveals that despite\ntheir dramatically different degrees of periodicity, the photonic crystal and\nthe quasicrystalline structure demonstrate an almost similar suppression of the\ndensity of states. Our results give new insight into the physical mechanisms\nresulting in the formation of band gaps."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Parameter Optimization of LLC-Converter with multiple operation points using Reinforcement Learning",
    "abstract": "The optimization of electrical circuits is a difficult and time-consuming\nprocess performed by experts, but also increasingly by sophisticated\nalgorithms. In this paper, a reinforcement learning (RL) approach is adapted to\noptimize a LLC converter at multiple operation points corresponding to\ndifferent output powers at high converter efficiency at different switching\nfrequencies. During a training period, the RL agent learns a problem specific\noptimization policy enabling optimizations for any objective and boundary\ncondition within a pre-defined range. The results show, that the trained RL\nagent is able to solve new optimization problems based on LLC converter\nsimulations using Fundamental Harmonic Approximation (FHA) within 50 tuning\nsteps for two operation points with power efficiencies greater than 90%.\nTherefore, this AI technique provides the potential to augment expert-driven\ndesign processes with data-driven strategy extraction in the field of power\nelectronics and beyond."
  },
  {
    "CAGR": -1.1000438135,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Effect of Transport Noise on Kelvin-Helmholtz instability",
    "abstract": "The effect of transport noise on a 2D fluid may depend on the space-scale of\nthe noise. We investigate numerically the dissipation properties of very\nsmall-scale transport noise. As a test problem we consider the Kelvin-Helmholtz\ninstability and we compare the inviscid case, the viscous one, both without\nnoise, and the inviscid case perturbed by transport noise. We observe a partial\nsimilarity with the viscous case, namely a delay of the instability."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.847481283,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -2.2878707487,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.535978894,
    "title": "ClArTTS: An Open-Source Classical Arabic Text-to-Speech Corpus",
    "abstract": "At present, Text-to-speech (TTS) systems that are trained with high-quality\ntranscribed speech data using end-to-end neural models can generate speech that\nis intelligible, natural, and closely resembles human speech. These models are\ntrained with relatively large single-speaker professionally recorded audio,\ntypically extracted from audiobooks. Meanwhile, due to the scarcity of freely\navailable speech corpora of this kind, a larger gap exists in Arabic TTS\nresearch and development. Most of the existing freely available Arabic speech\ncorpora are not suitable for TTS training as they contain multi-speaker casual\nspeech with variations in recording conditions and quality, whereas the corpus\ncurated for speech synthesis are generally small in size and not suitable for\ntraining state-of-the-art end-to-end models. In a move towards filling this gap\nin resources, we present a speech corpus for Classical Arabic Text-to-Speech\n(ClArTTS) to support the development of end-to-end TTS systems for Arabic. The\nspeech is extracted from a LibriVox audiobook, which is then processed,\nsegmented, and manually transcribed and annotated. The final ClArTTS corpus\ncontains about 12 hours of speech from a single male speaker sampled at 40100\nkHz. In this paper, we describe the process of corpus creation and provide\ndetails of corpus statistics and a comparison with existing resources.\nFurthermore, we develop two TTS systems based on Grad-TTS and Glow-TTS and\nillustrate the performance of the resulting systems via subjective and\nobjective evaluations. The corpus will be made publicly available at\nwww.clartts.com for research purposes, along with the baseline TTS systems\ndemo."
  },
  {
    "CAGR": 0.9712847185,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 2.3585316987,
    "title": "A Low-Complexity Solution to Sum Rate Maximization for IRS-assisted SWIPT-MIMO Broadcasting",
    "abstract": "This paper focuses on the fundamental problem of maximizing the achievable\nweighted sum rate (WSR) at information receivers (IRs) in an intelligent\nreflecting surface (IRS) assisted simultaneous wireless information and power\ntransfer system under a multiple-input multiple-output (SWIPT-MIMO) setting,\nsubject to a quality-of-service (QoS) constraint at the energy receivers (ERs).\nNotably, due to the coupling between the transmit precoding matrix and the\npassive beamforming vector in the QoS constraint, the formulated non-convex\noptimization problem is challenging to solve. We first decouple the design\nvariables in the constraints following a penalty dual decomposition method, and\nthen apply an alternating gradient projection algorithm to achieve a stationary\nsolution to the reformulated optimization problem. The proposed algorithm\nnearly doubles the WSR compared to that achieved by a block-coordinate descent\n(BCD) based benchmark scheme. At the same time, the complexity of the proposed\nscheme grows linearly with the number of IRS elements while that of the\nbenchmark scheme is proportional to the cube of the number of IRS elements."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.6054785613,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.9391417136,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.1380755951,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -1.3825183138,
    "title": "Region Prediction for Efficient Robot Localization on Large Maps",
    "abstract": "Recognizing already explored places (a.k.a. place recognition) is a\nfundamental task in Simultaneous Localization and Mapping (SLAM) to enable\nrobot relocalization and loop closure detection. In topological SLAM the\nrecognition takes place by comparing a signature (or feature vector) associated\nto the current node with the signatures of the nodes in the known map. However,\nas the number of nodes increases, matching the current node signature against\nall the existing ones becomes inefficient and thwarts real-time navigation. In\nthis paper we propose a novel approach to pre-select a subset of map nodes for\nplace recognition. The map nodes are clustered during exploration and each\ncluster is associated with a region. The region labels become the prediction\ntargets of a deep neural network and, during navigation, only the nodes\nassociated with the regions predicted with high probability are considered for\nmatching. While the proposed technique can be integrated in different SLAM\napproaches, in this work we describe an effective integration with RTAB-Map (a\npopular framework for real-time topological SLAM) which allowed us to design\nand run several experiments to demonstrate its effectiveness. All the code and\nmaterial from the experiments will be available online at\nhttps:\/\/github.com\/MI-BioLab\/region-learner."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.5710893717,
    "annual_revenue_USD_log": 0.025748487,
    "rnd_investment_required_log": -1.027440103,
    "title": "Progressive Scale-aware Network for Remote sensing Image Change Captioning",
    "abstract": "Remote sensing (RS) images contain numerous objects of different scales,\nwhich poses significant challenges for the RS image change captioning (RSICC)\ntask to identify visual changes of interest in complex scenes and describe them\nvia language. However, current methods still have some weaknesses in\nsufficiently extracting and utilizing multi-scale information. In this paper,\nwe propose a progressive scale-aware network (PSNet) to address the problem.\nPSNet is a pure Transformer-based model. To sufficiently extract multi-scale\nvisual features, multiple progressive difference perception (PDP) layers are\nstacked to progressively exploit the differencing features of bitemporal\nfeatures. To sufficiently utilize the extracted multi-scale features for\ncaptioning, we propose a scale-aware reinforcement (SR) module and combine it\nwith the Transformer decoding layer to progressively utilize the features from\ndifferent PDP layers. Experiments show that the PDP layer and SR module are\neffective and our PSNet outperforms previous methods. Our code is public at\nhttps:\/\/github.com\/Chen-Yang-Liu\/PSNet"
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.0192437628,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.0846092731,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.2476060596,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.692474134,
    "title": "GLH-Water: A Large-Scale Dataset for Global Surface Water Detection in Large-Size Very-High-Resolution Satellite Imagery",
    "abstract": "Global surface water detection in very-high-resolution (VHR) satellite\nimagery can directly serve major applications such as refined flood mapping and\nwater resource assessment. Although achievements have been made in detecting\nsurface water in small-size satellite images corresponding to local geographic\nscales, datasets and methods suitable for mapping and analyzing global surface\nwater have yet to be explored. To encourage the development of this task and\nfacilitate the implementation of relevant applications, we propose the\nGLH-water dataset that consists of 250 satellite images and manually labeled\nsurface water annotations that are distributed globally and contain water\nbodies exhibiting a wide variety of types (e.g., rivers, lakes, and ponds in\nforests, irrigated fields, bare areas, and urban areas). Each image is of the\nsize 12,800 $\\times$ 12,800 pixels at 0.3 meter spatial resolution. To build a\nbenchmark for GLH-water, we perform extensive experiments employing\nrepresentative surface water detection models, popular semantic segmentation\nmodels, and ultra-high resolution segmentation models. Furthermore, we also\ndesign a strong baseline with the novel pyramid consistency loss (PCL) to\ninitially explore this challenge. Finally, we implement the cross-dataset and\npilot area generalization experiments, and the superior performance illustrates\nthe strong generalization and practical application of GLH-water. The dataset\nis available at https:\/\/jack-bo1220.github.io\/project\/GLH-water.html."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.706112217,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 1.612544313,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.4256317728,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.1558904989,
    "title": "TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection",
    "abstract": "Multimodal hate detection, which aims to identify harmful content online such\nas memes, is crucial for building a wholesome internet environment. Previous\nwork has made enlightening exploration in detecting explicit hate remarks.\nHowever, most of their approaches neglect the analysis of implicit harm, which\nis particularly challenging as explicit text markers and demographic visual\ncues are often twisted or missing. The leveraged cross-modal attention\nmechanisms also suffer from the distributional modality gap and lack logical\ninterpretability. To address these semantic gaps issues, we propose TOT: a\ntopology-aware optimal transport framework to decipher the implicit harm in\nmemes scenario, which formulates the cross-modal aligning problem as solutions\nfor optimal transportation plans. Specifically, we leverage an optimal\ntransport kernel method to capture complementary information from multiple\nmodalities. The kernel embedding provides a non-linear transformation ability\nto reproduce a kernel Hilbert space (RKHS), which reflects significance for\neliminating the distributional modality gap. Moreover, we perceive the topology\ninformation based on aligned representations to conduct bipartite graph path\nreasoning. The newly achieved state-of-the-art performance on two publicly\navailable benchmark datasets, together with further visual analysis,\ndemonstrate the superiority of TOT in capturing implicit cross-modal alignment."
  },
  {
    "CAGR": -0.7548223915,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": -0.0791806145,
    "rnd_investment_required_log": 0.9097590502,
    "title": "Study of Surface Damage in Silicon by Irradiation with Focused Rubidium Ions",
    "abstract": "Cold atom ion sources have been developed and commercialized as alternative\nsources for focused ion beams (FIB). So far, applications and related research\nhave not been widely reported. In this paper, a prototype rubidium FIB is used\nto study the irradiation damage of 8.5 keV beam energy Rb$^+$ ions on silicon\nto examine the suitability of rubidium for nanomachining applications.\nTransmission electron microscopy combined with energy dispersive X-ray\nspectroscopy is applied to silicon samples irradiated by different doses of\nrubidium ions. The experimental results show a duplex damage layer consisting\nof an outer layer of oxidation without Rb and an inner layer containing Rb\nmostly at the interface to the underlying Si substrate. The steady-state damage\nlayer is measured to be $23.2(\\pm 0.3)$ nm thick with a rubidium staining level\nof $7(\\pm1)$ atomic percentage."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.0817321758,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.4968210863,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Stock Price Prediction Using Temporal Graph Model with Value Chain Data",
    "abstract": "Stock price prediction is a crucial element in financial trading as it allows\ntraders to make informed decisions about buying, selling, and holding stocks.\nAccurate predictions of future stock prices can help traders optimize their\ntrading strategies and maximize their profits. In this paper, we introduce a\nneural network-based stock return prediction method, the Long Short-Term Memory\nGraph Convolutional Neural Network (LSTM-GCN) model, which combines the Graph\nConvolutional Network (GCN) and Long Short-Term Memory (LSTM) Cells.\nSpecifically, the GCN is used to capture complex topological structures and\nspatial dependence from value chain data, while the LSTM captures temporal\ndependence and dynamic changes in stock returns data. We evaluated the LSTM-GCN\nmodel on two datasets consisting of constituents of Eurostoxx 600 and S&P 500.\nOur experiments demonstrate that the LSTM-GCN model can capture additional\ninformation from value chain data that are not fully reflected in price data,\nand the predictions outperform baseline models on both datasets."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -1.1517610651,
    "rnd_investment_required_log": 0.9097590502,
    "title": "NeRFMeshing: Distilling Neural Radiance Fields into Geometrically-Accurate 3D Meshes",
    "abstract": "With the introduction of Neural Radiance Fields (NeRFs), novel view synthesis\nhas recently made a big leap forward. At the core, NeRF proposes that each 3D\npoint can emit radiance, allowing to conduct view synthesis using\ndifferentiable volumetric rendering. While neural radiance fields can\naccurately represent 3D scenes for computing the image rendering, 3D meshes are\nstill the main scene representation supported by most computer graphics and\nsimulation pipelines, enabling tasks such as real time rendering and\nphysics-based simulations. Obtaining 3D meshes from neural radiance fields\nstill remains an open challenge since NeRFs are optimized for view synthesis,\nnot enforcing an accurate underlying geometry on the radiance field. We thus\npropose a novel compact and flexible architecture that enables easy 3D surface\nreconstruction from any NeRF-driven approach. Upon having trained the radiance\nfield, we distill the volumetric 3D representation into a Signed Surface\nApproximation Network, allowing easy extraction of the 3D mesh and appearance.\nOur final 3D mesh is physically accurate and can be rendered in real time on an\narray of devices."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 0.053041632,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.2605876197,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 1.3415318913,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Exploiting Semantic Attributes for Transductive Zero-Shot Learning",
    "abstract": "Zero-shot learning (ZSL) aims to recognize unseen classes by generalizing the\nrelation between visual features and semantic attributes learned from the seen\nclasses. A recent paradigm called transductive zero-shot learning further\nleverages unlabeled unseen data during training and has obtained impressive\nresults. These methods always synthesize unseen features from attributes\nthrough a generative adversarial network to mitigate the bias towards seen\nclasses. However, they neglect the semantic information in the unlabeled unseen\ndata and thus fail to generate high-fidelity attribute-consistent unseen\nfeatures. To address this issue, we present a novel transductive ZSL method\nthat produces semantic attributes of the unseen data and imposes them on the\ngenerative process. In particular, we first train an attribute decoder that\nlearns the mapping from visual features to semantic attributes. Then, from the\nattribute decoder, we obtain pseudo-attributes of unlabeled data and integrate\nthem into the generative model, which helps capture the detailed differences\nwithin unseen classes so as to synthesize more discriminative features.\nExperiments on five standard benchmarks show that our method yields\nstate-of-the-art results for zero-shot learning."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": 0.9097590502,
    "title": "Molecular Electronic Structure Calculation via a Quantum Computer",
    "abstract": "Quantum computers can be used to calculate the electronic structure and\nestimate the ground state energy of many-electron molecular systems. In the\npresent study, we implement the Variational Quantum Eigensolver (VQE)\nalgorithm, as a hybrid quantum-classical algorithm to calculate the ground\nstate energy of the molecules such as H3+, OH-, HF and BH3 in which the number\nof qubits has an increasing trend. We use the parity transformation for Fermion\nto qubit encoding and the Unitary Coupled Cluster for Single and Double\nexcitations (UCCSD) to construct an ansatz. We compare our quantum simulation\nresults with the computational chemistry approaches including Full\nConfiguration Interaction (FCI), as benchmark energy and Unrestricted\nHartree-Fock (UHF), as a common computational method. Our results show that\nthere is a good agreement between molecular ground state energy obtained from\nVQE and FCI. Moreover, the accuracy of the ground state energies obtained from\nVQE in our work is higher than the previously reported values. This work aims\nto benchmark the VQE algorithm to calculate the electronic ground state energy\nfor a new set of molecules that can be good candidates for molecular simulation\non a real quantum computer."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -1.1035246851,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -2.1424131503,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 0.5747930357,
    "title": "A large area 100 channel Picosec Micromegas detector with sub 20 ps time resolution",
    "abstract": "The PICOSEC Micromegas precise timing detector is based on a Cherenkov\nradiator coupled to a semi-transparent photocathode and a Micromegas\namplification structure. The first proof of concept single-channel small area\nprototype was able to achieve time resolution below 25 ps. One of the crucial\naspects in the development of the precise timing gaseous detectors applicable\nin high-energy physics experiments is a modular design that enables large area\ncoverage. The first 19-channel multi-pad prototype with an active area of\napproximately 10 cm$^2$ suffered from degraded timing resolution due to the\nnon-uniformity of the preamplification gap. A new 100 cm$^2$ detector module\nwith 100 channels based on a rigid hybrid ceramic\/FR4 Micromegas board for\nimproved drift gap uniformity was developed. Initial measurements with 80 GeV\/c\nmuons showed improvements in timing response over measured pads and a time\nresolution below 25 ps. More recent measurements with a new thinner drift gap\ndetector module and newly developed RF pulse amplifiers show that the\nresolution can be enhanced to a level of 17~ps. This work will present the\ndevelopment of the detector from structural simulations, design, and beam test\ncommissioning with a focus on the timing performance of a thinner drift gap\ndetector module in combination with new electronics using an automated timing\nscan method."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -1.1035246851,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.5173724297,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Hydrodynamic characterization of bubble column using Dynamical High Order Decomposition approach",
    "abstract": "Bubble columns are present in several applications, such as chemical and\nbiochemical reactors and petrochemical and environmental engineering\nindustries. This variety of applications is why understanding the bubble\ncolumns' dynamics is essential. This paper aims to describe a 2D bubble column\nsystem by a data-driven method to comprehend its dynamics better. We provided a\nset of simulations considering different superficial velocities to produce\ntraining data. With this data set, we compared two approaches: the Fast Fourier\ntransformation (FFT) and the High-Order Dynamic Mode Decomposition (HODMD). Our\nresults showed that FFT could not adequately describe the system as it has been\ndone for a long time in the industry. However, with a few measurement points,\nHODMD can well represent and reconstruct the dynamics of this complex dispersed\nmultiphase flow system."
  },
  {
    "CAGR": 2.0069489844,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -1.17581008,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.3930636585,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.6237901171,
    "title": "Enhancing Large Language Models with Climate Resources",
    "abstract": "Large language models (LLMs) have significantly transformed the landscape of\nartificial intelligence by demonstrating their ability in generating human-like\ntext across diverse topics. However, despite their impressive capabilities,\nLLMs lack recent information and often employ imprecise language, which can be\ndetrimental in domains where accuracy is crucial, such as climate change. In\nthis study, we make use of recent ideas to harness the potential of LLMs by\nviewing them as agents that access multiple sources, including databases\ncontaining recent and precise information about organizations, institutions,\nand companies. We demonstrate the effectiveness of our method through a\nprototype agent that retrieves emission data from ClimateWatch\n(https:\/\/www.climatewatchdata.org\/) and leverages general Google search. By\nintegrating these resources with LLMs, our approach overcomes the limitations\nassociated with imprecise language and delivers more reliable and accurate\ninformation in the critical domain of climate change. This work paves the way\nfor future advancements in LLMs and their application in domains where\nprecision is of paramount importance."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 1.2605876197,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Inductive Relation Prediction from Relational Paths and Context with Hierarchical Transformers",
    "abstract": "Relation prediction on knowledge graphs (KGs) is a key research topic.\nDominant embedding-based methods mainly focus on the transductive setting and\nlack the inductive ability to generalize to new entities for inference.\nExisting methods for inductive reasoning mostly mine the connections between\nentities, i.e., relational paths, without considering the nature of head and\ntail entities contained in the relational context. This paper proposes a novel\nmethod that captures both connections between entities and the intrinsic nature\nof entities, by simultaneously aggregating RElational Paths and cOntext with a\nunified hieRarchical Transformer framework, namely REPORT. REPORT relies solely\non relation semantics and can naturally generalize to the fully-inductive\nsetting, where KGs for training and inference have no common entities. In the\nexperiments, REPORT performs consistently better than all baselines on almost\nall the eight version subsets of two fully-inductive datasets. Moreover. REPORT\nis interpretable by providing each element's contribution to the prediction\nresults."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.8278466905,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 1.1599484684,
    "title": "Accuracy and Political Bias of News Source Credibility Ratings by Large Language Models",
    "abstract": "Search engines increasingly leverage large language models (LLMs) to generate\ndirect answers, and AI chatbots now access the Internet for fresh data. As\ninformation curators for billions of users, LLMs must assess the accuracy and\nreliability of different sources. This paper audits eight widely used LLMs from\nthree major providers -- OpenAI, Google, and Meta -- to evaluate their ability\nto discern credible and high-quality information sources from low-credibility\nones. We find that while LLMs can rate most tested news outlets, larger models\nmore frequently refuse to provide ratings due to insufficient information,\nwhereas smaller models are more prone to hallucination in their ratings. For\nsources where ratings are provided, LLMs exhibit a high level of agreement\namong themselves (average Spearman's $\\rho = 0.81$), but their ratings align\nonly moderately with human expert evaluations (average $\\rho = 0.59$).\nAnalyzing news sources with different political leanings in the US, we observe\na liberal bias in credibility ratings yielded by all LLMs in default\nconfigurations. Additionally, assigning partisan identities to LLMs\nconsistently results in strong politically congruent bias in the ratings. These\nfindings have important implications for the use of LLMs in curating news and\npolitical information."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.1380755951,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.5595405096,
    "title": "NPR: Nocturnal Place Recognition in Streets",
    "abstract": "Visual Place Recognition (VPR) is the task of retrieving database images\nsimilar to a query photo by comparing it to a large database of known images.\nIn real-world applications, extreme illumination changes caused by query images\ntaken at night pose a significant obstacle that VPR needs to overcome. However,\na training set with day-night correspondence for city-scale, street-level VPR\ndoes not exist. To address this challenge, we propose a novel pipeline that\ndivides VPR and conquers Nocturnal Place Recognition (NPR). Specifically, we\nfirst established a street-level day-night dataset, NightStreet, and used it to\ntrain an unpaired image-to-image translation model. Then we used this model to\nprocess existing large-scale VPR datasets to generate the VPR-Night datasets\nand demonstrated how to combine them with two popular VPR pipelines. Finally,\nwe proposed a divide-and-conquer VPR framework and provided explanations at the\ntheoretical, experimental, and application levels. Under our framework,\nprevious methods can significantly improve performance on two public datasets,\nincluding the top-ranked method."
  },
  {
    "CAGR": 1.7307718468,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.729673728,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.3526483917,
    "title": "On Context Distribution Shift in Task Representation Learning for Offline Meta RL",
    "abstract": "Offline Meta Reinforcement Learning (OMRL) aims to learn transferable\nknowledge from offline datasets to enhance the learning process for new target\ntasks. Context-based Reinforcement Learning (RL) adopts a context encoder to\nexpediently adapt the agent to new tasks by inferring the task representation,\nand then adjusting the policy based on this inferred representation. In this\nwork, we focus on context-based OMRL, specifically on the challenge of learning\ntask representation for OMRL. We conduct experiments that demonstrate that the\ncontext encoder trained on offline datasets might encounter distribution shift\nbetween the contexts used for training and testing. To overcome this problem,\nwe present a hard-sampling-based strategy to train a robust task context\nencoder. Our experimental findings on diverse continuous control tasks reveal\nthat utilizing our approach yields more robust task representations and better\ntesting performance in terms of accumulated returns compared to baseline\nmethods. Our code is available at https:\/\/github.com\/ZJLAB-AMMI\/HS-OMRL."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -1.970949423,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Mastering Pair Trading with Risk-Aware Recurrent Reinforcement Learning",
    "abstract": "Although pair trading is the simplest hedging strategy for an investor to\neliminate market risk, it is still a great challenge for reinforcement learning\n(RL) methods to perform pair trading as human expertise. It requires RL methods\nto make thousands of correct actions that nevertheless have no obvious\nrelations to the overall trading profit, and to reason over infinite states of\nthe time-varying market most of which have never appeared in history. However,\nexisting RL methods ignore the temporal connections between asset price\nmovements and the risk of the performed trading. These lead to frequent\ntradings with high transaction costs and potential losses, which barely reach\nthe human expertise level of trading. Therefore, we introduce CREDIT, a\nrisk-aware agent capable of learning to exploit long-term trading opportunities\nin pair trading similar to a human expert. CREDIT is the first to apply\nbidirectional GRU along with the temporal attention mechanism to fully consider\nthe temporal correlations embedded in the states, which allows CREDIT to\ncapture long-term patterns of the price movements of two assets to earn higher\nprofit. We also design the risk-aware reward inspired by the economic theory,\nthat models both the profit and risk of the tradings during the trading period.\nIt helps our agent to master pair trading with a robust trading preference that\navoids risky trading with possible high returns and losses. Experiments show\nthat it outperforms existing reinforcement learning methods in pair trading and\nachieves a significant profit over five years of U.S. stock data."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.7036515238,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.025748487,
    "rnd_investment_required_log": -0.692474134,
    "title": "Conveying Autonomous Robot Capabilities through Contrasting Behaviour Summaries",
    "abstract": "As advances in artificial intelligence enable increasingly capable\nlearning-based autonomous agents, it becomes more challenging for human\nobservers to efficiently construct a mental model of the agent's behaviour. In\norder to successfully deploy autonomous agents, humans should not only be able\nto understand the individual limitations of the agents but also have insight on\nhow they compare against one another. To do so, we need effective methods for\ngenerating human interpretable agent behaviour summaries. Single agent\nbehaviour summarization has been tackled in the past through methods that\ngenerate explanations for why an agent chose to pick a particular action at a\nsingle timestep. However, for complex tasks, a per-action explanation may not\nbe able to convey an agents global strategy. As a result, researchers have\nlooked towards multi-timestep summaries which can better help humans assess an\nagents overall capability. More recently, multi-step summaries have also been\nused for generating contrasting examples to evaluate multiple agents. However,\npast approaches have largely relied on unstructured search methods to generate\nsummaries and require agents to have a discrete action space. In this paper we\npresent an adaptive search method for efficiently generating contrasting\nbehaviour summaries with support for continuous state and action spaces. We\nperform a user study to evaluate the effectiveness of the summaries for helping\nhumans discern the superior autonomous agent for a given task. Our results\nindicate that adaptive search can efficiently identify informative contrasting\nscenarios that enable humans to accurately select the better performing agent\nwith a limited observation time budget."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8572985792,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": -0.8954744128,
    "rnd_investment_required_log": -0.692474134,
    "title": "SolefulTap: Augmenting Tap Dancing Experience using a Floor-Type Impact Display",
    "abstract": "We propose SolefulTap for a novel tap dancing experience. It allows users to\nfeel as if they are tap dancing or appreciate a tap dancing performance using\nthe sensations of their own feet. SolefulTap uses a method called Step\nAugmentation that provides audio-haptic feedback to users, generating impacts\nin response to users' simple step motions. Our prototype uses a floor-type\nimpact display consisting of pressure sensors, which detect users' steps, and\nsolenoids, which generate feedback through impact. Through a preliminary user\nstudy, we confirmed that the system can provide untrained users with the\nexperience of tap dancing. This study serves as a case study that provides\ninsight into how a reactive environment can affect the human capabilities of\nphysical expression and the sensation experienced."
  },
  {
    "CAGR": 1.7307718468,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.5747930357,
    "title": "A planar defect spin sensor in a two-dimensional material susceptible to strain and electric fields",
    "abstract": "The boron-vacancy spin defect ($\\text{V}_\\text{B}^{-}$) in hexagonal boron\nnitride (hBN) has a great potential as a quantum sensor in a two-dimensional\nmaterial that can directly probe various external perturbations in atomic-scale\nproximity to the quantum sensing layer. Here, we apply first principles\ncalculations to determine the coupling of the $\\text{V}_\\text{B}^{-}$\nelectronic spin to strain and electric fields. Our work unravels the interplay\nbetween local piezoelectric and elastic effects contributing to the final\nresponse to the electric fields. The theoretical predictions are then used to\nanalyse optically detected magnetic resonance (ODMR) spectra recorded on hBN\ncrystals containing different densities of $\\text{V}_\\text{B}^{-}$ centres. We\nprove that the orthorhombic zero-field splitting parameter results from local\nelectric fields produced by surrounding charge defects. By providing\ncalculations of the spin-strain and spin-electric field couplings, this work\npaves the way towards applications of $\\text{V}_\\text{B}^{-}$ centres for\nquantitative electric field imaging and quantum sensing under pressure."
  },
  {
    "CAGR": 2.6973918284,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Parents and Children: Distinguishing Multimodal DeepFakes from Natural Images",
    "abstract": "Recent advancements in diffusion models have enabled the generation of\nrealistic deepfakes from textual prompts in natural language. While these\nmodels have numerous benefits across various sectors, they have also raised\nconcerns about the potential misuse of fake images and cast new pressures on\nfake image detection. In this work, we pioneer a systematic study on deepfake\ndetection generated by state-of-the-art diffusion models. Firstly, we conduct a\ncomprehensive analysis of the performance of contrastive and\nclassification-based visual features, respectively extracted from CLIP-based\nmodels and ResNet or ViT-based architectures trained on image classification\ndatasets. Our results demonstrate that fake images share common low-level cues,\nwhich render them easily recognizable. Further, we devise a multimodal setting\nwherein fake images are synthesized by different textual captions, which are\nused as seeds for a generator. Under this setting, we quantify the performance\nof fake detection strategies and introduce a contrastive-based disentangling\nmethod that lets us analyze the role of the semantics of textual descriptions\nand low-level perceptual cues. Finally, we release a new dataset, called\nCOCOFake, containing about 1.2M images generated from the original COCO\nimage-caption pairs using two recent text-to-image diffusion models, namely\nStable Diffusion v1.4 and v2.0."
  },
  {
    "CAGR": -0.464836397,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 1.876511833,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.9786301475,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -1.535978894,
    "title": "Reply to Discussions of \"Multivariate Dynamic Modeling for Bayesian Forecasting of Business Revenue\"",
    "abstract": "We are most grateful to all discussants for their positive comments and many\nthought-provoking questions. In addition, the discussants provide a number of\nuseful leads into various areas of the literatures on time series, forecasting\nand commercial application within which the work in our paper is, of course,\njust one contribution linked to multiple threads. Our view is that,\ncollectively, the discussion contributions nicely expand on the core of the\npaper and together -- with multiple additional references -- provide an\nexcellent point-of-entr\\'ee to the broader field of retail forecasting and its\nresearch challenges. Interested readers are encouraged to dig deeply into the\ndiscussions and our responses here, and explore referenced sources.\n  There are several themes that recur across discussants, as well as a range of\nspecific points\/questions raised. Following some \"big-picture\" comments on our\nperspectives on Bayesian forecasting systems, we comment in turn on some\nspecifics in each contribution."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.9786301475,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.3825183138,
    "title": "Unsupervised Word Segmentation Using Temporal Gradient Pseudo-Labels",
    "abstract": "Unsupervised word segmentation in audio utterances is challenging as, in\nspeech, there is typically no gap between words. In a preliminary experiment,\nwe show that recent deep self-supervised features are very effective for word\nsegmentation but require supervision for training the classification head. To\nextend their effectiveness to unsupervised word segmentation, we propose a\npseudo-labeling strategy. Our approach relies on the observation that the\ntemporal gradient magnitude of the embeddings (i.e. the distance between the\nembeddings of subsequent frames) is typically minimal far from the boundaries\nand higher nearer the boundaries. We use a thresholding function on the\ntemporal gradient magnitude to define a psuedo-label for wordness. We train a\nlinear classifier, mapping the embedding of a single frame to the pseudo-label.\nFinally, we use the classifier score to predict whether a frame is a word or a\nboundary. In an empirical investigation, our method, despite its simplicity and\nfast run time, is shown to significantly outperform all previous methods on two\ndatasets."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": -1.6319355937,
    "rnd_investment_required_log": -0.3373958805,
    "title": "ViT-DAE: Transformer-driven Diffusion Autoencoder for Histopathology Image Analysis",
    "abstract": "Generative AI has received substantial attention in recent years due to its\nability to synthesize data that closely resembles the original data source.\nWhile Generative Adversarial Networks (GANs) have provided innovative\napproaches for histopathological image analysis, they suffer from limitations\nsuch as mode collapse and overfitting in discriminator. Recently, Denoising\nDiffusion models have demonstrated promising results in computer vision. These\nmodels exhibit superior stability during training, better distribution\ncoverage, and produce high-quality diverse images. Additionally, they display a\nhigh degree of resilience to noise and perturbations, making them well-suited\nfor use in digital pathology, where images commonly contain artifacts and\nexhibit significant variations in staining. In this paper, we present a novel\napproach, namely ViT-DAE, which integrates vision transformers (ViT) and\ndiffusion autoencoders for high-quality histopathology image synthesis. This\nmarks the first time that ViT has been introduced to diffusion autoencoders in\ncomputational pathology, allowing the model to better capture the complex and\nintricate details of histopathology images. We demonstrate the effectiveness of\nViT-DAE on three publicly available datasets. Our approach outperforms recent\nGAN-based and vanilla DAE methods in generating realistic images."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 0.6313247906,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 2.4921676729,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 0.5747930357,
    "title": "An Experimental Study of NOMA for Connected Autonomous Vehicles",
    "abstract": "Connected autonomous vehicles (CAV) constitute an important application of\nfuture-oriented traffic management .A vehicular system dominated by fully\nautonomous vehicles requires a robust and efficient vehicle-to-everything (V2X)\ninfrastructure that will provide sturdy connection of vehicles in both short\nand long distances for a large number of devices, requiring high spectral\nefficiency (SE). Power domain non-orthogonal multiple access (PD-NOMA)\ntechnique has the potential to provide the required high SE levels. In this\npaper, a vehicular PD-NOMA testbed is implemented using software defined radio\n(SDR) nodes. The main concerns and their corresponding solutions arising from\nthe implementation are highlighted. The bit error rates(BER) of vehicles with\ndifferent channel conditions are measured for mobile and stationary cases. The\nextent of the estimation errors on the success rate beyond the idealized\ntheoretical analysis view is investigated and the approaches to alleviate these\nerrors are discussed. Finally, our perspective on possible PD-NOMA based CAV\ndeployment scenarios is presented in terms of performance constraints and\nexpectancy along with the overlooked open issues."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.4890352234,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Can the Inference Logic of Large Language Models be Disentangled into Symbolic Concepts?",
    "abstract": "In this paper, we explain the inference logic of large language models (LLMs)\nas a set of symbolic concepts. Many recent studies have discovered that\ntraditional DNNs usually encode sparse symbolic concepts. However, because an\nLLM has much more parameters than traditional DNNs, whether the LLM also\nencodes sparse symbolic concepts is still an open problem. Therefore, in this\npaper, we propose to disentangle the inference score of LLMs for dialogue tasks\ninto a small number of symbolic concepts. We verify that we can use those\nsparse concepts to well estimate all inference scores of the LLM on all\narbitrarily masking states of the input sentence. We also evaluate the\ntransferability of concepts encoded by an LLM and verify that symbolic concepts\nusually exhibit high transferability across similar input sentences. More\ncrucially, those symbolic concepts can be used to explain the exact reasons\naccountable for the LLM's prediction errors."
  },
  {
    "CAGR": -0.4786452539,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.5923303378,
    "rnd_investment_required_log": -0.1558904989,
    "title": "LIGHT: Joint Individual Building Extraction and Height Estimation from Satellite Images through a Unified Multitask Learning Network",
    "abstract": "Building extraction and height estimation are two important basic tasks in\nremote sensing image interpretation, which are widely used in urban planning,\nreal-world 3D construction, and other fields. Most of the existing research\nregards the two tasks as independent studies. Therefore the height information\ncannot be fully used to improve the accuracy of building extraction and vice\nversa. In this work, we combine the individuaL buIlding extraction and heiGHt\nestimation through a unified multiTask learning network (LIGHT) for the first\ntime, which simultaneously outputs a height map, bounding boxes, and a\nsegmentation mask map of buildings. Specifically, LIGHT consists of an instance\nsegmentation branch and a height estimation branch. In particular, so as to\neffectively unify multi-scale feature branches and alleviate feature spans\nbetween branches, we propose a Gated Cross Task Interaction (GCTI) module that\ncan efficiently perform feature interaction between branches. Experiments on\nthe DFC2023 dataset show that our LIGHT can achieve superior performance, and\nour GCTI module with ResNet101 as the backbone can significantly improve the\nperformance of multitask learning by 2.8% AP50 and 6.5% delta1, respectively."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.0817321758,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -0.0791806145,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Entangled Photon Pair Source Demonstrator using the Quantum Instrumentation Control Kit System",
    "abstract": "We report the first demonstration of using the Quantum Instrumentation and\nControl Kit (QICK) system on RFSoCFPGA technology to drive an entangled photon\npair source and to detect the photon signals. With the QICK system, we achieve\nhigh levels of performance metrics including coincidence-to-accidental ratio\nexceeding 150, and entanglement visibility exceeding 95%, consistent with\nperformance metrics achieved using conventional waveform generators. We also\ndemonstrate simultaneous detector readout using the digitization functional of\nQICK, achieving internal system synchronization time resolution of 3.2 ps. The\nwork reported in this paper represents an explicit demonstration of the\nfeasibility for replacing commercial waveform generators and time taggers with\nRFSoC-FPGA technology in the operation of a quantum network, representing a\ncost reduction of more than an order of magnitude."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.8206417531,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": -1.2227962028,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -1.027440103,
    "title": "DoE2Vec: Deep-learning Based Features for Exploratory Landscape Analysis",
    "abstract": "We propose DoE2Vec, a variational autoencoder (VAE)-based methodology to\nlearn optimization landscape characteristics for downstream meta-learning\ntasks, e.g., automated selection of optimization algorithms. Principally, using\nlarge training data sets generated with a random function generator, DoE2Vec\nself-learns an informative latent representation for any design of experiments\n(DoE). Unlike the classical exploratory landscape analysis (ELA) method, our\napproach does not require any feature engineering and is easily applicable for\nhigh dimensional search spaces. For validation, we inspect the quality of\nlatent reconstructions and analyze the latent representations using different\nexperiments. The latent representations not only show promising potentials in\nidentifying similar (cheap-to-evaluate) surrogate functions, but also can\nsignificantly boost performances when being used complementary to the classical\nELA features in classification tasks."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.0287391931,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Fast Point Cloud Generation with Diffusion Models in High Energy Physics",
    "abstract": "Many particle physics datasets like those generated at colliders are\ndescribed by continuous coordinates (in contrast to grid points like in an\nimage), respect a number of symmetries (like permutation invariance), and have\na stochastic dimensionality. For this reason, standard deep generative models\nthat produce images or at least a fixed set of features are limiting. We\nintroduce a new neural network simulation based on a diffusion model that\naddresses these limitations named Fast Point Cloud Diffusion (FPCD). We show\nthat our approach can reproduce the complex properties of hadronic jets from\nproton-proton collisions with competitive precision to other recently proposed\nmodels. Additionally, we use a procedure called progressive distillation to\naccelerate the generation time of our method, which is typically a significant\nchallenge for diffusion models despite their state-of-the-art precision."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": -1.027440103,
    "title": "Accelerating Training of MLIPs Through Small-Cell Training",
    "abstract": "While machine-learned interatomic potentials have become a mainstay for\nmodeling materials, designing training sets that lead to robust potentials is\nchallenging. Automated methods, such as active learning and on-the-fly\nlearning, construct reliable training sets, but these processes can be\nresource-intensive. Current training approaches often use density functional\ntheory (DFT) calculations that have the same cell size as the simulations that\nthe potential is explicitly trained to model. Here, we demonstrate an\neasy-to-implement small-cell training protocol and use it to model the Zr-H\nsystem. This training leads to a potential that accurately predicts known\nstable Zr-H phases and reproduces the $\\alpha$-$\\beta$ pure zirconium phase\ntransition in molecular dynamics simulations. Compared to traditional active\nlearning, small-cell training decreased the training time of the\n$\\alpha$-$\\beta$ zirconium phase transition by approximately 20 times. The\npotential describes the phase transition with a degree of accuracy similar to\nthat of the large-cell training method."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.5175734475,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -1.027440103,
    "title": "Grand Challenge On Detecting Cheapfakes",
    "abstract": "Cheapfake is a recently coined term that encompasses non-AI (\"cheap\")\nmanipulations of multimedia content. Cheapfakes are known to be more prevalent\nthan deepfakes. Cheapfake media can be created using editing software for\nimage\/video manipulations, or even without using any software, by simply\naltering the context of an image\/video by sharing the media alongside\nmisleading claims. This alteration of context is referred to as out-of-context\n(OOC) misuse of media. OOC media is much harder to detect than fake media,\nsince the images and videos are not tampered. In this challenge, we focus on\ndetecting OOC images, and more specifically the misuse of real photographs with\nconflicting image captions in news items. The aim of this challenge is to\ndevelop and benchmark models that can be used to detect whether given samples\n(news image and associated captions) are OOC, based on the recently compiled\nCOSMOS dataset."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -1.17581008,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Charting the Topography of the Neural Network Landscape with Thermal-Like Noise",
    "abstract": "The training of neural networks is a complex, high-dimensional, non-convex\nand noisy optimization problem whose theoretical understanding is interesting\nboth from an applicative perspective and for fundamental reasons. A core\nchallenge is to understand the geometry and topography of the landscape that\nguides the optimization. In this work, we employ standard Statistical Mechanics\nmethods, namely, phase-space exploration using Langevin dynamics, to study this\nlandscape for an over-parameterized fully connected network performing a\nclassification task on random data. Analyzing the fluctuation statistics, in\nanalogy to thermal dynamics at a constant temperature, we infer a clear\ngeometric description of the low-loss region. We find that it is a\nlow-dimensional manifold whose dimension can be readily obtained from the\nfluctuations. Furthermore, this dimension is controlled by the number of data\npoints that reside near the classification decision boundary. Importantly, we\nfind that a quadratic approximation of the loss near the minimum is\nfundamentally inadequate due to the exponential nature of the decision boundary\nand the flatness of the low-loss region. This causes the dynamics to sample\nregions with higher curvature at higher temperatures, while producing\nquadratic-like statistics at any given temperature. We explain this behavior by\na simplified loss model which is analytically tractable and reproduces the\nobserved fluctuation statistics."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -2.0909238012,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -1.535978894,
    "title": "Towards an Hybrid Hodgkin-Huxley Action Potential Generation Model",
    "abstract": "Mathematical models for the generation of the action potential can improve\nthe understanding of physiological mechanisms that are consequence of the\nelectrical activity in neurons. In such models, some equations involving\nempirically obtained functions of the membrane potential are usually defined.\nThe best known of these models, the Hodgkin-Huxley model, is an example of this\nparadigm since it defines the conductances of ion channels in terms of the\nopening and closing rates of each type of gate present in the channels. These\nfunctions need to be derived from laboratory measurements that are often very\nexpensive and produce little data because they involve a time-space-independent\nmeasurement of the voltage in a single channel of the cell membrane. In this\nwork, we investigate the possibility of finding the Hodgkin-Huxley model's\nparametric functions using only two simple measurements (the membrane voltage\nas a function of time and the injected current that triggered that voltage) and\napplying Deep Learning methods to estimate these functions. This would result\nin an hybrid model of the action potential generation composed by the original\nHodgkin-Huxley equations and an Artificial Neural Network that requires a small\nset of easy-to-perform measurements to be trained. Experiments were carried out\nusing data generated from the original Hodgkin-Huxley model, and results show\nthat a simple two-layer artificial neural network (ANN) architecture trained on\na minimal amount of data can learn to model some of the fundamental proprieties\nof the action potential generation by estimating the model's rate functions."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Functional Knowledge Transfer with Self-supervised Representation Learning",
    "abstract": "This work investigates the unexplored usability of self-supervised\nrepresentation learning in the direction of functional knowledge transfer. In\nthis work, functional knowledge transfer is achieved by joint optimization of\nself-supervised learning pseudo task and supervised learning task, improving\nsupervised learning task performance. Recent progress in self-supervised\nlearning uses a large volume of data, which becomes a constraint for its\napplications on small-scale datasets. This work shares a simple yet effective\njoint training framework that reinforces human-supervised task learning by\nlearning self-supervised representations just-in-time and vice versa.\nExperiments on three public datasets from different visual domains, Intel\nImage, CIFAR, and APTOS, reveal a consistent track of performance improvements\non classification tasks during joint optimization. Qualitative analysis also\nsupports the robustness of learnt representations. Source code and trained\nmodels are available on GitHub."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -1.6095224489,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Low-loss Si-based Dielectrics for High Frequency Components of Superconducting Detectors",
    "abstract": "Silicon-based dielectric is crucial for many superconducting devices,\nincluding high-frequency transmission lines, filters, and resonators. Defects\nand contaminants in the amorphous dielectric and at the interfaces between the\ndielectric and metal layers can cause microwave losses and degrade device\nperformance. Optimization of the dielectric fabrication, device structure, and\nsurface morphology can help mitigate this problem. We present the fabrication\nof silicon oxide and nitride thin film dielectrics. We then characterized them\nusing Scanning Electron Microscopy, Atomic Force Microscopy, and\nspectrophotometry techniques. The samples were synthesized using various\ndeposition methods, including Plasma-Enhanced Chemical Vapor Deposition and\nmagnetron sputtering. The films morphology and structure were modified by\nadjusting the deposition pressure and gas flow. The resulting films were used\nin superconducting resonant systems consisting of planar inductors and\ncapacitors. Measurements of the resonator properties, including their quality\nfactor, were performed."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.7758955802,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -1.1517610651,
    "rnd_investment_required_log": 0.0662541385,
    "title": "The Interconnected Nature of Online Harm and Moderation: Investigating the Cross-Platform Spread of Harmful Content between YouTube and Twitter",
    "abstract": "The proliferation of harmful content shared online poses a threat to online\ninformation integrity and the integrity of discussion across platforms. Despite\nvarious moderation interventions adopted by social media platforms, researchers\nand policymakers are calling for holistic solutions. This study explores how a\ntarget platform could leverage content that has been deemed harmful on a source\nplatform by investigating the behavior and characteristics of Twitter users\nresponsible for sharing moderated YouTube videos. Using a large-scale dataset\nof 600M tweets related to the 2020 U.S. election, we find that moderated\nYoutube videos are extensively shared on Twitter and that users who share these\nvideos also endorse extreme and conspiratorial ideologies. A fraction of these\nusers are eventually suspended by Twitter, but they do not appear to be\ninvolved in state-backed information operations. The findings of this study\nhighlight the complex and interconnected nature of harmful cross-platform\ninformation diffusion, raising the need for cross-platform moderation\nstrategies."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.5173724297,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -1.027440103,
    "title": "Approaching Test Time Augmentation in the Context of Uncertainty Calibration for Deep Neural Networks",
    "abstract": "With the rise of Deep Neural Networks, machine learning systems are nowadays\nubiquitous in a number of real-world applications, which bears the need for\nhighly reliable models. This requires a thorough look not only at the accuracy\nof such systems, but also at their predictive uncertainty. Hence, we propose a\nnovel technique (with two different variations, named M-ATTA and V-ATTA) based\non test time augmentation, to improve the uncertainty calibration of deep\nmodels for image classification. By leveraging na adaptive weighting system,\nM\/V-ATTA improves uncertainty calibration without affecting the model's\naccuracy. The performance of these techniques is evaluated by considering\ndiverse metrics related to uncertainty calibration, demonstrating their\nrobustness. Empirical results, obtained on CIFAR-10, CIFAR-100, Aerial Image\nDataset, as well as in two different scenarios under distribution-shift,\nindicate that the proposed methods outperform several state-of-the-art post-hoc\ncalibration techniques. Furthermore, the methods proposed also show\nimprovements in terms of predictive entropy on out-of-distribution samples.\nCode for M\/V-ATTA available at: https:\/\/github.com\/pedrormconde\/MV-ATTA"
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 1.2605876197,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Multi-granulariy Time-based Transformer for Knowledge Tracing",
    "abstract": "In this paper, we present a transformer architecture for predicting student\nperformance on standardized tests. Specifically, we leverage students\nhistorical data, including their past test scores, study habits, and other\nrelevant information, to create a personalized model for each student. We then\nuse these models to predict their future performance on a given test. Applying\nthis model to the RIIID dataset, we demonstrate that using multiple\ngranularities for temporal features as the decoder input significantly improve\nmodel performance. Our results also show the effectiveness of our approach,\nwith substantial improvements over the LightGBM method. Our work contributes to\nthe growing field of AI in education, providing a scalable and accurate tool\nfor predicting student outcomes."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.8612254977,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Speech Reconstruction from Silent Tongue and Lip Articulation By Pseudo Target Generation and Domain Adversarial Training",
    "abstract": "This paper studies the task of speech reconstruction from ultrasound tongue\nimages and optical lip videos recorded in a silent speaking mode, where people\nonly activate their intra-oral and extra-oral articulators without producing\nsound. This task falls under the umbrella of articulatory-to-acoustic\nconversion, and may also be refered to as a silent speech interface. We propose\nto employ a method built on pseudo target generation and domain adversarial\ntraining with an iterative training strategy to improve the intelligibility and\nnaturalness of the speech recovered from silent tongue and lip articulation.\nExperiments show that our proposed method significantly improves the\nintelligibility and naturalness of the reconstructed speech in silent speaking\nmode compared to the baseline TaLNet model. When using an automatic speech\nrecognition (ASR) model to measure intelligibility, the word error rate (WER)\nof our proposed method decreases by over 15% compared to the baseline. In\naddition, our proposed method also outperforms the baseline on the\nintelligibility of the speech reconstructed in vocalized articulating mode,\nreducing the WER by approximately 10%."
  },
  {
    "CAGR": 0.1289444488,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.3861709233,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -1.535978894,
    "title": "Deep Stable Multi-Interest Learning for Out-of-distribution Sequential Recommendation",
    "abstract": "Recently, multi-interest models, which extract interests of a user as\nmultiple representation vectors, have shown promising performances for\nsequential recommendation. However, none of existing multi-interest\nrecommendation models consider the Out-Of-Distribution (OOD) generalization\nproblem, in which interest distribution may change. Considering multiple\ninterests of a user are usually highly correlated, the model has chance to\nlearn spurious correlations between noisy interests and target items. Once the\ndata distribution changes, the correlations among interests may also change,\nand the spurious correlations will mislead the model to make wrong predictions.\nTo tackle with above OOD generalization problem, we propose a novel\nmulti-interest network, named DEep Stable Multi-Interest Learning (DESMIL),\nwhich attempts to de-correlate the extracted interests in the model, and thus\nspurious correlations can be eliminated. DESMIL applies an attentive module to\nextract multiple interests, and then selects the most important one for making\nfinal predictions. Meanwhile, DESMIL incorporates a weighted correlation\nestimation loss based on Hilbert-Schmidt Independence Criterion (HSIC), with\nwhich training samples are weighted, to minimize the correlations among\nextracted interests. Extensive experiments have been conducted under both OOD\nand random settings, and up to 36.8% and 21.7% relative improvements are\nachieved respectively."
  },
  {
    "CAGR": 1.7307718468,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": 0.7562984273,
    "title": "A Multi-Institutional Open-Source Benchmark Dataset for Breast Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging Data",
    "abstract": "Recently, a new form of magnetic resonance imaging (MRI) called synthetic\ncorrelated diffusion (CDI$^s$) imaging was introduced and showed considerable\npromise for clinical decision support for cancers such as prostate cancer when\ncompared to current gold-standard MRI techniques. However, the efficacy for\nCDI$^s$ for other forms of cancers such as breast cancer has not been as\nwell-explored nor have CDI$^s$ data been previously made publicly available.\nMotivated to advance efforts in the development of computer-aided clinical\ndecision support for breast cancer using CDI$^s$, we introduce Cancer-Net BCa,\na multi-institutional open-source benchmark dataset of volumetric CDI$^s$\nimaging data of breast cancer patients. Cancer-Net BCa contains CDI$^s$\nvolumetric images from a pre-treatment cohort of 253 patients across ten\ninstitutions, along with detailed annotation metadata (the lesion type, genetic\nsubtype, longest diameter on the MRI (MRLD), the Scarff-Bloom-Richardson (SBR)\ngrade, and the post-treatment breast cancer pathologic complete response (pCR)\nto neoadjuvant chemotherapy). We further examine the demographic and tumour\ndiversity of the Cancer-Net BCa dataset to gain deeper insights into potential\nbiases. Cancer-Net BCa is publicly available as a part of a global open-source\ninitiative dedicated to accelerating advancement in machine learning to aid\nclinicians in the fight against cancer."
  },
  {
    "CAGR": 1.8688604156,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": -0.442284741,
    "title": "Global Prompt Cell: A Portable Control Module for Effective Prompt Tuning",
    "abstract": "As a novel approach to tuning pre-trained models, prompt tuning involves\nfreezing the parameters in downstream tasks while inserting trainable\nembeddings into inputs in the first layer. However, previous methods have\nmainly focused on the initialization of prompt embeddings. The strategy of\ntraining and utilizing prompt embeddings in a reasonable way has become a\nlimiting factor in the effectiveness of prompt tuning. To address this issue,\nwe introduce the Global Prompt Cell (GPC), a portable control module for prompt\ntuning that selectively preserves prompt information across all encoder layers.\nOur experimental results demonstrate a 5.8% improvement on SuperGLUE datasets\ncompared to vanilla prompt tuning."
  },
  {
    "CAGR": -1.4452652355,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -1.3926662644,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -3.0614283806,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": -0.3324392447,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": 1.3597208618,
    "title": "Evidence of experimental three-wave resonant interactions between two dispersion branches",
    "abstract": "We report the observation of nonlinear three-wave resonant interactions\nbetween two different branches of the dispersion relation of hydrodynamic\nwaves, namely the gravity-capillary and sloshing modes. These atypical\ninteractions are investigated within a torus of fluid for which the sloshing\nmode can be easily excited. A triadic resonance instability is then observed\ndue to this three-wave two-branch interaction mechanism. An exponential growth\nof the instability and phase locking are evidenced. The efficiency of this\ninteraction is found to be maximal when the gravity-capillary phase velocity\nmatches the group velocity of the sloshing mode. For a stronger forcing,\nadditional waves are generated by a cascade of three-wave interactions\npopulating the wave spectrum. Such a three-wave two-branch interaction\nmechanism is probably not restricted to hydrodynamics and could be of interest\nin other systems involving several propagation modes."
  },
  {
    "CAGR": -1.2381323823,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -1.8263786334,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.8551118345,
    "annual_revenue_USD_log": -2.3867657339,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Towards a more comprehensive open-source model for interdisciplinary smart integrated energy systems",
    "abstract": "The energy transition has recently experienced a further acceleration. In\norder to make the integration of renewable energies as cost-effective, secure\nand sustainable as possible and to develop new paradigms for the energy system,\nmany energy system models have been developed in research in the past to\nevaluate the solutions. While model identification and dissemination of results\nare widely discussed in the literature, a detailed view of the methodology is\noften missing. This paper addresses this topic and proposes a methodology to\nbuild a comprehensive, publicly accessible database for modeling a multi-modal\nintegrated energy system. The focus hereby is dynamic modeling of low- and\nmedium-voltage grids consisting of prosumers, battery storages, heat pumps and\nelectric cars. In addition, a district heating network is parameterized to\nmatch the electricity grid. Modelica and the TransiEnt-Library serves as the\nmodeling tool. The methodology for creating the grid models is available via\nGitLab. A study case that uses the methodology to analyze the congestion\nsituation within a medium-voltage distribution grid is presented."
  },
  {
    "CAGR": 1.7307718468,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": -0.8459347379,
    "title": "Using Multiple RDF Knowledge Graphs for Enriching ChatGPT Responses",
    "abstract": "There is a recent trend for using the novel Artificial Intelligence ChatGPT\nchatbox, which provides detailed responses and articulate answers across many\ndomains of knowledge. However, in many cases it returns plausible-sounding but\nincorrect or inaccurate responses, whereas it does not provide evidence.\nTherefore, any user has to further search for checking the accuracy of the\nanswer or\/and for finding more information about the entities of the response.\nAt the same time there is a high proliferation of RDF Knowledge Graphs (KGs)\nover any real domain, that offer high quality structured data. For enabling the\ncombination of ChatGPT and RDF KGs, we present a research prototype, called\nGPToLODS, which is able to enrich any ChatGPT response with more information\nfrom hundreds of RDF KGs. In particular, it identifies and annotates each\nentity of the response with statistics and hyperlinks to LODsyndesis KG (which\ncontains integrated data from 400 RDF KGs and over 412 million entities). In\nthis way, it is feasible to enrich the content of entities and to perform fact\nchecking and validation for the facts of the response at real time."
  },
  {
    "CAGR": 1.7307718468,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.0164407866,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -1.2659314651,
    "annual_revenue_USD_log": 0.4193630149,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Cancer-Net BCa-S: Breast Cancer Grade Prediction using Volumetric Deep Radiomic Features from Synthetic Correlated Diffusion Imaging",
    "abstract": "The prevalence of breast cancer continues to grow, affecting about 300,000\nfemales in the United States in 2023. However, there are different levels of\nseverity of breast cancer requiring different treatment strategies, and hence,\ngrading breast cancer has become a vital component of breast cancer diagnosis\nand treatment planning. Specifically, the gold-standard Scarff-Bloom-Richardson\n(SBR) grade has been shown to consistently indicate a patient's response to\nchemotherapy. Unfortunately, the current method to determine the SBR grade\nrequires removal of some cancer cells from the patient which can lead to stress\nand discomfort along with costly expenses. In this paper, we study the efficacy\nof deep learning for breast cancer grading based on synthetic correlated\ndiffusion (CDI$^s$) imaging, a new magnetic resonance imaging (MRI) modality\nand found that it achieves better performance on SBR grade prediction compared\nto those learnt using gold-standard imaging modalities. Hence, we introduce\nCancer-Net BCa-S, a volumetric deep radiomics approach for predicting SBR grade\nbased on volumetric CDI$^s$ data. Given the promising results, this proposed\nmethod to identify the severity of the cancer would allow for better treatment\ndecisions without the need for a biopsy. Cancer-Net BCa-S has been made\npublicly available as part of a global open-source initiative for advancing\nmachine learning for cancer care."
  },
  {
    "CAGR": 1.4545947092,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.310959674,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Radically Uniform Spike Trains in Optically Injected Quantum Cascade Oscillators",
    "abstract": "It has been found that noise-induced excitability in quantum well and quantum\ndot semiconductor laser systems usually produces spike patterns of non-uniform\namplitude. In this letter, we experimentally record that an inter-subband\nquantum cascade laser injected with a monochromatic laser exhibits a series of\nhighly-uniform spike trains in the time domain. Theoretical analysis\ndemonstrates that such high uniformity has its origin in the ultrashort carrier\nlifetime of the quantum cascade laser gain medium that is typically close to\none picosecond."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -1.4717292989,
    "title": "A Phoneme-Informed Neural Network Model for Note-Level Singing Transcription",
    "abstract": "Note-level automatic music transcription is one of the most representative\nmusic information retrieval (MIR) tasks and has been studied for various\ninstruments to understand music. However, due to the lack of high-quality\nlabeled data, transcription of many instruments is still a challenging task. In\nparticular, in the case of singing, it is difficult to find accurate notes due\nto its expressiveness in pitch, timbre, and dynamics. In this paper, we propose\na method of finding note onsets of singing voice more accurately by leveraging\nthe linguistic characteristics of singing, which are not seen in other\ninstruments. The proposed model uses mel-scaled spectrogram and phonetic\nposteriorgram (PPG), a frame-wise likelihood of phoneme, as an input of the\nonset detection network while PPG is generated by the pre-trained network with\nsinging and speech data. To verify how linguistic features affect onset\ndetection, we compare the evaluation results through the dataset with different\nlanguages and divide onset types for detailed analysis. Our approach\nsubstantially improves the performance of singing transcription and therefore\nemphasizes the importance of linguistic features in singing analysis."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.0271308869,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.4256317728,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Radiative suppression of exciton-exciton annihilation in a two-dimensional semiconductor",
    "abstract": "Two-dimensional (2D) semiconductors possess strongly bound excitons, opening\nnovel opportunities for engineering light-matter interaction at the nanoscale.\nHowever, their in-plane confinement leads to large non-radiative\nexciton-exciton annihilation (EEA) processes, setting a fundamental limit for\ntheir photonic applications. In this work, we demonstrate suppression of EEA\nvia enhancement of light-matter interaction in hybrid 2D\nsemiconductor-dielectric nanophotonic platforms, by coupling excitons in WS$ _2\n$ monolayers with optical Mie resonances in dielectric nanoantennas. The hybrid\nsystem reaches an intermediate light-matter coupling regime, with\nphotoluminescence enhancement factors up to 10$ ^2 $. Probing the exciton\nultrafast dynamics reveal suppressed EEA for coupled excitons, even under high\nexciton densities $>$ 10$^{12}$ cm$^{-2} $. We extract EEA coefficients in the\norder of 10$^{-3} $, compared to 10$^{-2} $ for uncoupled monolayers, as well\nas absorption enhancement of 3.9 and a Purcell factor of 4.5. Our results\nhighlight engineering the photonic environment as a route to achieve higher\nquantum efficiencies for low-power hybrid devices, and larger exciton\ndensities, towards strongly correlated excitonic phases in 2D semiconductors."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.2476060596,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 2.3585316987,
    "title": "Reentrant proximity-induced superconductivity for GeTe semimetal",
    "abstract": "We experimentally investigate charge transport in In-GeTe and In-GeTe-In\nproximity devices, which are formed as junctions between superconducting indium\nleads and thick single crystal flakes of $\\alpha$-GeTe topological semimetal.\nWe observe nonmonotonic effects of the applied external magnetic field,\nincluding reentrant superconductivity in In-GeTe-In Josephson junctions:\nsupercurrent reappears at some finite magnetic field. For a single In-GeTe\nAndreev junction, the superconducting gap is partially suppressed in zero\nmagnetic field, while the gap is increased nearly to the bulk value for some\nfinite field before its full suppression. We discuss possible reasons for the\nresults obtained, taking into account spin polarization of Fermi arc surface\nstates in topological semimetal $\\alpha$-GeTe with a strong spin-orbit\ncoupling. In particular, the zero-field surface state spin polarization\npartially suppresses the superconductivity, while it is recovered due to the\nmodified spin-split surface state configuration in finite fields. As an\nalternative possible scenario, the transition into the\nFulde-Ferrell-Larkin-Ovchinnikov state is discussed. However, the role of\nstrong spin-orbit coupling in forming the nonmonotonic behavior has not been\nanalyzed for heterostructures in the Fulde-Ferrell-Larkin-Ovchinnikov state,\nwhich is crucial for junctions involving GeTe topological semimetal."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": 0.5747930357,
    "title": "HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting",
    "abstract": "Medical decision-making processes can be enhanced by comprehensive biomedical\nknowledge bases, which require fusing knowledge graphs constructed from\ndifferent sources via a uniform index system. The index system often organizes\nbiomedical terms in a hierarchy to provide the aligned entities with\nfine-grained granularity. To address the challenge of scarce supervision in the\nbiomedical knowledge fusion (BKF) task, researchers have proposed various\nunsupervised methods. However, these methods heavily rely on ad-hoc lexical and\nstructural matching algorithms, which fail to capture the rich semantics\nconveyed by biomedical entities and terms. Recently, neural embedding models\nhave proved effective in semantic-rich tasks, but they rely on sufficient\nlabeled data to be adequately trained. To bridge the gap between the\nscarce-labeled BKF and neural embedding models, we propose HiPrompt, a\nsupervision-efficient knowledge fusion framework that elicits the few-shot\nreasoning ability of large language models through hierarchy-oriented prompts.\nEmpirical results on the collected KG-Hi-BKF benchmark datasets demonstrate the\neffectiveness of HiPrompt."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.0846092731,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.3861709233,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": -0.692474134,
    "title": "Regularizing Contrastive Predictive Coding for Speech Applications",
    "abstract": "Self-supervised methods such as Contrastive predictive Coding (CPC) have\ngreatly improved the quality of the unsupervised representations. These\nrepresentations significantly reduce the amount of labeled data needed for\ndownstream task performance, such as automatic speech recognition. CPC learns\nrepresentations by learning to predict future frames given current frames.\nBased on the observation that the acoustic information, e.g., phones, changes\nslower than the feature extraction rate in CPC, we propose regularization\ntechniques that impose slowness constraints on the features. Here we propose\ntwo regularization techniques: Self-expressing constraint and Left-or-Right\nregularization. We evaluate the proposed model on ABX and linear phone\nclassification tasks, acoustic unit discovery, and automatic speech\nrecognition. The regularized CPC trained on 100 hours of unlabeled data matches\nthe performance of the baseline CPC trained on 360 hours of unlabeled data. We\nalso show that our regularization techniques are complementary to data\naugmentation and can further boost the system's performance. In monolingual,\ncross-lingual, or multilingual settings, with\/without data augmentation,\nregardless of the amount of data used for training, our regularized models\noutperformed the baseline CPC models on the ABX task."
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.7562984273,
    "title": "A framework for fully autonomous design of materials via multiobjective optimization and active learning: challenges and next steps",
    "abstract": "In order to deploy machine learning in a real-world self-driving laboratory\nwhere data acquisition is costly and there are multiple competing design\ncriteria, systems need to be able to intelligently sample while balancing\nperformance trade-offs and constraints. For these reasons, we present an active\nlearning process based on multiobjective black-box optimization with\ncontinuously updated machine learning models. This workflow is built on\nopen-source technologies for real-time data streaming and modular\nmultiobjective optimization software development. We demonstrate a proof of\nconcept for this workflow through the autonomous operation of a continuous-flow\nchemistry laboratory, which identifies ideal manufacturing conditions for the\nelectrolyte 2,2,2-trifluoroethyl methyl carbonate."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -2.9778732615,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "On User-side Fairness in Negative Sampling for Recommender Systems",
    "abstract": "Recommender systems are usually trained to discern between positive and\nnegative instances for each user. Negative sampling plays an important role in\nselecting informative negative items. Since positive data is disproportionately\ncontributed by a minority of active users, negative samplers might be affected\nby data imbalance thus choosing more informative negative items for active\nusers. Consequently, users with low participation are further underrepresented\nin the training data, potentially causing subpar treatment from recommenders.\nIn this paper we demonstrate empirically that active users receive more\naccurate recommendation than inactive users for state-of-the-art negative\nsampling strategies, and the degree of data imbalance influences the severity\nof performance disparities. We further show that the performance gain brought\nby sampling more negative instances for each positive item is unequally\ndistributed across user groups. Generally, active users benefit from\nperformance gain whereas inactive users might suffer from performance\ndegradation. To address these shortcomings, we propose a group-wise negative\nratio setup where we use the appropriate smaller negative ratio for inactive\nusers and a bigger ratio for active users. Comprehensive experiments show our\nproposed group-wise ratio outperforms a single global ratio in user-side\nfairness and performance improvement."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.5899504433,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.1558904989,
    "title": "S3M: Scalable Statistical Shape Modeling through Unsupervised Correspondences",
    "abstract": "Statistical shape models (SSMs) are an established way to represent the\nanatomy of a population with various clinically relevant applications. However,\nthey typically require domain expertise, and labor-intensive landmark\nannotations to construct. We address these shortcomings by proposing an\nunsupervised method that leverages deep geometric features and functional\ncorrespondences to simultaneously learn local and global shape structures\nacross population anatomies. Our pipeline significantly improves unsupervised\ncorrespondence estimation for SSMs compared to baseline methods, even on highly\nirregular surface topologies. We demonstrate this for two different anatomical\nstructures: the thyroid and a multi-chamber heart dataset. Furthermore, our\nmethod is robust enough to learn from noisy neural network predictions,\npotentially enabling scaling SSMs to larger patient populations without manual\nsegmentation annotation."
  },
  {
    "CAGR": 0.3775038726,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.7036101854,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Acoustic Beamforming for Object-relative Distance Estimation and Control in Unmanned Air Vehicles using Propulsion System Noise",
    "abstract": "Unmanned air vehicles often produce significant noise from their propulsion\nsystems. Using this broadband signal as \"acoustic illumination\" for an\nauxiliary sensing system could make vehicles more robust at a minimal cost. We\npresent an acoustic beamforming-based algorithm that estimates object-relative\ndistance with a small two-microphone array using the generated propulsion\nsystem noise of a vehicle. We demonstrate this approach in several closed-loop\ndistance feedback control tests with a mounted quad-rotor vehicle in a noisy\nenvironment and show accurate object-relative distance estimates more than 2x\nfurther than the baseline channel-based approach. We conclude that this\napproach is robust to several practical vehicle and noise situations and shows\npromise for use in more complex operating environments."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -2.1424131503,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.9097590502,
    "title": "Harnessing Digital Pathology And Causal Learning To Improve Eosinophilic Esophagitis Dietary Treatment Assignment",
    "abstract": "Eosinophilic esophagitis (EoE) is a chronic, food antigen-driven, allergic\ninflammatory condition of the esophagus associated with elevated esophageal\neosinophils. EoE is a top cause of chronic dysphagia after GERD. Diagnosis of\nEoE relies on counting eosinophils in histological slides, a manual and\ntime-consuming task that limits the ability to extract complex\npatient-dependent features. The treatment of EoE includes medication and food\nelimination. A personalized food elimination plan is crucial for engagement and\nefficiency, but previous attempts failed to produce significant results. In\nthis work, on the one hand, we utilize AI for inferring histological features\nfrom the entire biopsy slide, features that cannot be extracted manually. On\nthe other hand, we develop causal learning models that can process this wealth\nof data. We applied our approach to the 'Six-Food vs. One-Food Eosinophilic\nEsophagitis Diet Study', where 112 symptomatic adults aged 18-60 years with\nactive EoE were assigned to either a six-food elimination diet (6FED) or a\none-food elimination diet (1FED) for six weeks. Our results show that the\naverage treatment effect (ATE) of the 6FED treatment compared with the 1FED\ntreatment is not significant, that is, neither diet was superior to the other.\nWe examined several causal models and show that the best treatment strategy was\nobtained using T-learner with two XGBoost modules. While 1FED only and 6FED\nonly provide improvement for 35%-38% of the patients, which is not\nsignificantly different from a random treatment assignment, our causal model\nyields a significantly better improvement rate of 58.4%. This study illustrates\nthe significance of AI in enhancing treatment planning by analyzing molecular\nfeatures' distribution in histological slides through causal learning. Our\napproach can be harnessed for other conditions that rely on histology for\ndiagnosis and treatment."
  },
  {
    "CAGR": -0.7548223915,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.9725576892,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": 0.3526483917,
    "title": "On the computation of thermo-relaxing multi-component flows with the Baer-Nunziato model",
    "abstract": "In inertial confinement fusion (ICF) implosions, mixing the ablator into the\nfuel and the hot spot is one of the most adverse factors that lead to ignition\ndegradation. Recent experiments in the Marble campaign at the Omega laser\nfacility and the National Ignition Facility (NIF) demonstrate the significance\nof the temperature separation in heterogeneous mixing flows. In the present\nwork we provide an approach to deal with thermally disequilibrium\nmulti-component flows with the ultimate aim to investigate the temperature\nseparation impact on mixing and fusion burn. The present work is two-fold,\ni.e., (a)we derive a model governing the multi-component flows in thermal\ndisequilibrium with transport terms, (b)we use the derived model to study the\nRayleigh-Taylor (RT) instability in thermally relaxing multi-component systems.\nThe model is reduced from the fully disequilibrium multi-phase Baer-Nunziato\nmodel in the limit of small Knudsen number $Kn << 1$. Velocity disequilibrium\nis closed with the diffusion laws and only one mass weighted velocity is\nretained formally. Thus, the complex wave structure of the original\nBaer-Nunziato model is simplified to a large extent and the obtained model is\nmuch more computationally affordable. Moreover, the capability to deal with\nfinite temperature relaxation is kept. Efficient numerical methods for solving\nthe proposed model are aslo presented. Equipped with the proposed model and\nnumerical methods, we further investigate the impact of the thermal relaxation\non the RT instability development at the inertial confinement fusion (ICF)\ndeceleration stage. On the basis of numerical simulations, we have found that\nfor the RT instability at an interface between the high-density low-temperature\ncomponent and the low-density high-temperature component, the thermal\nrelaxation significantly suppress the development of the instability."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Lightweight and Interpretable Left Ventricular Ejection Fraction Estimation using Mobile U-Net",
    "abstract": "Accurate LVEF measurement is important in clinical practice as it identifies\npatients who may be in need of life-prolonging treatments. This paper presents\na deep learning based framework to automatically estimate left ventricular\nejection fraction from an entire 4-chamber apical echocardiogram video. The aim\nof the proposed framework is to provide an interpretable and computationally\neffective ejection fraction prediction pipeline. A lightweight Mobile U-Net\nbased network is developed to segment the left ventricle in each frame of an\nechocardiogram video. An unsupervised LVEF estimation algorithm is implemented\nbased on Simpson's mono-plane method. Experimental results on a large public\ndataset show that our proposed approach achieves comparable accuracy to the\nstate-of-the-art while being significantly more space and time efficient (with\n5 times fewer parameters and 10 times fewer FLOPS)."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Fast Random Approximation of Multi-channel Room Impulse Response",
    "abstract": "Modern neural-network-based speech processing systems are typically required\nto be robust against reverberation, and the training of such systems thus needs\na large amount of reverberant data. During the training of the systems,\non-the-fly simulation pipeline is nowadays preferred as it allows the model to\ntrain on infinite number of data samples without pre-generating and saving them\non harddisk. An RIR simulation method thus needs to not only generate more\nrealistic artificial room impulse response (RIR) filters, but also generate\nthem in a fast way to accelerate the training process. Existing RIR simulation\ntools have proven effective in a wide range of speech processing tasks and\nneural network architectures, but their usage in on-the-fly simulation pipeline\nremains questionable due to their computational complexity or the quality of\nthe generated RIR filters. In this paper, we propose FRAM-RIR, a fast random\napproximation method of the widely-used image-source method (ISM), to\nefficiently generate realistic multi-channel RIR filters. FRAM-RIR bypasses the\nexplicit calculation of sound propagation paths in ISM-based algorithms by\nrandomly sampling the location and number of reflections of each virtual sound\nsource based on several heuristic assumptions, while still maintains accurate\ndirection-of-arrival (DOA) information of all sound sources. Visualization of\noracle beampatterns and directional features shows that FRAM-RIR can generate\nmore realistic RIR filters than existing widely-used ISM-based tools, and\nexperiment results on multi-channel noisy speech separation and dereverberation\ntasks with a wide range of neural network architectures show that models\ntrained with FRAM-RIR can also achieve on par or better performance on real\nRIRs compared to other RIR simulation tools with a significantly accelerated\ntraining procedure. A Python implementation of FRAM-RIR is released."
  },
  {
    "CAGR": 1.6064921349,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 2.274418923,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.5923303378,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Fed-MIWAE: Federated Imputation of Incomplete Data via Deep Generative Models",
    "abstract": "Federated learning allows for the training of machine learning models on\nmultiple decentralized local datasets without requiring explicit data exchange.\nHowever, data pre-processing, including strategies for handling missing data,\nremains a major bottleneck in real-world federated learning deployment, and is\ntypically performed locally. This approach may be biased, since the\nsubpopulations locally observed at each center may not be representative of the\noverall one. To address this issue, this paper first proposes a more consistent\napproach to data standardization through a federated model. Additionally, we\npropose Fed-MIWAE, a federated version of the state-of-the-art imputation\nmethod MIWAE, a deep latent variable model for missing data imputation based on\nvariational autoencoders. MIWAE has the great advantage of being easily\ntrainable with classical federated aggregators. Furthermore, it is able to deal\nwith MAR (Missing At Random) data, a more challenging missing-data mechanism\nthan MCAR (Missing Completely At Random), where the missingness of a variable\ncan depend on the observed ones. We evaluate our method on multi-modal medical\nimaging data and clinical scores from a simulated federated scenario with the\nADNI dataset. We compare Fed-MIWAE with respect to classical imputation\nmethods, either performed locally or in a centralized fashion. Fed-MIWAE allows\nto achieve imputation accuracy comparable with the best centralized method,\neven when local data distributions are highly heterogeneous. In addition,\nthanks to the variational nature of Fed-MIWAE, our method is designed to\nperform multiple imputation, allowing for the quantification of the imputation\nuncertainty in the federated scenario."
  },
  {
    "CAGR": 0.1427533057,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.690404543,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.1044389278,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -2.0194305031,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": 0.0662541385,
    "title": "A theory independent Curry-De Bruijn-Howard correspondence",
    "abstract": "Instead of developing a customized typed lambda-calculus for each theory, we\nattempt to design a general parametric calculus that permits to express the\nproofs of any theory. This way, the problem of expressing proofs in the\nlambda-calculus is separated from that of choosing a theory."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 3.0890282145,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Transformer-based Graph Neural Networks for Outfit Generation",
    "abstract": "Suggesting complementary clothing items to compose an outfit is a process of\nemerging interest, yet it involves a fine understanding of fashion trends and\nvisual aesthetics. Previous works have mainly focused on recommendation by\nscoring visual appeal and representing garments as ordered sequences or as\ncollections of pairwise-compatible items. This limits the full usage of\nrelations among clothes. We attempt to bridge the gap between outfit\nrecommendation and generation by leveraging a graph-based representation of\nitems in a collection. The work carried out in this paper, tries to build a\nbridge between outfit recommendation and generation, by discovering new\nappealing outfits starting from a collection of pre-existing ones. We propose a\ntransformer-based architecture, named TGNN, which exploits multi-headed self\nattention to capture relations between clothing items in a graph as a message\npassing step in Convolutional Graph Neural Networks. Specifically, starting\nfrom a seed, i.e.~one or more garments, outfit generation is performed by\niteratively choosing the garment that is most compatible with the previously\nchosen ones. Extensive experimentations are conducted with two different\ndatasets, demonstrating the capability of the model to perform seeded outfit\ngeneration as well as obtaining state of the art results on compatibility\nestimation tasks."
  },
  {
    "CAGR": 1.4545947092,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 3.4504551886,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Low-code LLM: Graphical User Interface over Large Language Models",
    "abstract": "Utilizing Large Language Models (LLMs) for complex tasks is challenging,\noften involving a time-consuming and uncontrollable prompt engineering process.\nThis paper introduces a novel human-LLM interaction framework, Low-code LLM. It\nincorporates six types of simple low-code visual programming interactions to\nachieve more controllable and stable responses. Through visual interaction with\na graphical user interface, users can incorporate their ideas into the process\nwithout writing trivial prompts. The proposed Low-code LLM framework consists\nof a Planning LLM that designs a structured planning workflow for complex\ntasks, which can be correspondingly edited and confirmed by users through\nlow-code visual programming operations, and an Executing LLM that generates\nresponses following the user-confirmed workflow. We highlight three advantages\nof the low-code LLM: user-friendly interaction, controllable generation, and\nwide applicability. We demonstrate its benefits using four typical\napplications. By introducing this framework, we aim to bridge the gap between\nhumans and LLMs, enabling more effective and efficient utilization of LLMs for\ncomplex tasks. The code, prompts, and experimental details are available at\nhttps:\/\/github.com\/moymix\/TaskMatrix\/tree\/main\/LowCodeLLM. A system\ndemonstration video can be found at\nhttps:\/\/www.youtube.com\/watch?v=jb2C1vaeO3E."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 1.398081227,
    "rnd_investment_required_log": 0.5747930357,
    "title": "AICons: An AI-Enabled Consensus Algorithm Driven by Energy Preservation and Fairness",
    "abstract": "Blockchain has been used in several domains. However, this technology still\nhas major limitations that are largely related to one of its core components,\nnamely the consensus protocol\/algorithm. Several solutions have been proposed\nin literature and some of them are based on the use of Machine Learning (ML)\nmethods. The ML-based consensus algorithms usually waste the work done by the\n(contributing\/participating) nodes, as only winners' ML models are\nconsidered\/used, resulting in low energy efficiency. To reduce energy waste and\nimprove scalability, this paper proposes an AI-enabled consensus algorithm\n(named AICons) driven by energy preservation and fairness of rewarding nodes\nbased on their contribution. In particular, the local ML models trained by all\nnodes are utilised to generate a global ML model for selecting winners, which\nreduces energy waste. Considering the fairness of the rewards, we innovatively\ndesigned a utility function for the Shapley value evaluation equation to\nevaluate the contribution of each node from three aspects, namely ML model\naccuracy, energy consumption, and network bandwidth. The three aspects are\ncombined into a single Shapley value to reflect the contribution of each node\nin a blockchain system. Extensive experiments were carried out to evaluate\nfairness, scalability, and profitability of the proposed solution. In\nparticular, AICons has an evenly distributed reward-contribution ratio across\nnodes, handling 38.4 more transactions per second, and allowing nodes to get\nmore profit to support a bigger network than the state-of-the-art schemes."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Attention Mixtures for Time-Aware Sequential Recommendation",
    "abstract": "Transformers emerged as powerful methods for sequential recommendation.\nHowever, existing architectures often overlook the complex dependencies between\nuser preferences and the temporal context. In this short paper, we introduce\nMOJITO, an improved Transformer sequential recommender system that addresses\nthis limitation. MOJITO leverages Gaussian mixtures of attention-based temporal\ncontext and item embedding representations for sequential modeling. Such an\napproach permits to accurately predict which items should be recommended next\nto users depending on past actions and the temporal context. We demonstrate the\nrelevance of our approach, by empirically outperforming existing Transformers\nfor sequential recommendation on several real-world datasets."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 3.4504551886,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.876511833,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Attentive Q-Matrix Learning for Knowledge Tracing",
    "abstract": "As the rapid development of Intelligent Tutoring Systems (ITS) in the past\ndecade, tracing the students' knowledge state has become more and more\nimportant in order to provide individualized learning guidance. This is the\nmain idea of Knowledge Tracing (KT), which models students' mastery of\nknowledge concepts (KCs, skills needed to solve a question) based on their past\ninteractions on platforms. Plenty of KT models have been proposed and have\nshown remarkable performance recently. However, the majority of these models\nuse concepts to index questions, which means the predefined skill tags for each\nquestion are required in advance to indicate the KCs needed to answer that\nquestion correctly. This makes it pretty hard to apply on large-scale online\neducation platforms where questions are often not well-organized by skill tags.\nIn this paper, we propose Q-matrix-based Attentive Knowledge Tracing (QAKT), an\nend-to-end style model that is able to apply the attentive method to scenes\nwhere no predefined skill tags are available without sacrificing its\nperformance. With a novel hybrid embedding method based on the q-matrix and\nRasch model, QAKT is capable of modeling problems hierarchically and learning\nthe q-matrix efficiently based on students' sequences. Meanwhile, the\narchitecture of QAKT ensures that it is friendly to questions associated with\nmultiple skills and has outstanding interpretability. After conducting\nexperiments on a variety of open datasets, we empirically validated that our\nmodel shows similar or even better performance than state-of-the-art KT\nmethods. Results of further experiments suggest that the q-matrix learned by\nQAKT is highly model-agnostic and more information-sufficient than the one\nlabeled by human experts, which could help with the data mining tasks in\nexisting ITSs."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.535978894,
    "title": "Towards Mitigating ChatGPT's Negative Impact on Education: Optimizing Question Design through Bloom's Taxonomy",
    "abstract": "The popularity of generative text AI tools in answering questions has led to\nconcerns regarding their potential negative impact on students' academic\nperformance and the challenges that educators face in evaluating student\nlearning. To address these concerns, this paper introduces an evolutionary\napproach that aims to identify the best set of Bloom's taxonomy keywords to\ngenerate questions that these tools have low confidence in answering. The\neffectiveness of this approach is evaluated through a case study that uses\nquestions from a Data Structures and Representation course being taught at the\nUniversity of New South Wales in Canberra, Australia. The results demonstrate\nthat the optimization algorithm is able to find keywords from different\ncognitive levels to create questions that ChatGPT has low confidence in\nanswering. This study is a step forward to offer valuable insights for\neducators seeking to create more effective questions that promote critical\nthinking among students."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -1.2480954748,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -1.027440103,
    "title": "Rearrangement Planning for General Part Assembly",
    "abstract": "Most successes in autonomous robotic assembly have been restricted to single\ntarget or category. We propose to investigate general part assembly, the task\nof creating novel target assemblies with unseen part shapes. As a fundamental\nstep to a general part assembly system, we tackle the task of determining the\nprecise poses of the parts in the target assembly, which we we term\n``rearrangement planning''. We present General Part Assembly Transformer\n(GPAT), a transformer-based model architecture that accurately predicts part\nposes by inferring how each part shape corresponds to the target shape. Our\nexperiments on both 3D CAD models and real-world scans demonstrate GPAT's\ngeneralization abilities to novel and diverse target and part shapes."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -1.2480954748,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -2.2260228842,
    "title": "Deep Reinforcement Learning Empowered Rate Selection of XP-HARQ",
    "abstract": "The complex transmission mechanism of cross-packet hybrid automatic repeat\nrequest (XP-HARQ) hinders its optimal system design. To overcome this\ndifficulty, this letter attempts to use the deep reinforcement learning (DRL)\nto solve the rate selection problem of XP-HARQ over correlated fading channels.\nIn particular, the long term average throughput (LTAT) is maximized by properly\nchoosing the incremental information rate for each HARQ round on the basis of\nthe outdated channel state information (CSI) available at the transmitter. The\nrate selection problem is first converted into a Markov decision process (MDP),\nwhich is then solved by capitalizing on the algorithm of deep deterministic\npolicy gradient (DDPG) with prioritized experience replay. The simulation\nresults finally corroborate the superiority of the proposed XP-HARQ scheme over\nthe conventional HARQ with incremental redundancy (HARQ-IR) and the XP-HARQ\nwith only statistical CSI."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 3.0890282145,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.7569770067,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 3.1229303951,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 2.1709094741,
    "rnd_investment_required_log": -1.535978894,
    "title": "Advancing Natural-Language Based Audio Retrieval with PaSST and Large Audio-Caption Data Sets",
    "abstract": "This work presents a text-to-audio-retrieval system based on pre-trained text\nand spectrogram transformers. Our method projects recordings and textual\ndescriptions into a shared audio-caption space in which related examples from\ndifferent modalities are close. Through a systematic analysis, we examine how\neach component of the system influences retrieval performance. As a result, we\nidentify two key components that play a crucial role in driving performance:\nthe self-attention-based audio encoder for audio embedding and the utilization\nof additional human-generated and synthetic data sets during pre-training. We\nfurther experimented with augmenting ClothoV2 captions with available keywords\nto increase their variety; however, this only led to marginal improvements. Our\nsystem ranked first in the 2023's DCASE Challenge, and it outperforms the\ncurrent state of the art on the ClothoV2 benchmark by 5.6 pp. mAP@10."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8651524162,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -1.027440103,
    "title": "Machine Learning aided Computer Architecture Design for CNN Inferencing Systems",
    "abstract": "Efficient and timely calculations of Machine Learning (ML) algorithms are\nessential for emerging technologies like autonomous driving, the Internet of\nThings (IoT), and edge computing. One of the primary ML algorithms used in such\nsystems is Convolutional Neural Networks (CNNs), which demand high\ncomputational resources. This requirement has led to the use of ML accelerators\nlike GPGPUs to meet design constraints. However, selecting the most suitable\naccelerator involves Design Space Exploration (DSE), a process that is usually\ntime-consuming and requires significant manual effort. Our work presents\napproaches to expedite the DSE process by identifying the most appropriate\nGPGPU for CNN inferencing systems. We have developed a quick and precise\ntechnique for forecasting the power and performance of CNNs during inference,\nwith a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computer\narchitects to estimate power and performance in the early stages of\ndevelopment, reducing the necessity for numerous prototypes. This saves time\nand money while also improving the time-to-market period."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Global in Local: A Convolutional Transformer for SAR ATR FSL",
    "abstract": "Convolutional neural networks (CNNs) have dominated the synthetic aperture\nradar (SAR) automatic target recognition (ATR) for years. However, under the\nlimited SAR images, the width and depth of the CNN-based models are limited,\nand the widening of the received field for global features in images is\nhindered, which finally leads to the low performance of recognition. To address\nthese challenges, we propose a Convolutional Transformer (ConvT) for SAR ATR\nfew-shot learning (FSL). The proposed method focuses on constructing a\nhierarchical feature representation and capturing global dependencies of local\nfeatures in each layer, named global in local. A novel hybrid loss is proposed\nto interpret the few SAR images in the forms of recognition labels and\ncontrastive image pairs, construct abundant anchor-positive and anchor-negative\nimage pairs in one batch and provide sufficient loss for the optimization of\nthe ConvT to overcome the few sample effect. An auto augmentation is proposed\nto enhance and enrich the diversity and amount of the few training samples to\nexplore the hidden feature in a few SAR images and avoid the over-fitting in\nSAR ATR FSL. Experiments conducted on the Moving and Stationary Target\nAcquisition and Recognition dataset (MSTAR) have shown the effectiveness of our\nproposed ConvT for SAR ATR FSL. Different from existing SAR ATR FSL methods\nemploying additional training datasets, our method achieved pioneering\nperformance without other SAR target images in training."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -2.6296726045,
    "title": "Membrane Potential Batch Normalization for Spiking Neural Networks",
    "abstract": "As one of the energy-efficient alternatives of conventional neural networks\n(CNNs), spiking neural networks (SNNs) have gained more and more interest\nrecently. To train the deep models, some effective batch normalization (BN)\ntechniques are proposed in SNNs. All these BNs are suggested to be used after\nthe convolution layer as usually doing in CNNs. However, the spiking neuron is\nmuch more complex with the spatio-temporal dynamics. The regulated data flow\nafter the BN layer will be disturbed again by the membrane potential updating\noperation before the firing function, i.e., the nonlinear activation.\nTherefore, we advocate adding another BN layer before the firing function to\nnormalize the membrane potential again, called MPBN. To eliminate the induced\ntime cost of MPBN, we also propose a training-inference-decoupled\nre-parameterization technique to fold the trained MPBN into the firing\nthreshold. With the re-parameterization technique, the MPBN will not introduce\nany extra time burden in the inference. Furthermore, the MPBN can also adopt\nthe element-wised form, while these BNs after the convolution layer can only\nuse the channel-wised form. Experimental results show that the proposed MPBN\nperforms well on both popular non-spiking static and neuromorphic datasets. Our\ncode is open-sourced at \\href{https:\/\/github.com\/yfguo91\/MPBN}{MPBN}."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.7611435848,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -2.6296726045,
    "title": "Temporal Interest Network for User Response Prediction",
    "abstract": "User response prediction is essential in industrial recommendation systems,\nsuch as online display advertising. Among all the features in recommendation\nmodels, user behaviors are among the most critical. Many works have revealed\nthat a user's behavior reflects her interest in the candidate item, owing to\nthe semantic or temporal correlation between behaviors and the candidate. While\nthe literature has individually examined each of these correlations,\nresearchers have yet to analyze them in combination, that is, the\nsemantic-temporal correlation. We empirically measure this correlation and\nobserve intuitive yet robust patterns. We then examine several popular user\ninterest models and find that, surprisingly, none of them learn such\ncorrelation well.\n  To fill this gap, we propose a Temporal Interest Network (TIN) to capture the\nsemantic-temporal correlation simultaneously between behaviors and the target.\nWe achieve this by incorporating target-aware temporal encoding, in addition to\nsemantic encoding, to represent behaviors and the target. Furthermore, we\nconduct explicit 4-way interaction by deploying target-aware attention and\ntarget-aware representation to capture both semantic and temporal correlation.\nWe conduct comprehensive evaluations on two popular public datasets, and our\nproposed TIN outperforms the best-performing baselines by 0.43% and 0.29% on\nGAUC, respectively. During online A\/B testing in Tencent's advertising\nplatform, TIN achieves 1.65% cost lift and 1.93% GMV lift over the base model.\nIt has been successfully deployed in production since October 2023, serving the\nWeChat Moments traffic. We have released our code at\nhttps:\/\/github.com\/zhouxy1003\/TIN."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": -1.7270042027,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -1.2480954748,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 2.3858924402,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Karma: Adaptive Video Streaming via Causal Sequence Modeling",
    "abstract": "Optimal adaptive bitrate (ABR) decision depends on a comprehensive\ncharacterization of state transitions that involve interrelated modalities over\ntime including environmental observations, returns, and actions. However,\nstate-of-the-art learning-based ABR algorithms solely rely on past observations\nto decide the next action. This paradigm tends to cause a chain of deviations\nfrom optimal action when encountering unfamiliar observations, which\nconsequently undermines the model generalization. This paper presents Karma, an\nABR algorithm that utilizes causal sequence modeling to improve generalization\nby comprehending the interrelated causality among past observations, returns,\nand actions and timely refining action when deviation occurs. Unlike direct\nobservation-to-action mapping, Karma recurrently maintains a multi-dimensional\ntime series of observations, returns, and actions as input and employs causal\nsequence modeling via a decision transformer to determine the next action. In\nthe input sequence, Karma uses the maximum cumulative future quality of\nexperience (QoE) (a.k.a, QoE-to-go) as an extended return signal, which is\nperiodically estimated based on current network conditions and playback status.\nWe evaluate Karma through trace-driven simulations and real-world field tests,\ndemonstrating superior performance compared to existing state-of-the-art ABR\nalgorithms, with an average QoE improvement ranging from 10.8% to 18.7% across\ndiverse network conditions. Furthermore, Karma exhibits strong generalization\ncapabilities, showing leading performance under unseen networks in both\nsimulations and real-world tests."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 2.5321252484,
    "rnd_investment_required_log": -1.027440103,
    "title": "MultiWay-Adapater: Adapting large-scale multi-modal models for scalable image-text retrieval",
    "abstract": "As Multimodal Large Language Models (MLLMs) grow in size, adapting them to\nspecialized tasks becomes increasingly challenging due to high computational\nand memory demands. Indeed, traditional fine-tuning methods are costly, due to\nthe need for extensive, task-specific training. While efficient adaptation\nmethods exist that aim to reduce these costs, in practice they suffer from\nshallow inter-modal alignment, which severely hurts model effectiveness. To\ntackle these computational challenges and improve inter-modal alignment, we\nintroduce the MultiWay-Adapter (MWA), a novel framework featuring an 'Alignment\nEnhancer'. This enhancer deepens inter-modal alignment, enabling high\ntransferability with minimal tuning effort. Our experiments show that unlike\nprior efficient tuning approaches, MWA maintains model effectiveness, while\nreducing training time by up-to 57%. MWA is also lightweight, increasing model\nsize by only 2-3% (in terms of parameters) for state-of-the-art foundation\nmodels like BEiT-3 Large. These results demonstrate that MWA provides an\nefficient and effective adaptation method for MLLMs, significantly broadening\ntheir applicability."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -2.4046617919,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.7569770067,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Recognition of Heat-Induced Food State Changes by Time-Series Use of Vision-Language Model for Cooking Robot",
    "abstract": "Cooking tasks are characterized by large changes in the state of the food,\nwhich is one of the major challenges in robot execution of cooking tasks. In\nparticular, cooking using a stove to apply heat to the foodstuff causes many\nspecial state changes that are not seen in other tasks, making it difficult to\ndesign a recognizer. In this study, we propose a unified method for recognizing\nchanges in the cooking state of robots by using the vision-language model that\ncan discriminate open-vocabulary objects in a time-series manner. We collected\ndata on four typical state changes in cooking using a real robot and confirmed\nthe effectiveness of the proposed method. We also compared the conditions and\ndiscussed the types of natural language prompts and the image regions that are\nsuitable for recognizing the state changes."
  },
  {
    "CAGR": 1.8688604156,
    "years_to_50pct_penetration": -2.1878823392,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -1.027440103,
    "title": "ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning",
    "abstract": "Logical rules are essential for uncovering the logical connections between\nrelations, which could improve reasoning performance and provide interpretable\nresults on knowledge graphs (KGs). Although there have been many efforts to\nmine meaningful logical rules over KGs, existing methods suffer from\ncomputationally intensive searches over the rule space and a lack of\nscalability for large-scale KGs. Besides, they often ignore the semantics of\nrelations which is crucial for uncovering logical connections. Recently, large\nlanguage models (LLMs) have shown impressive performance in the field of\nnatural language processing and various applications, owing to their emergent\nability and generalizability. In this paper, we propose a novel framework,\nChatRule, unleashing the power of large language models for mining logical\nrules over knowledge graphs. Specifically, the framework is initiated with an\nLLM-based rule generator, leveraging both the semantic and structural\ninformation of KGs to prompt LLMs to generate logical rules. To refine the\ngenerated rules, a rule ranking module estimates the rule quality by\nincorporating facts from existing KGs. Last, the ranked rules can be used to\nconduct reasoning over KGs. ChatRule is evaluated on four large-scale KGs,\nw.r.t. different rule quality metrics and downstream tasks, showing the\neffectiveness and scalability of our method."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -2.6296726045,
    "title": "DCAlign v1.0: Aligning biological sequences using co-evolution models and informed priors",
    "abstract": "DCAlign is a new alignment method able to cope with the conservation and the\nco-evolution signals that characterize the columns of multiple sequence\nalignments of homologous sequences. However, the pre-processing steps required\nto align a candidate sequence are computationally demanding. We show in v1.0\nhow to dramatically reduce the overall computing time by including an empirical\nprior over an informative set of variables mirroring the presence of insertions\nand deletions."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -1.7569770067,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -1.9396287803,
    "title": "Prompt-based Node Feature Extractor for Few-shot Learning on Text-Attributed Graphs",
    "abstract": "Text-attributed Graphs (TAGs) are commonly found in the real world, such as\nsocial networks and citation networks, and consist of nodes represented by\ntextual descriptions. Currently, mainstream machine learning methods on TAGs\ninvolve a two-stage modeling approach: (1) unsupervised node feature extraction\nwith pre-trained language models (PLMs); and (2) supervised learning using\nGraph Neural Networks (GNNs). However, we observe that these representations,\nwhich have undergone large-scale pre-training, do not significantly improve\nperformance with a limited amount of training samples. The main issue is that\nexisting methods have not effectively integrated information from the graph and\ndownstream tasks simultaneously. In this paper, we propose a novel framework\ncalled G-Prompt, which combines a graph adapter and task-specific prompts to\nextract node features. First, G-Prompt introduces a learnable GNN layer\n(\\emph{i.e.,} adaptor) at the end of PLMs, which is fine-tuned to better\ncapture the masked tokens considering graph neighborhood information. After the\nadapter is trained, G-Prompt incorporates task-specific prompts to obtain\n\\emph{interpretable} node representations for the downstream task. Our\nexperiment results demonstrate that our proposed method outperforms current\nstate-of-the-art (SOTA) methods on few-shot node classification. More\nimportantly, in zero-shot settings, the G-Prompt embeddings can not only\nprovide better task interpretability than vanilla PLMs but also achieve\ncomparable performance with fully-supervised baselines."
  },
  {
    "CAGR": -1.4452652355,
    "years_to_50pct_penetration": -2.1878823392,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -2.1878056075,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.3373958805,
    "title": "A deep Natural Language Inference predictor without language-specific training data",
    "abstract": "In this paper we present a technique of NLP to tackle the problem of\ninference relation (NLI) between pairs of sentences in a target language of\nchoice without a language-specific training dataset. We exploit a generic\ntranslation dataset, manually translated, along with two instances of the same\npre-trained model - the first to generate sentence embeddings for the source\nlanguage, and the second fine-tuned over the target language to mimic the\nfirst. This technique is known as Knowledge Distillation. The model has been\nevaluated over machine translated Stanford NLI test dataset, machine translated\nMulti-Genre NLI test dataset, and manually translated RTE3-ITA test dataset. We\nalso test the proposed architecture over different tasks to empirically\ndemonstrate the generality of the NLI task. The model has been evaluated over\nthe native Italian ABSITA dataset, on the tasks of Sentiment Analysis,\nAspect-Based Sentiment Analysis, and Topic Recognition. We emphasise the\ngenerality and exploitability of the Knowledge Distillation technique that\noutperforms other methodologies based on machine translation, even though the\nformer was not directly trained on the data it was tested over."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.0164407866,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.5711776239,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": 0.0662541385,
    "title": "View Classification and Object Detection in Cardiac Ultrasound to Localize Valves via Deep Learning",
    "abstract": "Echocardiography provides an important tool for clinicians to observe the\nfunction of the heart in real time, at low cost, and without harmful radiation.\nAutomated localization and classification of heart valves enables automatic\nextraction of quantities associated with heart mechanical function and related\nblood flow measurements. We propose a machine learning pipeline that uses deep\nneural networks for separate classification and localization steps. As the\nfirst step in the pipeline, we apply view classification to echocardiograms\nwith ten unique anatomic views of the heart. In the second step, we apply deep\nlearning-based object detection to both localize and identify the valves. Image\nsegmentation based object detection in echocardiography has been shown in many\nearlier studies but, to the best of our knowledge, this is the first study that\npredicts the bounding boxes around the valves along with classification from 2D\nultrasound images with the help of deep neural networks. Our object detection\nexperiments applied to the Apical views suggest that it is possible to localize\nand identify multiple valves precisely."
  },
  {
    "CAGR": -0.2715124007,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": -1.027440103,
    "title": "YOLOv8-Based Visual Detection of Road Hazards: Potholes, Sewer Covers, and Manholes",
    "abstract": "Effective detection of road hazards plays a pivotal role in road\ninfrastructure maintenance and ensuring road safety. This research paper\nprovides a comprehensive evaluation of YOLOv8, an object detection model, in\nthe context of detecting road hazards such as potholes, Sewer Covers, and Man\nHoles. A comparative analysis with previous iterations, YOLOv5 and YOLOv7, is\nconducted, emphasizing the importance of computational efficiency in various\napplications. The paper delves into the architecture of YOLOv8 and explores\nimage preprocessing techniques aimed at enhancing detection accuracy across\ndiverse conditions, including variations in lighting, road types, hazard sizes,\nand types. Furthermore, hyperparameter tuning experiments are performed to\noptimize model performance through adjustments in learning rates, batch sizes,\nanchor box sizes, and augmentation strategies. Model evaluation is based on\nMean Average Precision (mAP), a widely accepted metric for object detection\nperformance. The research assesses the robustness and generalization\ncapabilities of the models through mAP scores calculated across the diverse\ntest scenarios, underlining the significance of YOLOv8 in road hazard detection\nand infrastructure maintenance."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.7591256167,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Fast, multicolour optical sectioning over extended fields of view by combining interferometric SIM with machine learning",
    "abstract": "Structured illumination can reject out-of-focus signal from a sample,\nenabling high-speed and high-contrast imaging over large areas with widefield\ndetection optics. Currently, this optical-sectioning technique is limited by\nimage reconstruction artefacts and the need for sequential imaging of multiple\ncolour channels. We combine multicolour interferometric pattern generation with\nmachine-learning processing, permitting high-contrast, real-time reconstruction\nof image data. The method is insensitive to background noise and unevenly\nphase-stepped illumination patterns. We validate the method in silico and\ndemonstrate its application on diverse specimens, ranging from fixed and live\nbiological cells to synthetic biosystems, imaging at up to 37 Hz across a 44 x\n44 $\\mu m^2$ field of view."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.0192437628,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.3930636585,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Bandit-Driven Batch Selection for Robust Learning under Label Noise",
    "abstract": "We introduce a novel approach for batch selection in Stochastic Gradient\nDescent (SGD) training, leveraging combinatorial bandit algorithms. Our\nmethodology focuses on optimizing the learning process in the presence of label\nnoise, a prevalent issue in real-world datasets. Experimental evaluations on\nthe CIFAR-10 dataset reveal that our approach consistently outperforms existing\nmethods across various levels of label corruption. Importantly, we achieve this\nsuperior performance without incurring the computational overhead commonly\nassociated with auxiliary neural network models. This work presents a balanced\ntrade-off between computational efficiency and model efficacy, offering a\nscalable solution for complex machine learning applications."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.0192437628,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 1.876511833,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 2.2076095446,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Rethinking the Cloudonomics of Efficient I\/O for Data-Intensive Analytics Applications",
    "abstract": "This paper explores a prevailing trend in the industry: migrating\ndata-intensive analytics applications from on-premises to cloud-native\nenvironments. We find that the unique cost models associated with cloud-based\nstorage necessitate a more nuanced understanding of optimizing performance.\nSpecifically, based on traces collected from Uber's Presto fleet in production,\nwe argue that common I\/O optimizations, such as table scan and filter, and\nbroadcast join, may lead to unexpected costs when naively applied in the cloud.\nThis is because traditional I\/O optimizations mainly focus on improving\nthroughput or latency in on-premises settings, without taking into account the\nmonetary costs associated with storage API calls. In cloud environments, these\ncosts can be significant, potentially involving billions of API calls per day\njust for Presto workloads at Uber scale. Presented as a case study, this paper\nserves as a starting point for further research to design efficient I\/O\nstrategies specifically tailored for data-intensive applications in cloud\nsettings."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -2.1304791372,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Image Restoration with Point Spread Function Regularization and Active Learning",
    "abstract": "Large-scale astronomical surveys can capture numerous images of celestial\nobjects, including galaxies and nebulae. Analysing and processing these images\ncan reveal intricate internal structures of these objects, allowing researchers\nto conduct comprehensive studies on their morphology, evolution, and physical\nproperties. However, varying noise levels and point spread functions can hamper\nthe accuracy and efficiency of information extraction from these images. To\nmitigate these effects, we propose a novel image restoration algorithm that\nconnects a deep learning-based restoration algorithm with a high-fidelity\ntelescope simulator. During the training stage, the simulator generates images\nwith different levels of blur and noise to train the neural network based on\nthe quality of restored images. After training, the neural network can directly\nrestore images obtained by the telescope, as represented by the simulator. We\nhave tested the algorithm using real and simulated observation data and have\nfound that it effectively enhances fine structures in blurry images and\nincreases the quality of observation images. This algorithm can be applied to\nlarge-scale sky survey data, such as data obtained by LSST, Euclid, and CSST,\nto further improve the accuracy and efficiency of information extraction,\npromoting advances in the field of astronomical research."
  },
  {
    "CAGR": -1.0033818153,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.9283973715,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3894497787,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.3526483917,
    "title": "StableFDG: Style and Attention Based Learning for Federated Domain Generalization",
    "abstract": "Traditional federated learning (FL) algorithms operate under the assumption\nthat the data distributions at training (source domains) and testing (target\ndomain) are the same. The fact that domain shifts often occur in practice\nnecessitates equipping FL methods with a domain generalization (DG) capability.\nHowever, existing DG algorithms face fundamental challenges in FL setups due to\nthe lack of samples\/domains in each client's local dataset. In this paper, we\npropose StableFDG, a style and attention based learning strategy for\naccomplishing federated domain generalization, introducing two key\ncontributions. The first is style-based learning, which enables each client to\nexplore novel styles beyond the original source domains in its local dataset,\nimproving domain diversity based on the proposed style sharing, shifting, and\nexploration strategies. Our second contribution is an attention-based feature\nhighlighter, which captures the similarities between the features of data\nsamples in the same class, and emphasizes the important\/common characteristics\nto better learn the domain-invariant characteristics of each class in data-poor\nFL scenarios. Experimental results show that StableFDG outperforms existing\nbaselines on various DG benchmark datasets, demonstrating its efficacy."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.8143831059,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Architecture of Data Anomaly Detection-Enhanced Decentralized Expert System for Early-Stage Alzheimer's Disease Prediction",
    "abstract": "Alzheimer's Disease is a global health challenge that requires early and\naccurate detection to improve patient outcomes. Magnetic Resonance Imaging\n(MRI) holds significant diagnostic potential, but its effective analysis\nremains a formidable task. This study introduces a groundbreaking decentralized\nexpert system that cleverly combines blockchain technology with Artificial\nIntelligence (AI) to integrate robust anomaly detection for patient-submitted\ndata.\n  Traditional diagnostic methods often lead to delayed and imprecise\npredictions, especially in the early stages of the disease. Centralized data\nrepositories struggle to manage the immense volumes of MRI data, and persistent\nprivacy concerns hinder collaborative efforts. Our innovative solution\nharnesses decentralization to protect data integrity and patient privacy,\nfacilitated by blockchain technology. It not only emphasizes AI-driven MRI\nanalysis but also incorporates a sophisticated data anomaly detection\narchitecture. These mechanisms scrutinize patient-contributed data for various\nissues, including data quality problems and atypical findings within MRI\nimages.\n  Conducting an exhaustive check of MRI image correctness and quality directly\non the blockchain is impractical due to computational complexity and cost\nconstraints. Typically, such checks are performed off-chain, and the blockchain\nsecurely records the results. This comprehensive approach empowers our\ndecentralized app to provide more precise early-stage Alzheimer's Disease\npredictions. By merging the strengths of blockchain, AI, and anomaly detection,\nour system represents a pioneering step towards revolutionizing disease\ndiagnostics."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.7036515238,
    "ROI_percent": -1.1035246851,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.6914176643,
    "rnd_investment_required_log": 2.1363870464,
    "title": "RoboVQA: Multimodal Long-Horizon Reasoning for Robotics",
    "abstract": "We present a scalable, bottom-up and intrinsically diverse data collection\nscheme that can be used for high-level reasoning with long and medium horizons\nand that has 2.2x higher throughput compared to traditional narrow top-down\nstep-by-step collection. We collect realistic data by performing any user\nrequests within the entirety of 3 office buildings and using multiple robot and\nhuman embodiments. With this data, we show that models trained on all\nembodiments perform better than ones trained on the robot data only, even when\nevaluated solely on robot episodes. We find that for a fixed collection budget\nit is beneficial to take advantage of cheaper human collection along with robot\ncollection. We release a large and highly diverse (29,520 unique instructions)\ndataset dubbed RoboVQA containing 829,502 (video, text) pairs for\nrobotics-focused visual question answering. We also demonstrate how evaluating\nreal robot experiments with an intervention mechanism enables performing tasks\nto completion, making it deployable with human oversight even if imperfect\nwhile also providing a single performance metric. We demonstrate a single\nvideo-conditioned model named RoboVQA-VideoCoCa trained on our dataset that is\ncapable of performing a variety of grounded high-level reasoning tasks in broad\nrealistic settings with a cognitive intervention rate 46% lower than the\nzero-shot state of the art visual language model (VLM) baseline and is able to\nguide real robots through long-horizon tasks. The performance gap with\nzero-shot state-of-the-art models indicates that a lot of grounded data remains\nto be collected for real-world deployment, emphasizing the critical need for\nscalable data collection approaches. Finally, we show that video VLMs\nsignificantly outperform single-image VLMs with an average error rate reduction\nof 19% across all VQA tasks. Data and videos available at\nhttps:\/\/robovqa.github.io"
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Concatenated Masked Autoencoders as Spatial-Temporal Learner",
    "abstract": "Learning representations from videos requires understanding continuous motion\nand visual correspondences between frames. In this paper, we introduce the\nConcatenated Masked Autoencoders (CatMAE) as a spatial-temporal learner for\nself-supervised video representation learning. For the input sequence of video\nframes, CatMAE keeps the initial frame unchanged while applying substantial\nmasking (95%) to subsequent frames. The encoder in CatMAE is responsible for\nencoding visible patches for each frame individually; subsequently, for each\nmasked frame, the decoder leverages visible patches from both previous and\ncurrent frames to reconstruct the original image. Our proposed method enables\nthe model to estimate the motion information between visible patches, match the\ncorrespondences between preceding and succeeding frames, and ultimately learn\nthe evolution of scenes. Furthermore, we propose a new data augmentation\nstrategy, Video-Reverse (ViRe), which uses reversed video frames as the model's\nreconstruction targets. This further encourages the model to utilize continuous\nmotion details and correspondences to complete the reconstruction, thereby\nenhancing the model's capabilities. Compared to the most advanced pre-training\nmethods, CatMAE achieves a leading level in video segmentation tasks and action\nrecognition tasks."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1334390599,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Using Augmented Reality to Assess and Modify Mobile Manipulator Surface Repair Plans",
    "abstract": "Industrial robotics are redefining inspection and maintenance routines across\nmultiple sectors, enhancing safety, efficiency, and environmental\nsustainability. In outdoor industrial facilities, it is crucial to inspect and\nrepair complex surfaces affected by corrosion. To address this challenge,\nmobile manipulators have been developed to navigate these facilities, identify\ncorroded areas, and apply protective coatings. However, given that this\ntechnology is still in its infancy and the consequences of improperly coating\nessential equipment can be significant, human oversight is necessary to review\nthe robot's corrosion identification and repair plan. We present a practical\nand scalable Augmented Reality (AR)-based system designed to empower\nnon-experts to visualize, modify, and approve robot-generated surface corrosion\nrepair plans in real-time. Built upon an AR-based human-robot interaction\nframework, Augmented Robot Environment (AugRE), we developed a comprehensive AR\napplication module called Situational Task Accept and Repair (STAR). STAR\nallows users to examine identified corrosion images, point cloud data, and\nrobot navigation objectives overlaid on the physical environment within these\nindustrial environments. Users are able to additionally make adjustments to the\nrobot repair plan in real-time using interactive holographic volumes, excluding\ncritical nearby equipment that might be at risk of coating overspray. We\ndemonstrate the entire system using a Microsoft HoloLens 2 and a dual-arm\nmobile manipulator. Our future research will focus on evaluating user\nexperience, system robustness, and real-world validation."
  },
  {
    "CAGR": -0.3129389713,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.552836402,
    "annual_revenue_USD_log": 2.1709094741,
    "rnd_investment_required_log": 1.4463427327,
    "title": "Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning for Medical Image Captioning",
    "abstract": "With the development of multimodality and large language models, the deep\nlearning-based technique for medical image captioning holds the potential to\noffer valuable diagnostic recommendations. However, current generic text and\nimage pre-trained models do not yield satisfactory results when it comes to\ndescribing intricate details within medical images. In this paper, we present a\nnovel medical image captioning method guided by the segment anything model\n(SAM) to enable enhanced encoding with both general and detailed feature\nextraction. In addition, our approach employs a distinctive pre-training\nstrategy with mixed semantic learning to simultaneously capture both the\noverall information and finer details within medical images. We demonstrate the\neffectiveness of this approach, as it outperforms the pre-trained BLIP2 model\non various evaluation metrics for generating descriptions of medical images."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8631889569,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview Learning for Medical Image Segmentation",
    "abstract": "The utilisation of deep learning segmentation algorithms that learn complex\norgans and tissue patterns and extract essential regions of interest from the\nnoisy background to improve the visual ability for medical image diagnosis has\nachieved impressive results in Medical Image Computing (MIC). This thesis\nfocuses on retinal blood vessel segmentation tasks, providing an extensive\nliterature review of deep learning-based medical image segmentation approaches\nwhile comparing the methodologies and empirical performances. The work also\nexamines the limitations of current state-of-the-art methods by pointing out\nthe two significant existing limitations: data size constraints and the\ndependency on high computational resources. To address such problems, this work\nproposes a novel efficient, simple multiview learning framework that\ncontrastively learns invariant vessel feature representation by comparing with\nmultiple augmented views by various transformations to overcome data shortage\nand improve generalisation ability. Moreover, the hybrid network architecture\nintegrates the attention mechanism into a Convolutional Neural Network to\nfurther capture complex continuous curvilinear vessel structures. The result\ndemonstrates the proposed method validated on the CHASE-DB1 dataset, attaining\nthe highest F1 score of 83.46% and the highest Intersection over Union (IOU)\nscore of 71.62% with UNet structure, surpassing existing benchmark UNet-based\nmethods by 1.95% and 2.8%, respectively. The combination of the metrics\nindicates the model detects the vessel object accurately with a highly\ncoincidental location with the ground truth. Moreover, the proposed approach\ncould be trained within 30 minutes by consuming less than 3 GB GPU RAM, and\nsuch characteristics support the efficient implementation for real-world\napplications and deployments."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -1.7270042027,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 0.7758955802,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.3861709233,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.2495847072,
    "title": "Collaboration and Transition: Distilling Item Transitions into Multi-Query Self-Attention for Sequential Recommendation",
    "abstract": "Modern recommender systems employ various sequential modules such as\nself-attention to learn dynamic user interests. However, these methods are less\neffective in capturing collaborative and transitional signals within user\ninteraction sequences. First, the self-attention architecture uses the\nembedding of a single item as the attention query, making it challenging to\ncapture collaborative signals. Second, these methods typically follow an\nauto-regressive framework, which is unable to learn global item transition\npatterns. To overcome these limitations, we propose a new method called\nMulti-Query Self-Attention with Transition-Aware Embedding Distillation\n(MQSA-TED). First, we propose an $L$-query self-attention module that employs\nflexible window sizes for attention queries to capture collaborative signals.\nIn addition, we introduce a multi-query self-attention method that balances the\nbias-variance trade-off in modeling user preferences by combining long and\nshort-query self-attentions. Second, we develop a transition-aware embedding\ndistillation module that distills global item-to-item transition patterns into\nitem embeddings, which enables the model to memorize and leverage transitional\nsignals and serves as a calibrator for collaborative signals. Experimental\nresults on four real-world datasets demonstrate the effectiveness of the\nproposed modules."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.5073055989,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.2047175397,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.5175734475,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": 1.2648373378,
    "title": "AiluRus: A Scalable ViT Framework for Dense Prediction",
    "abstract": "Vision transformers (ViTs) have emerged as a prevalent architecture for\nvision tasks owing to their impressive performance. However, when it comes to\nhandling long token sequences, especially in dense prediction tasks that\nrequire high-resolution input, the complexity of ViTs increases significantly.\nNotably, dense prediction tasks, such as semantic segmentation or object\ndetection, emphasize more on the contours or shapes of objects, while the\ntexture inside objects is less informative. Motivated by this observation, we\npropose to apply adaptive resolution for different regions in the image\naccording to their importance. Specifically, at the intermediate layer of the\nViT, we utilize a spatial-aware density-based clustering algorithm to select\nrepresentative tokens from the token sequence. Once the representative tokens\nare determined, we proceed to merge other tokens into their closest\nrepresentative token. Consequently, semantic similar tokens are merged together\nto form low-resolution regions, while semantic irrelevant tokens are preserved\nindependently as high-resolution regions. This strategy effectively reduces the\nnumber of tokens, allowing subsequent layers to handle a reduced token sequence\nand achieve acceleration. We evaluate our proposed method on three different\ndatasets and observe promising performance. For example, the \"Segmenter ViT-L\"\nmodel can be accelerated by 48% FPS without fine-tuning, while maintaining the\nperformance. Additionally, our method can be applied to accelerate fine-tuning\nas well. Experimental results demonstrate that we can save 52% training time\nwhile accelerating 2.46 times FPS with only a 0.09% performance drop. The code\nis available at https:\/\/github.com\/caddyless\/ailurus\/tree\/main."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.8602437681,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": -0.692474134,
    "title": "MirrorNet: A TEE-Friendly Framework for Secure On-device DNN Inference",
    "abstract": "Deep neural network (DNN) models have become prevalent in edge devices for\nreal-time inference. However, they are vulnerable to model extraction attacks\nand require protection. Existing defense approaches either fail to fully\nsafeguard model confidentiality or result in significant latency issues. To\novercome these challenges, this paper presents MirrorNet, which leverages\nTrusted Execution Environment (TEE) to enable secure on-device DNN inference.\nIt generates a TEE-friendly implementation for any given DNN model to protect\nthe model confidentiality, while meeting the stringent computation and storage\nconstraints of TEE. The framework consists of two key components: the backbone\nmodel (BackboneNet), which is stored in the normal world but achieves lower\ninference accuracy, and the Companion Partial Monitor (CPM), a lightweight\nmirrored branch stored in the secure world, preserving model confidentiality.\nDuring inference, the CPM monitors the intermediate results from the\nBackboneNet and rectifies the classification output to achieve higher accuracy.\nTo enhance flexibility, MirrorNet incorporates two modules: the CPM Strategy\nGenerator, which generates various protection strategies, and the Performance\nEmulator, which estimates the performance of each strategy and selects the most\noptimal one. Extensive experiments demonstrate the effectiveness of MirrorNet\nin providing security guarantees while maintaining low computation latency,\nmaking MirrorNet a practical and promising solution for secure on-device DNN\ninference. For the evaluation, MirrorNet can achieve a 18.6% accuracy gap\nbetween authenticated and illegal use, while only introducing 0.99% hardware\noverhead."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.5899504433,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.1599484684,
    "title": "Atoms as Words: A Novel Approach to Deciphering Material Properties using NLP-inspired Machine Learning on Crystallographic Information Files (CIFs)",
    "abstract": "In condensed matter physics and materials science, predicting material\nproperties necessitates understanding intricate many-body interactions.\nConventional methods such as density functional theory (DFT) and molecular\ndynamics (MD) often resort to simplifying approximations and are\ncomputationally expensive. Meanwhile, recent machine learning methods use\nhandcrafted descriptors for material representation which sometimes neglect\nvital crystallographic information and are often limited to single property\nprediction or a sub-class of crystal structures. In this study, we pioneer an\nunsupervised strategy, drawing inspiration from Natural Language Processing\n(NLP), to harness the underutilized potential of Crystallographic Information\nFiles (CIFs). We conceptualize atoms and atomic positions within a CIF\nsimilarly to words in textual content. Using a Word2Vec-inspired technique, we\nproduce atomic embeddings that capture intricate atomic relationships. Our\nmodel, CIFSemantics, trained on the extensive Material Project dataset, adeptly\npredicts 15 distinct material properties from the CIFs. Its performance rivals\nspecialized models, marking a significant step forward in material property\npredictions."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 2.3661742663,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 2.3743681906,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.1167994539,
    "annual_revenue_USD_log": 0.025748487,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Real-Time Adaptive Neural Network on FPGA: Enhancing Adaptability through Dynamic Classifier Selection",
    "abstract": "This research studies an adaptive neural network with a Dynamic Classifier\nSelection framework on Field-Programmable Gate Arrays (FPGAs). The evaluations\nare conducted across three different datasets. By adjusting parameters, the\narchitecture surpasses all models in the ensemble set in accuracy and shows an\nimprovement of up to 8% compared to a singular neural network implementation.\nThe research also emphasizes considerable resource savings of up to 109.28%,\nachieved via partial reconfiguration rather than a traditional fixed approach.\nSuch improved efficiency suggests that the architecture is ideal for settings\nlimited by computational capacity, like in edge computing scenarios. The\ncollected data highlights the architecture's two main benefits: high\nperformance and real-world application, signifying a notable input to\nFPGA-based ensemble learning methods."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9086309264,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": 0.5747930357,
    "title": "NGEL-SLAM: Neural Implicit Representation-based Global Consistent Low-Latency SLAM System",
    "abstract": "Neural implicit representations have emerged as a promising solution for\nproviding dense geometry in Simultaneous Localization and Mapping (SLAM).\nHowever, existing methods in this direction fall short in terms of global\nconsistency and low latency. This paper presents NGEL-SLAM to tackle the above\nchallenges. To ensure global consistency, our system leverages a traditional\nfeature-based tracking module that incorporates loop closure. Additionally, we\nmaintain a global consistent map by representing the scene using multiple\nneural implicit fields, enabling quick adjustment to the loop closure.\nMoreover, our system allows for fast convergence through the use of\noctree-based implicit representations. The combination of rapid response to\nloop closure and fast convergence makes our system a truly low-latency system\nthat achieves global consistency. Our system enables rendering high-fidelity\nRGB-D images, along with extracting dense and complete surfaces. Experiments on\nboth synthetic and real-world datasets suggest that our system achieves\nstate-of-the-art tracking and mapping accuracy while maintaining low latency."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -1.7270042027,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 0.6313247906,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.516046306,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Towards Serverless Optimization with In-place Scaling",
    "abstract": "Serverless computing has gained popularity due to its cost efficiency, ease\nof deployment, and enhanced scalability. However, in serverless environments,\nservers are initiated only after receiving a request, leading to increased\nresponse times. This delay is commonly known as the cold start problem. In this\nstudy, we explore the in-place scaling feature released in Kubernetes v1.27 and\nexamine its impact on serverless computing. Our experimental results reveal\nimprovements in request latency, with reductions ranging from 1.16 to 18.15\ntimes across various workloads when compared to traditional cold policy."
  },
  {
    "CAGR": -0.8929109603,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Multi-Task Learning Approach for Unified Biometric Estimation from Fetal Ultrasound Anomaly Scans",
    "abstract": "Precise estimation of fetal biometry parameters from ultrasound images is\nvital for evaluating fetal growth, monitoring health, and identifying potential\ncomplications reliably. However, the automated computerized segmentation of the\nfetal head, abdomen, and femur from ultrasound images, along with the\nsubsequent measurement of fetal biometrics, remains challenging. In this work,\nwe propose a multi-task learning approach to classify the region into head,\nabdomen and femur as well as estimate the associated parameters. We were able\nto achieve a mean absolute error (MAE) of 1.08 mm on head circumference, 1.44\nmm on abdomen circumference and 1.10 mm on femur length with a classification\naccuracy of 99.91\\% on a dataset of fetal Ultrasound images. To achieve this,\nwe leverage a weighted joint classification and segmentation loss function to\ntrain a U-Net architecture with an added classification head. The code can be\naccessed through\n\\href{https:\/\/github.com\/BioMedIA-MBZUAI\/Multi-Task-Learning-Approach-for-Unified-Biometric-Estimation-from-Fetal-Ultrasound-Anomaly-Scans.git}{\\texttt{Github}"
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.0271308869,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.3086955919,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Online Continual Knowledge Learning for Language Models",
    "abstract": "Large Language Models (LLMs) serve as repositories of extensive world\nknowledge, enabling them to perform tasks such as question-answering and\nfact-checking. However, this knowledge can become obsolete as global contexts\nchange. In this paper, we introduce a novel problem in the realm of continual\nlearning: Online Continual Knowledge Learning (OCKL). This problem formulation\naims to manage the dynamic nature of world knowledge in LMs under real-time\nconstraints. We propose a new benchmark and evaluation metric designed to\nmeasure both the rate of new knowledge acquisition and the retention of\npreviously learned knowledge. Our empirical evaluation, conducted using a\nvariety of state-of-the-art methods, establishes robust base-lines for OCKL.\nOur results reveal that existing continual learning approaches are\nunfortunately insufficient for tackling the unique challenges posed by OCKL. We\nidentify key factors that influence the trade-off between knowledge acquisition\nand retention, thereby advancing our understanding of how to train LMs in a\ncontinually evolving environment."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.0817321758,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Redefining the Laparoscopic Spatial Sense: AI-based Intra- and Postoperative Measurement from Stereoimages",
    "abstract": "A significant challenge in image-guided surgery is the accurate measurement\ntask of relevant structures such as vessel segments, resection margins, or\nbowel lengths. While this task is an essential component of many surgeries, it\ninvolves substantial human effort and is prone to inaccuracies. In this paper,\nwe develop a novel human-AI-based method for laparoscopic measurements\nutilizing stereo vision that has been guided by practicing surgeons. Based on a\nholistic qualitative requirements analysis, this work proposes a comprehensive\nmeasurement method, which comprises state-of-the-art machine learning\narchitectures, such as RAFT-Stereo and YOLOv8. The developed method is assessed\nin various realistic experimental evaluation environments. Our results outline\nthe potential of our method achieving high accuracies in distance measurements\nwith errors below 1 mm. Furthermore, on-surface measurements demonstrate\nrobustness when applied in challenging environments with textureless regions.\nOverall, by addressing the inherent challenges of image-guided surgery, we lay\nthe foundation for a more robust and accurate solution for intra- and\npostoperative measurements, enabling more precise, safe, and efficient surgical\nprocedures."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.5073055989,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.9786301475,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Graph Elicitation for Guiding Multi-Step Reasoning in Large Language Models",
    "abstract": "Chain-of-Thought (CoT) prompting along with sub-question generation and\nanswering has enhanced multi-step reasoning capabilities of Large Language\nModels (LLMs). However, prompting the LLMs to directly generate sub-questions\nis suboptimal since they sometimes generate redundant or irrelevant questions.\nTo deal with them, we propose a GE-Reasoning method, which directs LLMs to\ngenerate proper sub-questions and corresponding answers. Concretely, given an\ninput question, we first prompt the LLM to generate knowledge triplets, forming\na graph representation of the question. Unlike conventional knowledge triplets,\nour approach allows variables as head or tail entities, effectively\nrepresenting a question as knowledge triplets. Second, for each triplet, the\nLLM generates a corresponding sub-question and answer along with using\nknowledge retrieval. If the prediction confidence exceeds a threshold, the\nsub-question and prediction are incorporated into the prompt for subsequent\nprocessing. This approach encourages that sub-questions are grounded in the\nextracted knowledge triplets, reducing redundancy and irrelevance. Our\nexperiments demonstrate that our approach outperforms previous CoT prompting\nmethods and their variants on multi-hop question answering benchmark datasets."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": -1.0144332116,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Improving Unimodal Inference with Multimodal Transformers",
    "abstract": "This paper proposes an approach for improving performance of unimodal models\nwith multimodal training. Our approach involves a multi-branch architecture\nthat incorporates unimodal models with a multimodal transformer-based branch.\nBy co-training these branches, the stronger multimodal branch can transfer its\nknowledge to the weaker unimodal branches through a multi-task objective,\nthereby improving the performance of the resulting unimodal models. We evaluate\nour approach on tasks of dynamic hand gesture recognition based on RGB and\nDepth, audiovisual emotion recognition based on speech and facial video, and\naudio-video-text based sentiment analysis. Our approach outperforms the\nconventionally trained unimodal counterparts. Interestingly, we also observe\nthat optimization of the unimodal branches improves the multimodal branch,\ncompared to a similar multimodal model trained from scratch."
  },
  {
    "CAGR": -0.0643795475,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 2.274418923,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.5710893717,
    "annual_revenue_USD_log": 0.6432509228,
    "rnd_investment_required_log": -0.1152512465,
    "title": "You Cannot Escape Me: Detecting Evasions of SIEM Rules in Enterprise Networks",
    "abstract": "Cyberattacks have grown into a major risk for organizations, with common\nconsequences being data theft, sabotage, and extortion. Since preventive\nmeasures do not suffice to repel attacks, timely detection of successful\nintruders is crucial to stop them from reaching their final goals. For this\npurpose, many organizations utilize Security Information and Event Management\n(SIEM) systems to centrally collect security-related events and scan them for\nattack indicators using expert-written detection rules. However, as we show by\nanalyzing a set of widespread SIEM detection rules, adversaries can evade\nalmost half of them easily, allowing them to perform common malicious actions\nwithin an enterprise network without being detected. To remedy these critical\ndetection blind spots, we propose the idea of adaptive misuse detection, which\nutilizes machine learning to compare incoming events to SIEM rules on the one\nhand and known-benign events on the other hand to discover successful evasions.\nBased on this idea, we present AMIDES, an open-source proof-of-concept adaptive\nmisuse detection system. Using four weeks of SIEM events from a large\nenterprise network and more than 500 hand-crafted evasions, we show that AMIDES\nsuccessfully detects a majority of these evasions without any false alerts. In\naddition, AMIDES eases alert analysis by assessing which rules were evaded. Its\ncomputational efficiency qualifies AMIDES for real-world operation and hence\nenables organizations to significantly reduce detection blind spots with\nmoderate effort."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.7611435848,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Near-Memory Parallel Indexing and Coalescing: Enabling Highly Efficient Indirect Access for SpMV",
    "abstract": "Sparse matrix vector multiplication (SpMV) is central to numerous\ndata-intensive applications, but requires streaming indirect memory accesses\nthat severely degrade both processing and memory throughput in state-of-the-art\narchitectures. Near-memory hardware units, decoupling indirect streams from\nprocessing elements, partially alleviate the bottleneck, but rely on low DRAM\naccess granularity, which is highly inefficient for modern DRAM standards like\nHBM and LPDDR. To fully address the end-to-end challenge, we propose a\nlow-overhead data coalescer combined with a near-memory indirect streaming unit\nfor AXI-Pack, an extension to the widespread AXI4 protocol packing narrow\nirregular stream elements onto wide memory buses. Our combined solution\nleverages the memory-level parallelism and coalescence of streaming indirect\naccesses in irregular applications like SpMV to maximize the performance and\nbandwidth efficiency attained on wide memory interfaces. Our solution delivers\nan average speedup of 8x in effective indirect access, often reaching the full\nmemory bandwidth. As a result, we achieve an average end-to-end speedup on SpMV\nof 3x. Moreover, our approach demonstrates remarkable on-chip efficiency,\nrequiring merely 27kB of on-chip storage and a very compact implementation area\nof 0.2-0.3mm^2 in a 12nm node."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.5595405096,
    "title": "Learning Realistic Joint Space Boundaries for Range of Motion Analysis of Healthy and Impaired Human Arms",
    "abstract": "A realistic human kinematic model that satisfies anatomical constraints is\nessential for human-robot interaction, biomechanics and robot-assisted\nrehabilitation. Modeling realistic joint constraints, however, is challenging\nas human arm motion is constrained by joint limits, inter- and intra-joint\ndependencies, self-collisions, individual capabilities and muscular or\nneurological constraints which are difficult to represent. Hence, physicians\nand researchers have relied on simple box-constraints, ignoring important\nanatomical factors. In this paper, we propose a data-driven method to learn\nrealistic anatomically constrained upper-limb range of motion (RoM) boundaries\nfrom motion capture data. This is achieved by fitting a one-class support\nvector machine to a dataset of upper-limb joint space exploration motions with\nan efficient hyper-parameter tuning scheme. Our approach outperforms similar\nworks focused on valid RoM learning. Further, we propose an impairment index\n(II) metric that offers a quantitative assessment of capability\/impairment when\ncomparing healthy and impaired arms. We validate the metric on healthy subjects\nphysically constrained to emulate hemiplegia and different disability levels as\nstroke patients."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8572985792,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.4256317728,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Reprogramming Self-supervised Learning-based Speech Representations for Speaker Anonymization",
    "abstract": "Current speaker anonymization methods, especially with self-supervised\nlearning (SSL) models, require massive computational resources when hiding\nspeaker identity. This paper proposes an effective and parameter-efficient\nspeaker anonymization method based on recent End-to-End model reprogramming\ntechnology. To improve the anonymization performance, we first extract speaker\nrepresentation from large SSL models as the speaker identifies. To hide the\nspeaker's identity, we reprogram the speaker representation by adapting the\nspeaker to a pseudo domain. Extensive experiments are carried out on the\nVoicePrivacy Challenge (VPC) 2022 datasets to demonstrate the effectiveness of\nour proposed parameter-efficient learning anonymization methods. Additionally,\nwhile achieving comparable performance with the VPC 2022 strong baseline 1.b,\nour approach consumes less computational resources during anonymization."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -2.4658964612,
    "annual_revenue_USD_log": 1.5534070302,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Total Skin Electron Therapy Stanford Technique Evolution With Monte Carlo Simulation Toward Personalized Treatments For Cutaneous Lymphoma",
    "abstract": "Current Total Skin Electron Therapy (TSET) Stanford technique for cutaneous\nlymphoma, established in the 70's, involves a unique irradiation setup, i.e.\npatient's position and beam arrangement, for all patients with ensuing great\nvariability in dose distribution and difficult dose optimization. A\nGeant4-based simulation has been developed to explore the possibility of\npersonalizing the dose to each patient's anatomy. To achieve this optimization\nof the treatment method, this project enrolls different aspects of the clinical\nand computational techniques: starting with the knowledge of the experimental\nparameters involving TSET practice, passing through an innovative approach to\nmodel the patient's anatomy, a precise description of the electron beam and a\nvalidated configuration of the physics models handling the interactions of the\nelectrons and of secondary particles. The Geant4-based simulation models the\npatient as a tessellated solid derived from the optical scan of her\/his body,\nrealistically reproduces the irradiation environment in detail and calculates\nthe energy deposition corresponding to each facet of the patient's scanned\nsurface. The resulting three-dimensional dose distribution constitutes the\nbasis for the personalization of the medical treatement as appropriate to each\npatient's specific characteristics."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.8583906896,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 1.6684873834,
    "title": "Principles for single-pixel terahertz imaging based on the engineering of illuminating and collecting nonparaxial diffractive optics",
    "abstract": "The art of light engineering unveils a world of possibilities through the\nmeticulous manipulation of photonic properties such as intensity, phase, and\npolarization. The precise control over these optical properties under various\nconditions finds application in fields spanning communication, light-matter\ninteractions, laser direct writing, and imaging, enriching our technological\nlandscape. In this study, we embark on a journey to establish a rational\nframework for the design and assembly of nonparaxial THz imaging systems. Our\nfocus centers on a lensless photonic system composed solely of flat-silicon\ndiffractive optics. These elements include the high-resistivity silicon-based\nnonparaxial Fresnel zone plate, the Fibonacci lens, the Bessel axicon, and the\nAiry zone plate, all meticulously crafted using laser ablation technology. A\nsystematic exploration of these flat elements in various combinations sheds\nlight on their strengths and weaknesses. Our endeavor extends to the practical\napplication of these optical components, where they illuminate samples and\ncapture the light scattered from these raster-scanned samples using\nsingle-pixel detectors. Through a comprehensive examination, we evaluate\nimaging systems across diverse metrics that include contrast, resolution, depth\nof field and focus. This multifaceted approach allows us to distill rational\ndesign principles for the optimal assembly of THz imaging setups. The findings\nof this research chart an exciting course toward the development of compact,\nuser-friendly THz imaging systems where sensors and passive optical elements\nseamlessly integrate into a single chip. These innovations not only enhance\ncapabilities in THz imaging but also pave the way for novel applications,\nushering in a new encouraging era of advanced THz photonic technology."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -2.4658964612,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Non-destructive depth reconstruction of Al-Al$_2$Cu layer structure with nanometer resolution using extreme ultraviolet coherence tomography",
    "abstract": "Non-destructive cross-sectional characterization of materials systems with a\nresolution in the nanometer range and the ability to allow for time-resolved\nin-situ studies is of great importance in material science. Here, we present\nsuch a measurements method, extreme ultraviolet coherence tomography (XCT). The\nmethod is non-destructive during sample preparation as well as during the\nmeasurement, which is distinguished by a negligible thermal load as compared to\nelectron microscopy methods. Laser-generated radiation in the extreme\nultraviolet (XUV) and soft x-ray range is used for characterization. The\nmeasurement principle is interferometric and the signal evaluation is performed\nvia an iterative Fourier analysis. The method is demonstrated on the metallic\nmaterial system Al-Al$_2$Cu and compared to electron and atomic force\nmicroscopy measurements. We also present advanced reconstruction methods for\nXCT which even allow for the determination of the roughness of outer and inner\ninterfaces."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.8278466905,
    "ROI_percent": 1.281893344,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.0791806145,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Can Language Model Moderators Improve the Health of Online Discourse?",
    "abstract": "Conversational moderation of online communities is crucial to maintaining\ncivility for a constructive environment, but it is challenging to scale and\nharmful to moderators. The inclusion of sophisticated natural language\ngeneration modules as a force multiplier to aid human moderators is a\ntantalizing prospect, but adequate evaluation approaches have so far been\nelusive. In this paper, we establish a systematic definition of conversational\nmoderation effectiveness grounded on moderation literature and establish design\ncriteria for conducting realistic yet safe evaluation. We then propose a\ncomprehensive evaluation framework to assess models' moderation capabilities\nindependently of human intervention. With our framework, we conduct the first\nknown study of language models as conversational moderators, finding that\nappropriately prompted models that incorporate insights from social science can\nprovide specific and fair feedback on toxic behavior but struggle to influence\nusers to increase their levels of respect and cooperation."
  },
  {
    "CAGR": 1.4545947092,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.6054785613,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.9086309264,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.027440103,
    "title": "Robustness Enhancement in Neural Networks with Alpha-Stable Training Noise",
    "abstract": "With the increasing use of deep learning on data collected by non-perfect\nsensors and in non-perfect environments, the robustness of deep learning\nsystems has become an important issue. A common approach for obtaining\nrobustness to noise has been to train deep learning systems with data augmented\nwith Gaussian noise. In this work, we challenge the common choice of Gaussian\nnoise and explore the possibility of stronger robustness for non-Gaussian\nimpulsive noise, specifically alpha-stable noise. Justified by the Generalized\nCentral Limit Theorem and evidenced by observations in various application\nareas, alpha-stable noise is widely present in nature. By comparing the testing\naccuracy of models trained with Gaussian noise and alpha-stable noise on data\ncorrupted by different noise, we find that training with alpha-stable noise is\nmore effective than Gaussian noise, especially when the dataset is corrupted by\nimpulsive noise, thus improving the robustness of the model. The generality of\nthis conclusion is validated through experiments conducted on various deep\nlearning models with image and time series datasets, and other benchmark\ncorrupted datasets. Consequently, we propose a novel data augmentation method\nthat replaces Gaussian noise, which is typically added to the training data,\nwith alpha-stable noise."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 2.3141419596,
    "annual_revenue_USD_log": 0.025748487,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Subjective Quality Assessment of Compressed Tone-Mapped High Dynamic Range Videos",
    "abstract": "High Dynamic Range (HDR) videos are able to represent wider ranges of\ncontrasts and colors than Standard Dynamic Range (SDR) videos, giving more\nvivid experiences. Due to this, HDR videos are expected to grow into the\ndominant video modality of the future. However, HDR videos are incompatible\nwith existing SDR displays, which form the majority of affordable consumer\ndisplays on the market. Because of this, HDR videos must be processed by\ntone-mapping them to reduced bit-depths to service a broad swath of SDR-limited\nvideo consumers. Here, we analyze the impact of tone-mapping operators on the\nvisual quality of streaming HDR videos. To this end, we built the first\nlarge-scale subjectively annotated open-source database of compressed\ntone-mapped HDR videos, containing 15,000 tone-mapped sequences derived from 40\nunique HDR source contents. The videos in the database were labeled with more\nthan 750,000 subjective quality annotations, collected from more than 1,600\nunique human observers. We demonstrate the usefulness of the new subjective\ndatabase by benchmarking objective models of visual quality on it. We envision\nthat the new LIVE Tone-Mapped HDR (LIVE-TMHDR) database will enable significant\nprogress on HDR video tone mapping and quality assessment in the future. To\nthis end, we make the database freely available to the community at\nhttps:\/\/live.ece.utexas.edu\/research\/LIVE_TMHDR\/index.html"
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": -1.1323289524,
    "title": "Real-time Threat Detection Strategies for Resource-constrained Devices",
    "abstract": "As more devices connect to the internet, it becomes crucial to address their\nlimitations and basic security needs. While much research focuses on utilizing\nML and DL to tackle security challenges, there is often a tendency to overlook\nthe practicality and feasibility of implementing these methods in real-time\nsettings. This oversight stems from the constrained processing power and memory\nof certain devices (IoT devices), as well as concerns about the\ngeneralizability of these approaches. Focusing on the detection of\nDNS-tunneling attacks in a router as a case study, we present an end-to-end\nprocess designed to effectively address these challenges. The process spans\nfrom developing a lightweight DNS-tunneling detection model to integrating it\ninto a resource-constrained device for real-time detection. Through our\nexperiments, we demonstrate that utilizing stateless features for training the\nML model, along with features chosen to be independent of the network\nconfiguration, leads to highly accurate results. The deployment of this\ncarefully crafted model, optimized for embedded devices across diverse\nenvironments, resulted in high DNS-tunneling attack detection with minimal\nlatency. With this work, we aim to encourage solutions that strike a balance\nbetween theoretical advancements and the practical applicability of ML\napproaches in the ever-evolving landscape of device security."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.3958856557,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.5595405096,
    "title": "IFSENet : Harnessing Sparse Iterations for Interactive Few-shot Segmentation Excellence",
    "abstract": "Training a computer vision system to segment a novel class typically requires\ncollecting and painstakingly annotating lots of images with objects from that\nclass. Few-shot segmentation techniques reduce the required number of images to\nlearn to segment a new class, but careful annotations of object boundaries are\nstill required. On the other hand, interactive segmentation techniques only\nfocus on incrementally improving the segmentation of one object at a time\n(typically, using clicks given by an expert) in a class-agnostic manner. We\ncombine the two concepts to drastically reduce the effort required to train\nsegmentation models for novel classes. Instead of trivially feeding interactive\nsegmentation masks as ground truth to a few-shot segmentation model, we propose\nIFSENet, which can accept sparse supervision on a single or few support images\nin the form of clicks to generate masks on support (training, at least clicked\nupon once) as well as query (test, never clicked upon) images. To trade-off\neffort for accuracy flexibly, the number of images and clicks can be\nincrementally added to the support set to further improve the segmentation of\nsupport as well as query images. The proposed model approaches the accuracy of\nprevious state-of-the-art few-shot segmentation models with considerably lower\nannotation effort (clicks instead of maps), when tested on Pascal and SBD\ndatasets on query images. It also works well as an interactive segmentation\nmethod on support images."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.808212098,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -2.1424131503,
    "annual_revenue_USD_log": 0.6432509228,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Improving cross-domain brain tissue segmentation in fetal MRI with synthetic data",
    "abstract": "Segmentation of fetal brain tissue from magnetic resonance imaging (MRI)\nplays a crucial role in the study of in utero neurodevelopment. However,\nautomated tools face substantial domain shift challenges as they must be robust\nto highly heterogeneous clinical data, often limited in numbers and lacking\nannotations. Indeed, high variability of the fetal brain morphology, MRI\nacquisition parameters, and superresolution reconstruction (SR) algorithms\nadversely affect the model's performance when evaluated out-of-domain. In this\nwork, we introduce FetalSynthSeg, a domain randomization method to segment\nfetal brain MRI, inspired by SynthSeg. Our results show that models trained\nsolely on synthetic data outperform models trained on real data in out-ofdomain\nsettings, validated on a 120-subject cross-domain dataset. Furthermore, we\nextend our evaluation to 40 subjects acquired using lowfield (0.55T) MRI and\nreconstructed with novel SR models, showcasing robustness across different\nmagnetic field strengths and SR algorithms. Leveraging a generative synthetic\napproach, we tackle the domain shift problem in fetal brain MRI and offer\ncompelling prospects for applications in fields with limited and highly\nheterogeneous data."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 1.281893344,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.4991958469,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Exploring the Task-agnostic Trait of Self-supervised Learning in the Context of Detecting Mental Disorders",
    "abstract": "Self-supervised learning (SSL) has been investigated to generate\ntask-agnostic representations across various domains. However, such\ninvestigation has not been conducted for detecting multiple mental disorders.\nThe rationale behind the existence of a task-agnostic representation lies in\nthe overlapping symptoms among multiple mental disorders. Consequently, the\nbehavioural data collected for mental health assessment may carry a mixed bag\nof attributes related to multiple disorders. Motivated by that, in this study,\nwe explore a task-agnostic representation derived through SSL in the context of\ndetecting major depressive disorder (MDD) and post-traumatic stress disorder\n(PTSD) using audio and video data collected during interactive sessions. This\nstudy employs SSL models trained by predicting multiple fixed targets or masked\nframes. We propose a list of fixed targets to make the generated representation\nmore efficient for detecting MDD and PTSD. Furthermore, we modify the\nhyper-parameters of the SSL encoder predicting fixed targets to generate global\nrepresentations that capture varying temporal contexts. Both these innovations\nare noted to yield improved detection performances for considered mental\ndisorders and exhibit task-agnostic traits. In the context of the SSL model\npredicting masked frames, the generated global representations are also noted\nto exhibit task-agnostic traits."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.7100391355,
    "ROI_percent": -0.0915291576,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.1599347162,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -0.3373958805,
    "title": "InstaSynth: Opportunities and Challenges in Generating Synthetic Instagram Data with ChatGPT for Sponsored Content Detection",
    "abstract": "Large Language Models (LLMs) raise concerns about lowering the cost of\ngenerating texts that could be used for unethical or illegal purposes,\nespecially on social media. This paper investigates the promise of such models\nto help enforce legal requirements related to the disclosure of sponsored\ncontent online. We investigate the use of LLMs for generating synthetic\nInstagram captions with two objectives: The first objective (fidelity) is to\nproduce realistic synthetic datasets. For this, we implement content-level and\nnetwork-level metrics to assess whether synthetic captions are realistic. The\nsecond objective (utility) is to create synthetic data that is useful for\nsponsored content detection. For this, we evaluate the effectiveness of the\ngenerated synthetic data for training classifiers to identify undisclosed\nadvertisements on Instagram. Our investigations show that the objectives of\nfidelity and utility may conflict and that prompt engineering is a useful but\ninsufficient strategy. Additionally, we find that while individual synthetic\nposts may appear realistic, collectively they lack diversity, topic\nconnectivity, and realistic user interaction patterns."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.4890352234,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.247070394,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.027440103,
    "title": "Hierarchical Information Enhancement Network for Cascade Prediction in Social Networks",
    "abstract": "Understanding information cascades in networks is a fundamental issue in\nnumerous applications. Current researches often sample cascade information into\nseveral independent paths or subgraphs to learn a simple cascade\nrepresentation. However, these approaches fail to exploit the hierarchical\nsemantic associations between different modalities, limiting their predictive\nperformance. In this work, we propose a novel Hierarchical Information\nEnhancement Network (HIENet) for cascade prediction. Our approach integrates\nfundamental cascade sequence, user social graphs, and sub-cascade graph into a\nunified framework. Specifically, HIENet utilizes DeepWalk to sample cascades\ninformation into a series of sequences. It then gathers path information\nbetween users to extract the social relationships of propagators. Additionally,\nwe employ a time-stamped graph convolutional network to aggregate sub-cascade\ngraph information effectively. Ultimately, we introduce a Multi-modal Cascade\nTransformer to powerfully fuse these clues, providing a comprehensive\nunderstanding of cascading process. Extensive experiments have demonstrated the\neffectiveness of the proposed method."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 2.7434938157,
    "usd_savings_per_year": -0.7198564318,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Inverse Design of Crystals and Quasicrystals in a Non-Additive Binary Mixture of Hard Disks",
    "abstract": "The development of new materials typically involves a process of trial and\nerror, guided by insights from past experimental and theoretical findings. The\ninverse design approach for soft-matter systems has the potential to optimize\nspecific physical parameters such as particle interactions, particle shape, or\ncomposition and packing fraction. This optimization aims to facilitate the\nspontaneous formation of specific target structures through self-assembly. In\nthis study, we expand upon a recently introduced inverse design protocol for\nmonodisperse systems to identify the required conditions and interactions for\nassembling crystal and quasicrystal phases within a binary mixture of two\ndistinct species. This method utilizes an evolutionary algorithm to identify\nthe optimal state point and interaction parameters, enabling the self-assembly\nof the desired structure. Additionally, we employ a convolutional neural\nnetwork (CNN) that classifies different phases based on their diffraction\npatterns, serving as a fitness function for the desired structure. Using our\nprotocol, we successfully inverse design two-dimensional crystalline\nstructures, including a hexagonal lattice, and a dodecagonal quasicrystal,\nwithin a non-additive binary mixture of hard disks. Finally, we introduce a\nsymmetry-based order parameter that leverages the encoded symmetry within the\ndiffraction pattern. This order parameter circumvents the need for training a\nCNN, and is used as a fitness function to inverse design an octagonal\nquasicrystal."
  },
  {
    "CAGR": -0.6581603933,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Ultrasound Imaging based on the Variance of a Diffusion Restoration Model",
    "abstract": "Despite today's prevalence of ultrasound imaging in medicine, ultrasound\nsignal-to-noise ratio is still affected by several sources of noise and\nartefacts. Moreover, enhancing ultrasound image quality involves balancing\nconcurrent factors like contrast, resolution, and speckle preservation.\nRecently, there has been progress in both model-based and learning-based\napproaches addressing the problem of ultrasound image reconstruction. Bringing\nthe best from both worlds, we propose a hybrid reconstruction method combining\nan ultrasound linear direct model with a learning-based prior coming from a\ngenerative Denoising Diffusion model. More specifically, we rely on the\nunsupervised fine-tuning of a pre-trained Denoising Diffusion Restoration Model\n(DDRM). Given the nature of multiplicative noise inherent to ultrasound, this\npaper proposes an empirical model to characterize the stochasticity of\ndiffusion reconstruction of ultrasound images, and shows the interest of its\nvariance as an echogenicity map estimator. We conduct experiments on synthetic,\nin-vitro, and in-vivo data, demonstrating the efficacy of our variance imaging\napproach in achieving high-quality image reconstructions from single plane-wave\nacquisitions and in comparison to state-of-the-art methods. The code is\navailable at: https:\/\/github.com\/Yuxin-Zhang-Jasmine\/DRUSvar"
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Optimal Data-Driven Prediction and Predictive Control using Signal Matrix Models",
    "abstract": "Data-driven control uses a past signal trajectory to characterise the\ninput-output behaviour of a system. Willems' lemma provides a data-based\nprediction model allowing a control designer to bypass the step of identifying\na state-space or transfer function model. This paper provides a more\nparsimonious formulation of Willems' lemma that separates the model into\ninitial condition matching and predictive control design parts. This avoids the\nneed for regularisers in the predictive control problem that are found in other\ndata-driven predictive control methods. It also gives a closed form expression\nfor the optimal (minimum variance) unbiased predictor of the future output\ntrajectory and applies it for predictive control. Simulation comparisons\nillustrate very good control performance."
  },
  {
    "CAGR": -1.2381323823,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 1.4890352234,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.173042894,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Dialogue Understandability: Why are we streaming movies with subtitles?",
    "abstract": "Watching movies and TV shows with subtitles enabled is not simply down to\naudibility or speech intelligibility. A variety of evolving factors related to\ntechnological advances, cinema production and social behaviour challenge our\nperception and understanding. This study seeks to formalise and give context to\nthese influential factors under a wider and novel term referred to as Dialogue\nUnderstandability. We propose a working definition for Dialogue\nUnderstandability being a listener's capacity to follow the story without undue\ncognitive effort or concentration being required that impacts their Quality of\nExperience (QoE). The paper identifies, describes and categorises the factors\nthat influence Dialogue Understandability mapping them over the QoE framework,\na media streaming lifecycle, and the stakeholders involved. We then explore\navailable measurement tools in the literature and link them to the factors they\ncould potentially be used for. The maturity and suitability of these tools is\nevaluated over a set of pilot experiments. Finally, we reflect on the gaps that\nstill need to be filled, what we can measure and what not, future subjective\nexperiments, and new research trends that could help us to fully characterise\nDialogue Understandability."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -0.3083853421,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 1.6684873834,
    "title": "Fully automated workflow for designing patient-specific orthopaedic implants: application to total knee arthroplasty",
    "abstract": "Background. Osteoarthritis affects about 528 million people worldwide,\ncausing pain and stiffness in the joints. Arthroplasty is commonly performed to\ntreat joint osteoarthritis, reducing pain and improving mobility. Nevertheless,\na significant share of patients remain unsatisfied with their surgery.\nPersonalised arthroplasty was introduced to improve surgical outcomes however\ncurrent solutions require delays, making it difficult to integrate in clinical\nroutine. We propose a fully automated workflow to design patient-specific\nimplants for total knee arthroplasty.\n  Methods. The proposed pipeline first uses artificial neural networks to\nsegment the femur and tibia proximal and distal extremities. Then the full\nbones are reconstructed using augmented statistical shape models, combining\nshape and landmarks information. Finally, 77 morphological parameters are\ncomputed to design patient-specific implants. The developed workflow has been\ntrained on 91 CT scans and evaluated on 41 CT scans, in terms of accuracy and\nexecution time.\n  Results. The workflow accuracy was $0.4\\pm0.2mm$ for segmentation,\n$1.0\\pm0.3mm$ for full bone reconstruction, and $2.2\\pm1.5mm$ for anatomical\nlandmarks determination. The custom implants fitted the patients' anatomy with\n$0.9\\pm0.5mm$ accuracy. The whole process from segmentation to implants' design\nlasted about 15 minutes.\n  Conclusion. The proposed workflow performs a fast and reliable\npersonalisation of knee implants, directly from a CT image without requiring\nany manual intervention. It allows the establishment of a patient-specific\npre-operative planning in a very short time, making it easily available for all\npatients. Combined with efficient implant manufacturing techniques, this\nsolution could help answer the growing number of arthroplasties while reducing\ncomplications and improving patients' satisfaction."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": 1.4890352234,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 2.3164576997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.5175734475,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.0662541385,
    "title": "LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models",
    "abstract": "Large Multimodal Models (LMMs) have shown significant visual reasoning\ncapabilities by connecting a visual encoder and a large language model. LMMs\ntypically take in a fixed and large amount of visual tokens, such as the\npenultimate layer features in the CLIP visual encoder, as the prefix content.\nRecent LMMs incorporate more complex visual inputs, such as high-resolution\nimages and videos, which further increases the number of visual tokens\nsignificantly. However, due to the inherent design of the Transformer\narchitecture, the computational costs of these models tend to increase\nquadratically with the number of input tokens. To tackle this problem, we\nexplore a token reduction mechanism that identifies significant spatial\nredundancy among visual tokens. In response, we propose PruMerge, a novel\nadaptive visual token reduction strategy that significantly reduces the number\nof visual tokens without compromising the performance of LMMs. Specifically, to\nmetric the importance of each token, we exploit the sparsity observed in the\nvisual encoder, characterized by the sparse distribution of attention scores\nbetween the class token and visual tokens. This sparsity enables us to\ndynamically select the most crucial visual tokens to retain. Subsequently, we\ncluster the selected (unpruned) tokens based on their key similarity and merge\nthem with the unpruned tokens, effectively supplementing and enhancing their\ninformational content. Empirically, when applied to LLaVA-1.5, our approach can\ncompress the visual tokens by 14 times on average, and achieve comparable\nperformance across diverse visual question-answering and reasoning tasks. Code\nand checkpoints are at https:\/\/llava-prumerge.github.io\/."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.5173724297,
    "annual_revenue_USD_log": -2.3018569987,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Physics-informed and Unsupervised Riemannian Domain Adaptation for Machine Learning on Heterogeneous EEG Datasets",
    "abstract": "Combining electroencephalogram (EEG) datasets for supervised machine learning\n(ML) is challenging due to session, subject, and device variability. ML\nalgorithms typically require identical features at train and test time,\ncomplicating analysis due to varying sensor numbers and positions across\ndatasets. Simple channel selection discards valuable data, leading to poorer\nperformance, especially with datasets sharing few channels. To address this, we\npropose an unsupervised approach leveraging EEG signal physics. We map EEG\nchannels to fixed positions using field interpolation, facilitating source-free\ndomain adaptation. Leveraging Riemannian geometry classification pipelines and\ntransfer learning steps, our method demonstrates robust performance in\nbrain-computer interface (BCI) tasks and potential biomarker applications.\nComparative analysis against a statistical-based approach known as\nDimensionality Transcending, a signal-based imputation called ComImp,\nsource-dependent methods, as well as common channel selection and spherical\nspline interpolation, was conducted with leave-one-dataset-out validation on\nsix public BCI datasets for a right-hand\/left-hand classification task.\nNumerical experiments show that in the presence of few shared channels in train\nand test, the field interpolation consistently outperforms other methods,\ndemonstrating enhanced classification performance across all datasets. When\nmore channels are shared, field interpolation was found to be competitive with\nother methods and faster to compute than source-dependent methods."
  },
  {
    "CAGR": -1.1138526704,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.1599347162,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.7562984273,
    "title": "HyPer-EP: Meta-Learning Hybrid Personalized Models for Cardiac Electrophysiology",
    "abstract": "Personalized virtual heart models have demonstrated increasing potential for\nclinical use, although the estimation of their parameters given\npatient-specific data remain a challenge. Traditional physics-based modeling\napproaches are computationally costly and often neglect the inherent structural\nerrors in these models due to model simplifications and assumptions. Modern\ndeep learning approaches, on the other hand, rely heavily on data supervision\nand lacks interpretability. In this paper, we present a novel hybrid modeling\nframework to describe a personalized cardiac digital twin as a combination of a\nphysics-based known expression augmented by neural network modeling of its\nunknown gap to reality. We then present a novel meta-learning framework to\nenable the separate identification of both the physics-based and neural\ncomponents in the hybrid model. We demonstrate the feasibility and generality\nof this hybrid modeling framework with two examples of instantiations and their\nproof-of-concept in synthetic experiments."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 1.4475710586,
    "annual_revenue_USD_log": 2.1709094741,
    "rnd_investment_required_log": 0.0662541385,
    "title": "A Survey of IMU Based Cross-Modal Transfer Learning in Human Activity Recognition",
    "abstract": "Despite living in a multi-sensory world, most AI models are limited to\ntextual and visual understanding of human motion and behavior. In fact, full\nsituational awareness of human motion could best be understood through a\ncombination of sensors. In this survey we investigate how knowledge can be\ntransferred and utilized amongst modalities for Human Activity\/Action\nRecognition (HAR), i.e. cross-modality transfer learning. We motivate the\nimportance and potential of IMU data and its applicability in cross-modality\nlearning as well as the importance of studying the HAR problem. We categorize\nHAR related tasks by time and abstractness and then compare various types of\nmultimodal HAR datasets. We also distinguish and expound on many related but\ninconsistently used terms in the literature, such as transfer learning, domain\nadaptation, representation learning, sensor fusion, and multimodal learning,\nand describe how cross-modal learning fits with all these concepts. We then\nreview the literature in IMU-based cross-modal transfer for HAR. The two main\napproaches for cross-modal transfer are instance-based transfer, where\ninstances of one modality are mapped to another (e.g. knowledge is transferred\nin the input space), or feature-based transfer, where the model relates the\nmodalities in an intermediate latent space (e.g. knowledge is transferred in\nthe feature space). Finally, we discuss future research directions and\napplications in cross-modal HAR."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.808212098,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.3598997146,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -1.027440103,
    "title": "A2DMN: Anatomy-Aware Dilated Multiscale Network for Breast Ultrasound Semantic Segmentation",
    "abstract": "In recent years, convolutional neural networks for semantic segmentation of\nbreast ultrasound (BUS) images have shown great success; however, two major\nchallenges still exist. 1) Most current approaches inherently lack the ability\nto utilize tissue anatomy, resulting in misclassified image regions. 2) They\nstruggle to produce accurate boundaries due to the repeated down-sampling\noperations. To address these issues, we propose a novel breast anatomy-aware\nnetwork for capturing fine image details and a new smoothness term that encodes\nbreast anatomy. It incorporates context information across multiple spatial\nscales to generate more accurate semantic boundaries. Extensive experiments are\nconducted to compare the proposed method and eight state-of-the-art approaches\nusing a BUS dataset with 325 images. The results demonstrate the proposed\nmethod significantly improves the segmentation of the muscle, mammary, and\ntumor classes and produces more accurate fine details of tissue boundaries."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 1.9721180886,
    "rnd_investment_required_log": 2.1363870464,
    "title": "Technologies for Modulation of Visible Light and their Applications",
    "abstract": "Control over the amplitude, phase, and spatial distribution of\nvisible-spectrum light underlies many technologies, but commercial solutions\nremain bulky, require high control power, and are often too slow. Active\nintegrated photonics for visible light promises a solution, especially with\nrecent materials and fabrication advances. In this review, we discuss three\ngrowing application spaces which rely on control of visible light: control and\nmeasurement of atomic quantum technologies, augmented-reality displays, and\nmeasurement and control of biological systems. We then review the commercial\ndynamic surfaces and bulk systems which currently provide visible-light\nmodulation and the current state-of-the-art integrated solutions. Throughout\nthe review we focus on speed, control power, size, optical bandwidth, and\ntechnological maturity when comparing technologies."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 2.8817771622,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 1.7327369984,
    "title": "Electrically Switchable Circular Photogalvanic Effect in Methylammonium Lead Iodide Microcrystals",
    "abstract": "We investigate the circular photogalvanic effect (CPGE) in single-crystalline\nmethylammonium lead iodide microcrystals under a static electric field. The\nexternal electric field can enhance the magnitude of the helicity dependent\nphotocurrent (HDPC) by two orders of magnitude and flip its sign, which we\nattribute to magnetic shift currents induced by the Rashba-Edelstein effect.\nThis HDPC induced by the static electric field may be viewed as an unusually\nstrong third-order photoresponse, which produces a current two orders of\nmagnitude larger than second-order injection current. Furthermore, the HDPC is\nhighly nonlocal and can be created by photoexcitation out of the device\nchannel, indicating a spin diffusion length up to 50 $\\mu$m at 78 K."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.018090997,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": -1.027440103,
    "title": "Multi-Robot Task Allocation using Global Games with Negative Feedback: The Colony Maintenance Problem",
    "abstract": "In this article we address the multi-robot task allocation problem, where\nrobots must cooperatively assign themselves to accomplish a set of tasks. We\nconsider the colony maintenance problem as an example, where a team of robots\nare tasked with continuously maintaining the energy supply of a central colony.\nWe model this as a global game, where each robot measures the energy level of\nthe colony, and the current number of assigned robots, to determine whether or\nnot to forage for energy sources. The key to our approach is introducing a\nnegative feedback term into the robots' utility, which also eliminates the\ntrivial solution where foraging or not foraging are strictly dominant\nstrategies. We compare our approach qualitatively to existing an global games\napproach, where a positive positive feedback term admits threshold-based\ndecision making that encourages many robots to forage. We discuss how positive\nfeedback can lead to a cascading failure when robots are removed from the\nsystem, and we demonstrate the resilience of our approach in simulation."
  },
  {
    "CAGR": 2.8354803972,
    "years_to_50pct_penetration": -1.7270042027,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 1.7627495964,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.1558904989,
    "title": "EAGLE: A Domain Generalization Framework for AI-generated Text Detection",
    "abstract": "With the advancement in capabilities of Large Language Models (LLMs), one\nmajor step in the responsible and safe use of such LLMs is to be able to detect\ntext generated by these models. While supervised AI-generated text detectors\nperform well on text generated by older LLMs, with the frequent release of new\nLLMs, building supervised detectors for identifying text from such new models\nwould require new labeled training data, which is infeasible in practice. In\nthis work, we tackle this problem and propose a domain generalization framework\nfor the detection of AI-generated text from unseen target generators. Our\nproposed framework, EAGLE, leverages the labeled data that is available so far\nfrom older language models and learns features invariant across these\ngenerators, in order to detect text generated by an unknown target generator.\nEAGLE learns such domain-invariant features by combining the representational\npower of self-supervised contrastive learning with domain adversarial training.\nThrough our experiments we demonstrate how EAGLE effectively achieves\nimpressive performance in detecting text generated by unseen target generators,\nincluding recent state-of-the-art ones such as GPT-4 and Claude, reaching\ndetection scores of within 4.7% of a fully supervised detector."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.847481283,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -1.027440103,
    "title": "Technical Report: Masked Skeleton Sequence Modeling for Learning Larval Zebrafish Behavior Latent Embeddings",
    "abstract": "In this report, we introduce a novel self-supervised learning method for\nextracting latent embeddings from behaviors of larval zebrafish. Drawing\ninspiration from Masked Modeling techniquesutilized in image processing with\nMasked Autoencoders (MAE) \\cite{he2022masked} and in natural language\nprocessing with Generative Pre-trained Transformer (GPT)\n\\cite{radford2018improving}, we treat behavior sequences as a blend of images\nand language. For the skeletal sequences of swimming zebrafish, we propose a\npioneering Transformer-CNN architecture, the Sequence Spatial-Temporal\nTransformer (SSTFormer), designed to capture the inter-frame correlation of\ndifferent joints. This correlation is particularly valuable, as it reflects the\ncoordinated movement of various parts of the fish body across adjacent frames.\nTo handle the high frame rate, we segment the skeleton sequence into distinct\ntime slices, analogous to \"words\" in a sentence, and employ self-attention\ntransformer layers to encode the consecutive frames within each slice,\ncapturing the spatial correlation among different joints. Furthermore, we\nincorporate a CNN-based attention module to enhance the representations\noutputted by the transformer layers. Lastly, we introduce a temporal feature\naggregation operation between time slices to improve the discrimination of\nsimilar behaviors."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.1799051383,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.2927067131,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.3373958805,
    "title": "PNAS-MOT: Multi-Modal Object Tracking with Pareto Neural Architecture Search",
    "abstract": "Multiple object tracking is a critical task in autonomous driving. Existing\nworks primarily focus on the heuristic design of neural networks to obtain high\naccuracy. As tracking accuracy improves, however, neural networks become\nincreasingly complex, posing challenges for their practical application in real\ndriving scenarios due to the high level of latency. In this paper, we explore\nthe use of the neural architecture search (NAS) methods to search for efficient\narchitectures for tracking, aiming for low real-time latency while maintaining\nrelatively high accuracy. Another challenge for object tracking is the\nunreliability of a single sensor, therefore, we propose a multi-modal framework\nto improve the robustness. Experiments demonstrate that our algorithm can run\non edge devices within lower latency constraints, thus greatly reducing the\ncomputational requirements for multi-modal object tracking while keeping lower\nlatency."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": -1.027440103,
    "title": "Towards Channel-Resilient CSI-Based RF Fingerprinting using Deep Learning",
    "abstract": "This work introduces DeepCRF, a deep learning framework designed for channel\nstate information-based radio frequency fingerprinting (CSI-RFF). The\nconsidered CSI-RFF is built on micro-CSI, a recently discovered radio-frequency\n(RF) fingerprint that manifests as micro-signals appearing on the channel state\ninformation (CSI) curves of commercial WiFi devices. Micro-CSI facilitates\nCSI-RFF which is more streamlined and easily implementable compared to existing\nschemes that rely on raw I\/Q samples. The primary challenge resides in the\nprecise extraction of micro-CSI from the inherently fluctuating CSI\nmeasurements, a process critical for reliable RFF. The construction of a\nframework that is resilient to channel variability is essential for the\npractical deployment of CSI-RFF techniques. DeepCRF addresses this challenge\nwith a thoughtfully trained convolutional neural network (CNN). This network's\nperformance is significantly enhanced by employing effective and strategic data\naugmentation techniques, which bolster its ability to generalize to novel,\nunseen channel conditions. Furthermore, DeepCRF incorporates supervised\ncontrastive learning to enhance its robustness against noises. Our evaluations\ndemonstrate that DeepCRF significantly enhances the accuracy of device\nidentification across previously unencountered channels. It outperforms both\nthe conventional model-based methods and standard CNN that lack our specialized\ntraining and enhancement strategies."
  },
  {
    "CAGR": 1.4545947092,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.8153973948,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 2.1709094741,
    "rnd_investment_required_log": 1.2648373378,
    "title": "CodeShell Technical Report",
    "abstract": "Code large language models mark a pivotal breakthrough in artificial\nintelligence. They are specifically crafted to understand and generate\nprogramming languages, significantly boosting the efficiency of coding\ndevelopment workflows. In this technical report, we present CodeShell-Base, a\nseven billion-parameter foundation model with 8K context length, showcasing\nexceptional proficiency in code comprehension. By incorporating Grouped-Query\nAttention and Rotary Positional Embedding into GPT-2, CodeShell-Base integrates\nthe structural merits of StarCoder and CodeLlama and forms its unique\narchitectural design. We then carefully built a comprehensive data\npre-processing process, including similar data deduplication, perplexity-based\ndata filtering, and model-based data filtering. Through this process, We have\ncurated 100 billion high-quality pre-training data from GitHub. Benefiting from\nthe high-quality data, CodeShell-Base outperforms CodeLlama in Humaneval after\ntraining on just 500 billion tokens (5 epochs). We have conducted extensive\nexperiments across multiple language datasets, including Python, Java, and C++,\nand the results indicate that our model possesses robust foundational\ncapabilities in code comprehension and generation."
  },
  {
    "CAGR": 2.973568966,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.808212098,
    "ROI_percent": -0.6698123162,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 1.2605876197,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": -0.692474134,
    "title": "iDAT: inverse Distillation Adapter-Tuning",
    "abstract": "Adapter-Tuning (AT) method involves freezing a pre-trained model and\nintroducing trainable adapter modules to acquire downstream knowledge, thereby\ncalibrating the model for better adaptation to downstream tasks. This paper\nproposes a distillation framework for the AT method instead of crafting a\ncarefully designed adapter module, which aims to improve fine-tuning\nperformance. For the first time, we explore the possibility of combining the AT\nmethod with knowledge distillation. Via statistical analysis, we observe\nsignificant differences in the knowledge acquisition between adapter modules of\ndifferent models. Leveraging these differences, we propose a simple yet\neffective framework called inverse Distillation Adapter-Tuning (iDAT).\nSpecifically, we designate the smaller model as the teacher and the larger\nmodel as the student. The two are jointly trained, and online knowledge\ndistillation is applied to inject knowledge of different perspective to student\nmodel, and significantly enhance the fine-tuning performance on downstream\ntasks. Extensive experiments on the VTAB-1K benchmark with 19 image\nclassification tasks demonstrate the effectiveness of iDAT. The results show\nthat using existing AT method within our iDAT framework can further yield a\n2.66% performance gain, with only an additional 0.07M trainable parameters. Our\napproach compares favorably with state-of-the-arts without bells and whistles.\nOur code is available at https:\/\/github.com\/JCruan519\/iDAT."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 1.5998033579,
    "title": "Optimal Control of Spin Qudits Subject to Decoherence Using Amplitude-and-Frequency-Constrained Pulses",
    "abstract": "Quantum optimal control theory (QOCT) can be used to design the shape of\nelectromagnetic pulses that implement operations on quantum devices. By using\nnon-trivially shaped waveforms, gates can be made significantly faster than\nthose built by concatenating monochromatic pulses. Recently, we applied this\ntechnique to the control of molecular spin qudits modelled with Schr\\\"odinger's\nequation and showed it can speed up operations, helping mitigate the effects of\ndecoherence [Phys. Rev. Appl. 17, 064028 (2022)]. However, short gate times\nresult in large optimal pulse amplitudes, which may not be experimentally\naccessible. Introducing bounds to the amplitudes then unavoidably leads to\nlonger operation times, for which decoherence can no longer be neglected. Here,\nwe study how to improve this procedure by applying QOCT on top of Lindblad's\nequation, to design control pulses accounting for decoherence already in the\noptimization process. In addition, we introduce a formulation that allows us to\nbound the maximum amplitude and frequency of the signals, which are the typical\nlimitations of waveform generators. The pulses we obtain consistently enhance\noperation fidelities compared to those achieved with Schr\\\"odinger's equation\nacross various target gates and durations, demonstrating the flexibility and\nrobustness of our method. The improvement is larger the shorter the spin\ncoherence time $T_{2}$."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.3421832113,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 0.4193630149,
    "rnd_investment_required_log": -0.1558904989,
    "title": "The Impact of Evolutionary Computation on Robotic Design: A Case Study with an Underactuated Hand Exoskeleton",
    "abstract": "Robotic exoskeletons can enhance human strength and aid people with physical\ndisabilities. However, designing them to ensure safety and optimal performance\npresents significant challenges. Developing exoskeletons should incorporate\nspecific optimization algorithms to find the best design. This study\ninvestigates the potential of Evolutionary Computation (EC) methods in robotic\ndesign optimization, with an underactuated hand exoskeleton (U-HEx) used as a\ncase study. We propose improving the performance and usability of the U-HEx\ndesign, which was initially optimized using a naive brute-force approach, by\nintegrating EC techniques such as Genetic Algorithm and Big Bang-Big Crunch\nAlgorithm. Comparative analysis revealed that EC methods consistently yield\nmore precise and optimal solutions than brute force in a significantly shorter\ntime. This allowed us to improve the optimization by increasing the number of\nvariables in the design, which was impossible with naive methods. The results\nshow significant improvements in terms of the torque magnitude the device\ntransfers to the user, enhancing its efficiency. These findings underline the\nimportance of performing proper optimization while designing exoskeletons, as\nwell as providing a significant improvement to this specific robotic design."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -1.5550659269,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.2066838583,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": 1.1599484684,
    "title": "Permutation Recovery Problem against Deletion Errors for DNA Data Storage",
    "abstract": "Owing to its immense storage density and durability, DNA has emerged as a\npromising storage medium. However, due to technological constraints, data can\nonly be written onto many short DNA molecules called data blocks that are\nstored in an unordered way. To handle the unordered nature of DNA data storage\nsystems, a unique address is typically prepended to each data block to form a\nDNA strand. However, DNA storage systems are prone to errors and generate\nmultiple noisy copies of each strand called DNA reads. Thus, we study the\npermutation recovery problem against deletions errors for DNA data storage.\n  The permutation recovery problem for DNA data storage requires one to\nreconstruct the addresses or in other words to uniquely identify the noisy\nreads. By successfully reconstructing the addresses, one can essentially\ndetermine the correct order of the data blocks, effectively solving the\nclustering problem.\n  We first show that we can almost surely identify all the noisy reads under\ncertain mild assumptions. We then propose a permutation recovery procedure and\nanalyze its complexity."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Initialisation and Network Effects in Decentralised Federated Learning",
    "abstract": "Fully decentralised federated learning enables collaborative training of\nindividual machine learning models on a distributed network of communicating\ndevices while keeping the training data localised on each node. This approach\navoids central coordination, enhances data privacy and eliminates the risk of a\nsingle point of failure. Our research highlights that the effectiveness of\ndecentralised federated learning is significantly influenced by the network\ntopology of connected devices and the learning models' initial conditions. We\npropose a strategy for uncoordinated initialisation of the artificial neural\nnetworks based on the distribution of eigenvector centralities of the\nunderlying communication network, leading to a radically improved training\nefficiency. Additionally, our study explores the scaling behaviour and the\nchoice of environmental parameters under our proposed initialisation strategy.\nThis work paves the way for more efficient and scalable artificial neural\nnetwork training in a distributed and uncoordinated environment, offering a\ndeeper understanding of the intertwining roles of network structure and\nlearning dynamics."
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.8651524162,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": -1.027440103,
    "title": "Using Large Language Models for OntoClean-based Ontology Refinement",
    "abstract": "This paper explores the integration of Large Language Models (LLMs) such as\nGPT-3.5 and GPT-4 into the ontology refinement process, specifically focusing\non the OntoClean methodology. OntoClean, critical for assessing the\nmetaphysical quality of ontologies, involves a two-step process of assigning\nmeta-properties to classes and verifying a set of constraints. Manually\nconducting the first step proves difficult in practice, due to the need for\nphilosophical expertise and lack of consensus among ontologists. By employing\nLLMs with two prompting strategies, the study demonstrates that high accuracy\nin the labelling process can be achieved. The findings suggest the potential\nfor LLMs to enhance ontology refinement, proposing the development of plugin\nsoftware for ontology tools to facilitate this integration."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": 0.9204663698,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 1.9391692981,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -1.027440103,
    "title": "Negotiating the Shared Agency between Humans & AI in the Recommender System",
    "abstract": "Smart recommendation algorithms have revolutionized information\ndissemination, enhancing efficiency and reshaping content delivery across\nvarious domains. However, concerns about user agency have arisen due to the\ninherent opacity (information asymmetry) and the nature of one-way output\n(power asymmetry) on algorithms. While both issues have been criticized by\nscholars via advocating explainable AI (XAI) and human-AI collaborative\ndecision-making (HACD), few research evaluates their integrated effects on\nusers, and few HACD discussions in recommender systems beyond improving and\nfiltering the results. This study proposes an incubating idea as a missing step\nin HACD that allows users to control the degrees of AI-recommended content.\nThen, we integrate it with existing XAI to a flow prototype aimed at assessing\nthe enhancement of user agency. We seek to understand how types of agency\nimpact user perception and experience, and bring empirical evidence to refine\nthe guidelines and designs for human-AI interactive systems."
  },
  {
    "CAGR": -0.7548223915,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Towards optimal spatiotemporal wavefront shaping for the cocktail party problem with inverse design of an acoustic reconfigurable metasurface in disordered media",
    "abstract": "Multiple-user multiple-input multiple-output applications have recently\ngained a lot of attention. Here, we show an efficient optimization formulation\nfor the design of all the temporal and spatial degrees of freedom of an\nacoustic reconfigurable metasurface for the cocktail party problem. In the\nfrequency domain, the closed-form least square solution matches the optimal\ntime reversal solution for multiple emitter-receiver pairs, optimizing for each\nfrequency independently. This is more efficient than solving in the time domain\nwhere the time convolution mixes all the degrees of freedom into a\nresource-intensive optimization. We illustrate this methodology by optimizing\nthe frequency response of a design for two pairs of emitters-receivers using\nthe Green's functions of disordered media that are measured experimentally. We\nreport strong performance that will be put in perspective in future work, where\nwe will analyze the robustness of the design to noise in the data and design\nthe convolutional filters that match the optimal frequency response for\nexperiment validation of the design."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 2.0047472922,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.7129330908,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.0762061071,
    "title": "Nanoimprinted Exciton-Polaritons Metasurfaces: Cost-Effective, Large-Scale, High Homogeneity, and Room Temperature Operation",
    "abstract": "Exciton-polaritons represent a promising platform that combines the strengths\nof both photonic and electronic systems for future optoelectronic devices.\nHowever, their application is currently limited to laboratory research due to\nthe high cost and complexity of fabrication methods, which are not compatible\nwith the mature CMOS technology developed for microelectronics. In this work,\nwe develop an innovative, low-cost, and CMOS-compatible method for fabricating\nlarge surface polaritonic devices. This is achieved by direct patterning of a\nhalide-perovskite thin film via thermal nanoimprint. As a result, we observe\nhighly homogeneous polaritonic modes of quality factor $Q\\approx 300$ at room\ntemperature across a centimetric scale. Impressively, the process provides high\nreproducibility and fidelity, as the same mold can be reused more than 10 times\nto imprint the perovskite layer on different types of substrates. Our results\ncould pave the way for the production of low-cost integrated polaritonic\ndevices operating at room temperature."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": -1.2495847072,
    "title": "Improving the Optimization in Model Predictive Controllers: Scheduling Large Groups of Electric Vehicles",
    "abstract": "In parking lots with large groups of electric vehicles (EVs), charging has to\nhappen in a coordinated manner, among others, due to the high load per vehicle\nand the limited capacity of the electricity grid. To achieve such coordination,\nmodel predictive control can be applied, thereby repeatedly solving an\noptimization problem. Due to its repetitive nature and its dependency on the\ntime granularity, optimization has to be (computationally) efficient. The work\npresented here focuses on that optimization subroutine, its computational\nefficiency and how to speed up the optimization for large groups of EVs. In\nparticular, we adapt FOCS, an algorithm that can solve the underlying\noptimization problem, to better suit the repetitive set-up of model predictive\ncontrol by adding a pre-mature stop feature. Based on real-world data, we\nempirically show that the added feature speeds up the median computation time\nfor 1-minute granularity by up to 44%. Furthermore, since FOCS is an algorithm\nthat uses maximum flow methods as a subroutine, the impact of choosing various\nmaximum flow methods on the runtime is investigated. Finally, we compare FOCS\nto a commercially available solver, concluding that FOCS outperforms the\nstate-of-the-art when making a full-day schedule for large groups of EVs."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.0287391931,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.9283973715,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 2.3858924402,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": -0.0791806145,
    "rnd_investment_required_log": 0.7562984273,
    "title": "An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems",
    "abstract": "The increasing prevalence of Cyber-Physical Systems and the Internet of\nThings (CPS-IoT) applications and Foundation Models are enabling new\napplications that leverage real-time control of the environment. For example,\nreal-time control of Heating, Ventilation and Air-Conditioning (HVAC) systems\ncan reduce its usage when not needed for the comfort of human occupants, hence\nreducing energy consumption. Collecting real-time feedback on human preferences\nin such human-in-the-loop (HITL) systems, however, is difficult in practice. We\npropose the use of large language models (LLMs) to deal with the challenges of\ndynamic environments and difficult-to-obtain data in CPS optimization. In this\npaper, we present a case study that employs LLM agents to mimic the behaviors\nand thermal preferences of various population groups (e.g. young families, the\nelderly) in a shopping mall. The aggregated thermal preferences are integrated\ninto an agent-in-the-loop based reinforcement learning algorithm AitL-RL, which\nemploys the LLM as a dynamic simulation of the physical environment to learn\nhow to balance between energy savings and occupant comfort. Our results show\nthat LLMs are capable of simulating complex population movements within large\nopen spaces. Besides, AitL-RL demonstrates superior performance compared to the\npopular existing policy of set point control, suggesting that adaptive and\npersonalized decision-making is critical for efficient optimization in CPS-IoT\napplications. Through this case study, we demonstrate the potential of\nintegrating advanced Foundation Models like LLMs into CPS-IoT to enhance system\nadaptability and efficiency. The project's code can be found on our GitHub\nrepository."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -0.1981394181,
    "rnd_investment_required_log": 0.9097590502,
    "title": "CipherFormer: Efficient Transformer Private Inference with Low Round Complexity",
    "abstract": "There is a growing trend to outsource the inference task of large transformer\nmodels to cloud servers. However, this poses a severe threat to users' private\ndata as they are exposed to cloud servers after uploading. Although several\nworks attempted to provide private inference for transformer models, their\nhundreds of communication rounds limit the application scenarios. Motivated by\nthe desire to minimize round complexity, we propose CipherFormer, a novel\ntransformer private inference scheme using homomorphic encryption and garbled\ncircuits. We present a protocol for quickly computing homomorphic matrix\nmultiplications. We then modify the attention mechanism and design the\ncorresponding garbled circuits. Furthermore, we show how to use a lightweight\nattention mechanism and mixed-bitwidth to reduce the inference latency while\nmaintaining accuracy. In comparison with an advanced homomorphic encryption\nscheme on text classification tasks, our model improves accuracy by 3% to 11%\nwhile performing private inference with a 7.7x-11.9x speedup."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.4686850597,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.9396287803,
    "title": "DISL: Fueling Research with A Large Dataset of Solidity Smart Contracts",
    "abstract": "The DISL dataset features a collection of $514,506$ unique Solidity files\nthat have been deployed to Ethereum mainnet. It caters to the need for a large\nand diverse dataset of real-world smart contracts. DISL serves as a resource\nfor developing machine learning systems and for benchmarking software\nengineering tools designed for smart contracts. By aggregating every verified\nsmart contract from Etherscan up to January 15, 2024, DISL surpasses existing\ndatasets in size and recency."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.7885775055,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -2.4658964612,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Towards Balanced RGB-TSDF Fusion for Consistent Semantic Scene Completion by 3D RGB Feature Completion and a Classwise Entropy Loss Function",
    "abstract": "Semantic Scene Completion (SSC) aims to jointly infer semantics and\noccupancies of 3D scenes. Truncated Signed Distance Function (TSDF), a 3D\nencoding of depth, has been a common input for SSC. Furthermore, RGB-TSDF\nfusion, seems promising since these two modalities provide color and geometry\ninformation, respectively. Nevertheless, RGB-TSDF fusion has been considered\nnontrivial and commonly-used naive addition will result in inconsistent\nresults. We argue that the inconsistency comes from the sparsity of RGB\nfeatures upon projecting into 3D space, while TSDF features are dense, leading\nto imbalanced feature maps when summed up. To address this RGB-TSDF\ndistribution difference, we propose a two-stage network with a 3D RGB feature\ncompletion module that completes RGB features with meaningful values for\noccluded areas. Moreover, we propose an effective classwise entropy loss\nfunction to punish inconsistency. Extensive experiments on public datasets\nverify that our method achieves state-of-the-art performance among methods that\ndo not adopt extra data."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.7036515238,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.1323289524,
    "title": "FLIGAN: Enhancing Federated Learning with Incomplete Data using GAN",
    "abstract": "Federated Learning (FL) provides a privacy-preserving mechanism for\ndistributed training of machine learning models on networked devices (e.g.,\nmobile devices, IoT edge nodes). It enables Artificial Intelligence (AI) at the\nedge by creating models without sharing actual data across the network.\nExisting research typically focuses on generic aspects of non-IID data and\nheterogeneity in client's system characteristics, but they often neglect the\nissue of insufficient data for model development, which can arise from uneven\nclass label distribution and highly variable data volumes across edge nodes. In\nthis work, we propose FLIGAN, a novel approach to address the issue of data\nincompleteness in FL. First, we leverage Generative Adversarial Networks (GANs)\nto adeptly capture complex data distributions and generate synthetic data that\nclosely resemble real-world data. Then, we use synthetic data to enhance the\nrobustness and completeness of datasets across nodes. Our methodology adheres\nto FL's privacy requirements by generating synthetic data in a federated manner\nwithout sharing the actual data in the process. We incorporate techniques such\nas classwise sampling and node grouping, designed to improve the federated\nGAN's performance, enabling the creation of high-quality synthetic datasets and\nfacilitating efficient FL training. Empirical results from our experiments\ndemonstrate that FLIGAN significantly improves model accuracy, especially in\nscenarios with high class imbalances, achieving up to a 20% increase in model\naccuracy over traditional FL baselines."
  },
  {
    "CAGR": -1.5833538043,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 2.0047472922,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.692474134,
    "title": "A Multi-Stage Framework for Joint Chest X-Ray Diagnosis and Visual Attention Prediction Using Deep Learning",
    "abstract": "Purpose: As visual inspection is an inherent process during radiological\nscreening, the associated eye gaze data can provide valuable insights into\nrelevant clinical decisions. As deep learning has become the state-of-the-art\nfor computer-assisted diagnosis, integrating human behavior, such as eye gaze\ndata, into these systems is instrumental to help align machine predictions with\nclinical diagnostic criteria, thus enhancing the quality of automatic\nradiological diagnosis. Methods: We propose a novel deep learning framework for\njoint disease diagnosis and prediction of corresponding clinical visual\nattention maps for chest X-ray scans. Specifically, we introduce a new\ndual-encoder multi-task UNet, which leverages both a DenseNet201 backbone and a\nResidual and Squeeze-and-Excitation block-based encoder to extract diverse\nfeatures for visual attention map prediction, and a multi-scale feature-fusion\nclassifier to perform disease classification. To tackle the issue of\nasynchronous training schedules of individual tasks in multi-task learning, we\nproposed a multi-stage cooperative learning strategy, with contrastive learning\nfor feature encoder pretraining to boost performance. Results: Our proposed\nmethod is shown to significantly outperform existing techniques for chest X-ray\ndiagnosis (AUC=0.93) and the quality of visual attention map prediction\n(Correlation coefficient=0.58). Conclusion: Benefiting from the proposed\nmulti-task multi-stage cooperative learning, our technique demonstrates the\nbenefit of integrating clinicians' eye gaze into clinical AI systems to boost\nperformance and potentially explainability."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.0817321758,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.8206417531,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -1.5504097469,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.9786301475,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.692474134,
    "title": "GOLF: Goal-Oriented Long-term liFe tasks supported by human-AI collaboration",
    "abstract": "The advent of ChatGPT and similar large language models (LLMs) has\nrevolutionized the human-AI interaction and information-seeking process.\nLeveraging LLMs as an alternative to search engines, users can now access\nsummarized information tailored to their queries, significantly reducing the\ncognitive load associated with navigating vast information resources. This\nshift underscores the potential of LLMs in redefining information access\nparadigms. Drawing on the foundation of task-focused information retrieval and\nLLMs' task planning ability, this research extends the scope of LLM\ncapabilities beyond routine task automation to support users in navigating\nlong-term and significant life tasks. It introduces the GOLF framework\n(Goal-Oriented Long-term liFe tasks), which focuses on enhancing LLMs' ability\nto assist in significant life decisions through goal orientation and long-term\nplanning. The methodology encompasses a comprehensive simulation study to test\nthe framework's efficacy, followed by model and human evaluations to develop a\ndataset benchmark for long-term life tasks, and experiments across different\nmodels and settings. By shifting the focus from short-term tasks to the broader\nspectrum of long-term life goals, this research underscores the transformative\npotential of LLMs in enhancing human decision-making processes and task\nmanagement, marking a significant step forward in the evolution of human-AI\ncollaboration."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -0.4978916609,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Corra: Correlation-Aware Column Compression",
    "abstract": "Column encoding schemes have witnessed a spark of interest with the rise of\nopen storage formats (like Parquet) in data lakes in modern cloud deployments.\nThis is not surprising -- as data volume increases, it becomes more and more\nimportant to reduce storage cost on block storage (such as S3) as well as\nreduce memory pressure in multi-tenant in-memory buffers of cloud databases.\nHowever, single-column encoding schemes have reached a plateau in terms of the\ncompression size they can achieve.\n  We argue that this is due to the neglect of cross-column correlations. For\ninstance, consider the column pair ($\\texttt{city}$, $\\texttt{zip_code}$).\nTypically, cities have only a few dozen unique zip codes. If this information\nis properly exploited, it can significantly reduce the space consumption of the\nlatter column.\n  In this work, we depart from the established path of compressing data using\nonly single-column encoding schemes and introduce several what we call\n$\\textit{horizontal}$, correlation-aware encoding schemes. We demonstrate their\nadvantages over single-column encoding schemes on the well-known TPC-H's\n$\\texttt{lineitem}$, LDBC's $\\texttt{message}$, DMV, and Taxi datasets. Our\ncorrelation-aware encoding schemes save up to 58.3% of the compressed size over\nsingle-column schemes for $\\texttt{lineitem}$'s $\\texttt{receiptdate}$, 53.7%\nfor DMV's $\\texttt{zip_code}$, and 85.16% for Taxi's $\\texttt{total_amount}$."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.5073055989,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": -1.0271308869,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Latency-Aware Generative Semantic Communications with Pre-Trained Diffusion Models",
    "abstract": "Generative foundation AI models have recently shown great success in\nsynthesizing natural signals with high perceptual quality using only textual\nprompts and conditioning signals to guide the generation process. This enables\nsemantic communications at extremely low data rates in future wireless\nnetworks. In this paper, we develop a latency-aware semantic communications\nframework with pre-trained generative models. The transmitter performs\nmulti-modal semantic decomposition on the input signal and transmits each\nsemantic stream with the appropriate coding and communication schemes based on\nthe intent. For the prompt, we adopt a re-transmission-based scheme to ensure\nreliable transmission, and for the other semantic modalities we use an adaptive\nmodulation\/coding scheme to achieve robustness to the changing wireless\nchannel. Furthermore, we design a semantic and latency-aware scheme to allocate\ntransmission power to different semantic modalities based on their importance\nsubjected to semantic quality constraints. At the receiver, a pre-trained\ngenerative model synthesizes a high fidelity signal using the received\nmulti-stream semantics. Simulation results demonstrate ultra-low-rate,\nlow-latency, and channel-adaptive semantic communications."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 1.281893344,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.018090997,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.442284741,
    "title": "Unsupervised Learning for Joint Beamforming Design in RIS-aided ISAC Systems",
    "abstract": "It is critical to design efficient beamforming in reconfigurable intelligent\nsurface (RIS)-aided integrated sensing and communication (ISAC) systems for\nenhancing spectrum utilization. However, conventional methods often have\nlimitations, either incurring high computational complexity due to iterative\nalgorithms or sacrificing performance when using heuristic methods. To achieve\nboth low complexity and high spectrum efficiency, an unsupervised\nlearning-based beamforming design is proposed in this work. We tailor\nimage-shaped channel samples and develop an ISAC beamforming neural network\n(IBF-Net) model for beamforming. By leveraging unsupervised learning, the loss\nfunction incorporates key performance metrics like sensing and communication\nchannel correlation and sensing channel gain, eliminating the need of labeling.\nSimulations show that the proposed method achieves competitive performance\ncompared to benchmarks while significantly reduces computational complexity."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.6008783938,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.3373958805,
    "title": "EL-MLFFs: Ensemble Learning of Machine Leaning Force Fields",
    "abstract": "Machine learning force fields (MLFFs) have emerged as a promising approach to\nbridge the accuracy of quantum mechanical methods and the efficiency of\nclassical force fields. However, the abundance of MLFF models and the challenge\nof accurately predicting atomic forces pose significant obstacles in their\npractical application. In this paper, we propose a novel ensemble learning\nframework, EL-MLFFs, which leverages the stacking method to integrate\npredictions from diverse MLFFs and enhance force prediction accuracy. By\nconstructing a graph representation of molecular structures and employing a\ngraph neural network (GNN) as the meta-model, EL-MLFFs effectively captures\natomic interactions and refines force predictions. We evaluate our approach on\ntwo distinct datasets: methane molecules and methanol adsorbed on a Cu(100)\nsurface. The results demonstrate that EL-MLFFs significantly improves force\nprediction accuracy compared to individual MLFFs, with the ensemble of all\neight models yielding the best performance. Moreover, our ablation study\nhighlights the crucial roles of the residual network and graph attention layers\nin the model's architecture. The EL-MLFFs framework offers a promising solution\nto the challenges of model selection and force prediction accuracy in MLFFs,\npaving the way for more reliable and efficient molecular simulations."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.0164407866,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.876511833,
    "break_even_time_years": -1.9851926003,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.7018568771,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 2.3141419596,
    "annual_revenue_USD_log": 1.5534070302,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Naive Bayes-based Context Extension for Large Language Models",
    "abstract": "Large Language Models (LLMs) have shown promising in-context learning\nabilities. However, conventional In-Context Learning (ICL) approaches are often\nimpeded by length limitations of transformer architecture, which pose\nchallenges when attempting to effectively integrate supervision from a\nsubstantial number of demonstration examples. In this paper, we introduce a\nnovel framework, called Naive Bayes-based Context Extension (NBCE), to enable\nexisting LLMs to perform ICL with an increased number of demonstrations by\nsignificantly expanding their context size. Importantly, this expansion does\nnot require fine-tuning or dependence on particular model architectures, all\nthe while preserving linear efficiency. NBCE initially splits the context into\nequal-sized windows fitting the target LLM's maximum length. Then, it\nintroduces a voting mechanism to select the most relevant window, regarded as\nthe posterior context. Finally, it employs Bayes' theorem to generate the test\ntask. Our experimental results demonstrate that NBCE substantially enhances\nperformance, particularly as the number of demonstration examples increases,\nconsistently outperforming alternative methods. The NBCE code will be made\npublicly accessible. The code NBCE is available at:\nhttps:\/\/github.com\/amurtadha\/NBCE-master"
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Fake or JPEG? Revealing Common Biases in Generated Image Detection Datasets",
    "abstract": "The widespread adoption of generative image models has highlighted the urgent\nneed to detect artificial content, which is a crucial step in combating\nwidespread manipulation and misinformation. Consequently, numerous detectors\nand associated datasets have emerged. However, many of these datasets\ninadvertently introduce undesirable biases, thereby impacting the effectiveness\nand evaluation of detectors. In this paper, we emphasize that many datasets for\nAI-generated image detection contain biases related to JPEG compression and\nimage size. Using the GenImage dataset, we demonstrate that detectors indeed\nlearn from these undesired factors. Furthermore, we show that removing the\nnamed biases substantially increases robustness to JPEG compression and\nsignificantly alters the cross-generator performance of evaluated detectors.\nSpecifically, it leads to more than 11 percentage points increase in\ncross-generator performance for ResNet50 and Swin-T detectors on the GenImage\ndataset, achieving state-of-the-art results.\n  We provide the dataset and source codes of this paper on the anonymous\nwebsite: https:\/\/www.unbiased-genimage.org"
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": 0.7562984273,
    "title": "PeersimGym: An Environment for Solving the Task Offloading Problem with Reinforcement Learning",
    "abstract": "Task offloading, crucial for balancing computational loads across devices in\nnetworks such as the Internet of Things, poses significant optimization\nchallenges, including minimizing latency and energy usage under strict\ncommunication and storage constraints. While traditional optimization falls\nshort in scalability; and heuristic approaches lack in achieving optimal\noutcomes, Reinforcement Learning (RL) offers a promising avenue by enabling the\nlearning of optimal offloading strategies through iterative interactions.\nHowever, the efficacy of RL hinges on access to rich datasets and\ncustom-tailored, realistic training environments. To address this, we introduce\nPeersimGym, an open-source, customizable simulation environment tailored for\ndeveloping and optimizing task offloading strategies within computational\nnetworks. PeersimGym supports a wide range of network topologies and\ncomputational constraints and integrates a \\textit{PettingZoo}-based interface\nfor RL agent deployment in both solo and multi-agent setups. Furthermore, we\ndemonstrate the utility of the environment through experiments with Deep\nReinforcement Learning agents, showcasing the potential of RL-based approaches\nto significantly enhance offloading strategies in distributed computing\nsettings. PeersimGym thus bridges the gap between theoretical RL models and\ntheir practical applications, paving the way for advancements in efficient task\noffloading methodologies."
  },
  {
    "CAGR": -0.2024681163,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.8376639867,
    "ROI_percent": -1.3926662644,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6328746732,
    "annual_revenue_USD_log": -1.9316877958,
    "rnd_investment_required_log": -2.1617733098,
    "title": "Using Stratified Sampling to Improve LIME Image Explanations",
    "abstract": "We investigate the use of a stratified sampling approach for LIME Image, a\npopular model-agnostic explainable AI method for computer vision tasks, in\norder to reduce the artifacts generated by typical Monte Carlo sampling. Such\nartifacts are due to the undersampling of the dependent variable in the\nsynthetic neighborhood around the image being explained, which may result in\ninadequate explanations due to the impossibility of fitting a linear regressor\non the sampled data. We then highlight a connection with the Shapley theory,\nwhere similar arguments about undersampling and sample relevance were suggested\nin the past. We derive all the formulas and adjustment factors required for an\nunbiased stratified sampling estimator. Experiments show the efficacy of the\nproposed approach."
  },
  {
    "CAGR": 2.6973918284,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.6315007656,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving",
    "abstract": "The automated generation of diverse and complex training scenarios has been\nan important ingredient in many complex learning tasks. Especially in\nreal-world application domains, such as autonomous driving, auto-curriculum\ngeneration is considered vital for obtaining robust and general policies.\nHowever, crafting traffic scenarios with multiple, heterogeneous agents is\ntypically considered as a tedious and time-consuming task, especially in more\ncomplex simulation environments. In our work, we introduce MATS-Gym, a\nMulti-Agent Traffic Scenario framework to train agents in CARLA, a\nhigh-fidelity driving simulator. MATS-Gym is a multi-agent training framework\nfor autonomous driving that uses partial scenario specifications to generate\ntraffic scenarios with variable numbers of agents. This paper unifies various\nexisting approaches to traffic scenario description into a single training\nframework and demonstrates how it can be integrated with techniques from\nunsupervised environment design to automate the generation of adaptive\nauto-curricula. The code is available at\nhttps:\/\/github.com\/AutonomousDrivingExaminer\/mats-gym."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.0817321758,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": -0.5595405096,
    "title": "D-PAD: Deep-Shallow Multi-Frequency Patterns Disentangling for Time Series Forecasting",
    "abstract": "In time series forecasting, effectively disentangling intricate temporal\npatterns is crucial. While recent works endeavor to combine decomposition\ntechniques with deep learning, multiple frequencies may still be mixed in the\ndecomposed components, e.g., trend and seasonal. Furthermore, frequency domain\nanalysis methods, e.g., Fourier and wavelet transforms, have limitations in\nresolution in the time domain and adaptability. In this paper, we propose\nD-PAD, a deep-shallow multi-frequency patterns disentangling neural network for\ntime series forecasting. Specifically, a multi-component decomposing (MCD)\nblock is introduced to decompose the series into components with different\nfrequency ranges, corresponding to the \"shallow\" aspect. A\ndecomposition-reconstruction-decomposition (D-R-D) module is proposed to\nprogressively extract the information of frequencies mixed in the components,\ncorresponding to the \"deep\" aspect. After that, an interaction and fusion (IF)\nmodule is used to further analyze the components. Extensive experiments on\nseven real-world datasets demonstrate that D-PAD achieves the state-of-the-art\nperformance, outperforming the best baseline by an average of 9.48% and 7.15%\nin MSE and MAE, respectively."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "GPFL: A Gradient Projection-Based Client Selection Framework for Efficient Federated Learning",
    "abstract": "Federated learning client selection is crucial for determining participant\nclients while balancing model accuracy and communication efficiency. Existing\nmethods have limitations in handling data heterogeneity, computational burdens,\nand independent client treatment. To address these challenges, we propose GPFL,\nwhich measures client value by comparing local and global descent directions.\nWe also employ an Exploit-Explore mechanism to enhance performance.\nExperimental results on FEMINST and CIFAR-10 datasets demonstrate that GPFL\noutperforms baselines in Non-IID scenarios, achieving over 9\\% improvement in\nFEMINST test accuracy. Moreover, GPFL exhibits shorter computation times\nthrough pre-selection and parameter reuse in federated learning."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8572985792,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 1.4463427327,
    "title": "ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages",
    "abstract": "Question answering (QA) and Machine Reading Comprehension (MRC) tasks have\nsignificantly advanced in recent years due to the rapid development of deep\nlearning techniques and, more recently, large language models. At the same\ntime, many benchmark datasets have become available for QA and MRC tasks.\nHowever, most existing large-scale benchmark datasets have been created\npredominantly using synchronous document collections like Wikipedia or the Web.\nArchival document collections, such as historical newspapers, contain valuable\ninformation from the past that is still not widely used to train large language\nmodels. To further contribute to advancing QA and MRC tasks and to overcome the\nlimitation of previous datasets, we introduce ChroniclingAmericaQA, a\nlarge-scale temporal QA dataset with 487K question-answer pairs created based\non the historical newspaper collection Chronicling America. Our dataset is\nconstructed from a subset of the Chronicling America newspaper collection\nspanning 120 years. One of the significant challenges for utilizing digitized\nhistorical newspaper collections is the low quality of OCR text. Therefore, to\nenable realistic testing of QA models, our dataset can be used in three\ndifferent ways: answering questions from raw and noisy content, answering\nquestions from cleaner, corrected version of the content, as well as answering\nquestions from scanned images of newspaper pages. This and the fact that\nChroniclingAmericaQA spans the longest time period among available QA datasets\nmake it quite a unique and useful resource."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 2.3141419596,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": 1.2648373378,
    "title": "An AI-Native Runtime for Multi-Wearable Environments",
    "abstract": "The miniaturization of AI accelerators is paving the way for next-generation\nwearable applications within wearable technologies. We introduce Mojito, an\nAI-native runtime with advanced MLOps designed to facilitate the development\nand deployment of these applications on wearable devices. It emphasizes the\nnecessity of dynamic orchestration of distributed resources equipped with\nultra-low-power AI accelerators to overcome challenges associated with\nunpredictable runtime environments. Through its innovative approaches, Mojito\ndemonstrates how future wearable technologies can evolve to be more autonomous."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.1799051383,
    "ROI_percent": 1.281893344,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.0592499803,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": 2.4706617266,
    "rnd_investment_required_log": 2.1363870464,
    "title": "Enhancing Indoor and Outdoor THz Communications with Beyond Diagonal-IRS: Optimization and Performance Analysis",
    "abstract": "This work investigates the application of Beyond Diagonal Intelligent\nReflective Surface (BD-IRS) to enhance THz downlink communication systems,\noperating in a hybrid: reflective and transmissive mode, to simultaneously\nprovide services to indoor and outdoor users. We propose an optimization\nframework that jointly optimizes the beamforming vectors and phase shifts in\nthe hybrid reflective\/transmissive mode, aiming to maximize the system sum\nrate. To tackle the challenges in solving the joint design problem, we employ\nthe conjugate gradient method and propose an iterative algorithm that\nsuccessively optimizes the hybrid beamforming vectors and the phase shifts.\nThrough comprehensive numerical simulations, our findings demonstrate a\nsignificant improvement in rate when compared to existing benchmark schemes,\nincluding time- and frequency-divided approaches, by approximately $30.5\\%$ and\n$69.9\\%$ respectively and even outperforms the STAR-IRS system by $76.99\\%$.\nThis underscores the significant influence of IRS elements on system\nperformance relative to that of base station antennas, highlighting their\npivotal role in advancing the communication system efficacy."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8572985792,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.692474134,
    "title": "Towards Explaining Hypercomplex Neural Networks",
    "abstract": "Hypercomplex neural networks are gaining increasing interest in the deep\nlearning community. The attention directed towards hypercomplex models\noriginates from several aspects, spanning from purely theoretical and\nmathematical characteristics to the practical advantage of lightweight models\nover conventional networks, and their unique properties to capture both global\nand local relations. In particular, a branch of these architectures,\nparameterized hypercomplex neural networks (PHNNs), has also gained popularity\ndue to their versatility across a multitude of application domains.\nNonetheless, only few attempts have been made to explain or interpret their\nintricacies. In this paper, we propose inherently interpretable PHNNs and\nquaternion-like networks, thus without the need for any post-hoc method. To\nachieve this, we define a type of cosine-similarity transform within the\nparameterized hypercomplex domain. This PHB-cos transform induces weight\nalignment with relevant input features and allows to reduce the model into a\nsingle linear transform, rendering it directly interpretable. In this work, we\nstart to draw insights into how this unique branch of neural models operates.\nWe observe that hypercomplex networks exhibit a tendency to concentrate on the\nshape around the main object of interest, in addition to the shape of the\nobject itself. We provide a thorough analysis, studying single neurons of\ndifferent layers and comparing them against how real-valued networks learn. The\ncode of the paper is available at https:\/\/github.com\/ispamm\/HxAI."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": -0.1558904989,
    "title": "SpectralWaste Dataset: Multimodal Data for Waste Sorting Automation",
    "abstract": "The increase in non-biodegradable waste is a worldwide concern. Recycling\nfacilities play a crucial role, but their automation is hindered by the complex\ncharacteristics of waste recycling lines like clutter or object deformation. In\naddition, the lack of publicly available labeled data for these environments\nmakes developing robust perception systems challenging. Our work explores the\nbenefits of multimodal perception for object segmentation in real waste\nmanagement scenarios. First, we present SpectralWaste, the first dataset\ncollected from an operational plastic waste sorting facility that provides\nsynchronized hyperspectral and conventional RGB images. This dataset contains\nlabels for several categories of objects that commonly appear in sorting plants\nand need to be detected and separated from the main trash flow for several\nreasons, such as security in the management line or reuse. Additionally, we\npropose a pipeline employing different object segmentation architectures and\nevaluate the alternatives on our dataset, conducting an extensive analysis for\nboth multimodal and unimodal alternatives. Our evaluation pays special\nattention to efficiency and suitability for real-time processing and\ndemonstrates how HSI can bring a boost to RGB-only perception in these\nrealistic industrial settings without much computational overhead."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.3083853421,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.6237901171,
    "title": "Learning Piecewise Residuals of Control Barrier Functions for Safety of Switching Systems using Multi-Output Gaussian Processes",
    "abstract": "Control barrier functions (CBFs) have recently been introduced as a\nsystematic tool to ensure safety by establishing set invariance. When combined\nwith a control Lyapunov function (CLF), they form a safety-critical control\nmechanism. However, the effectiveness of CBFs and CLFs is closely tied to the\nsystem model. In practice, model uncertainty can jeopardize safety and\nstability guarantees and may lead to undesirable performance. In this paper, we\ndevelop a safe learning-based control strategy for switching systems in the\nface of uncertainty. We focus on the case that a nominal model is available for\na true underlying switching system. This uncertainty results in piecewise\nresiduals for each switching surface, impacting the CLF and CBF constraints. We\nintroduce a batch multi-output Gaussian process (MOGP) framework to approximate\nthese piecewise residuals, thereby mitigating the adverse effects of\nuncertainty. A particular structure of the covariance function enables us to\nconvert the MOGP-based chance constraints CLF and CBF into second-order cone\nconstraints, which leads to a convex optimization. We analyze the feasibility\nof the resulting optimization and provide the necessary and sufficient\nconditions for feasibility. The effectiveness of the proposed strategy is\nvalidated through a simulation of a switching adaptive cruise control system."
  },
  {
    "CAGR": 0.6260632965,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.1799051383,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 2.4830881658,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.5383218201,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Self-Clustering Hierarchical Multi-Agent Reinforcement Learning with Extensible Cooperation Graph",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) has been successful in solving many\ncooperative challenges. However, classic non-hierarchical MARL algorithms still\ncannot address various complex multi-agent problems that require hierarchical\ncooperative behaviors. The cooperative knowledge and policies learned in\nnon-hierarchical algorithms are implicit and not interpretable, thereby\nrestricting the integration of existing knowledge. This paper proposes a novel\nhierarchical MARL model called Hierarchical Cooperation Graph Learning (HCGL)\nfor solving general multi-agent problems. HCGL has three components: a dynamic\nExtensible Cooperation Graph (ECG) for achieving self-clustering cooperation; a\ngroup of graph operators for adjusting the topology of ECG; and an MARL\noptimizer for training these graph operators. HCGL's key distinction from other\nMARL models is that the behaviors of agents are guided by the topology of ECG\ninstead of policy neural networks. ECG is a three-layer graph consisting of an\nagent node layer, a cluster node layer, and a target node layer. To manipulate\nthe ECG topology in response to changing environmental conditions, four graph\noperators are trained to adjust the edge connections of ECG dynamically. The\nhierarchical feature of ECG provides a unique approach to merge primitive\nactions (actions executed by the agents) and cooperative actions (actions\nexecuted by the clusters) into a unified action space, allowing us to integrate\nfundamental cooperative knowledge into an extensible interface. In our\nexperiments, the HCGL model has shown outstanding performance in multi-agent\nbenchmarks with sparse rewards. We also verify that HCGL can easily be\ntransferred to large-scale scenarios with high zero-shot transfer success\nrates."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.7036515238,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.2047175397,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -1.1372752271,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": 0.8331725486,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": 0.9097590502,
    "title": "ANOCA: AC Network-aware Optimal Curtailment Approach for Dynamic Hosting Capacity",
    "abstract": "With exponential growth in distributed energy resources (DERs) coupled with\nat-capacity distribution grid infrastructure, prosumers cannot always export\nall extra power to the grid without violating technical limits. Consequently, a\nslew of dynamic hosting capacity (DHC) algorithms have emerged for optimal\nutilization of grid infrastructure while maximizing export from DERs. Most of\nthese DHC algorithms utilize the concept of operating envelopes (OE), where the\nutility gives prosumers technical power export limits, and they are free to\nexport power within these limits. Recent studies have shown that OE-based\nframeworks have drawbacks, as most develop power export limits based on convex\nor linear grid models. As OEs must capture extreme operating conditions, both\nconvex and linear models can violate technical limits in practice because they\napproximate grid physics. However, AC models are unsuitable because they may\nnot be feasible within the whole region of OE. We propose a new two-stage\noptimization framework for DHC built on three-phase AC models to address the\ncurrent gaps. In this approach, the prosumers first run a receding horizon\nmulti-period optimization to identify optimal export power setpoints to\ncommunicate with the utility. The utility then performs an infeasibility-based\noptimization to either accept the prosumer's request or dispatch an optimal\ncurtail signal such that overall system technical constraints are not violated.\nTo explore various curtailment strategies, we develop an L1, L2, and Linf\nnorm-based dispatch algorithm with an exact three-phase AC model. We test our\nframework on a 1420 three-phase node meshed distribution network and show that\nthe proposed algorithm optimally curtails DERs while guaranteeing the AC\nfeasibility of the network."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.692474134,
    "title": "HealthGAT: Node Classifications in Electronic Health Records using Graph Attention Networks",
    "abstract": "While electronic health records (EHRs) are widely used across various\napplications in healthcare, most applications use the EHRs in their raw\n(tabular) format. Relying on raw or simple data pre-processing can greatly\nlimit the performance or even applicability of downstream tasks using EHRs. To\naddress this challenge, we present HealthGAT, a novel graph attention network\nframework that utilizes a hierarchical approach to generate embeddings from\nEHR, surpassing traditional graph-based methods. Our model iteratively refines\nthe embeddings for medical codes, resulting in improved EHR data analysis. We\nalso introduce customized EHR-centric auxiliary pre-training tasks to leverage\nthe rich medical knowledge embedded within the data. This approach provides a\ncomprehensive analysis of complex medical relationships and offers significant\nadvancement over standard data representation techniques. HealthGAT has\ndemonstrated its effectiveness in various healthcare scenarios through\ncomprehensive evaluations against established methodologies. Specifically, our\nmodel shows outstanding performance in node classification and downstream tasks\nsuch as predicting readmissions and diagnosis classifications.\n  Our code is available at https:\/\/github.com\/healthylaife\/HealthGAT"
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.2360999473,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": -0.0369520687,
    "annual_revenue_USD_log": 0.5923303378,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Pseudo-MRI-Guided PET Image Reconstruction Method Based on a Diffusion Probabilistic Model",
    "abstract": "Anatomically guided PET reconstruction using MRI information has been shown\nto have the potential to improve PET image quality. However, these improvements\nare limited to PET scans with paired MRI information. In this work we employed\na diffusion probabilistic model (DPM) to infer T1-weighted-MRI (deep-MRI)\nimages from FDG-PET brain images. We then use the DPM-generated T1w-MRI to\nguide the PET reconstruction. The model was trained with brain FDG scans, and\ntested in datasets containing multiple levels of counts. Deep-MRI images\nappeared somewhat degraded than the acquired MRI images. Regarding PET image\nquality, volume of interest analysis in different brain regions showed that\nboth PET reconstructed images using the acquired and the deep-MRI images\nimproved image quality compared to OSEM. Same conclusions were found analysing\nthe decimated datasets. A subjective evaluation performed by two physicians\nconfirmed that OSEM scored consistently worse than the MRI-guided PET images\nand no significant differences were observed between the MRI-guided PET images.\nThis proof of concept shows that it is possible to infer DPM-based MRI imagery\nto guide the PET reconstruction, enabling the possibility of changing\nreconstruction parameters such as the strength of the prior on anatomically\nguided PET reconstruction in the absence of MRI."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Non-Resonant Picosecond Three-Wave Mixing in the Gas Phase",
    "abstract": "We report on the experimental observation of non-resonant, second-order\noptical Sum-Frequency Generation (SFG) in five different atomic and molecular\ngases. The measured signal is attributed to a SFG process by characterizing its\nintensity scaling and its polarization behavior. We show that the electric\nquadrupole mechanism cannot explain the observed trends. Our results\ndemonstrate that SFG in the gas phase is about four orders of magnitude\nstronger than Third Harmonic Generation (THG) and independent from any\nexternally-applied electric fields. These features make this method suitable\nfor gas number density measurements at the picosecond timescale in reactive\nflows and plasmas."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.7326525797,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -1.5704720804,
    "rnd_investment_required_log": 0.6514095594,
    "title": "Looking Beyond What You See: An Empirical Analysis on Subgroup Intersectional Fairness for Multi-label Chest X-ray Classification Using Social Determinants of Racial Health Inequities",
    "abstract": "There has been significant progress in implementing deep learning models in\ndisease diagnosis using chest X- rays. Despite these advancements, inherent\nbiases in these models can lead to disparities in prediction accuracy across\nprotected groups. In this study, we propose a framework to achieve accurate\ndiagnostic outcomes and ensure fairness across intersectional groups in\nhigh-dimensional chest X- ray multi-label classification. Transcending\ntraditional protected attributes, we consider complex interactions within\nsocial determinants, enabling a more granular benchmark and evaluation of\nfairness. We present a simple and robust method that involves retraining the\nlast classification layer of pre-trained models using a balanced dataset across\ngroups. Additionally, we account for fairness constraints and integrate\nclass-balanced fine-tuning for multi-label settings. The evaluation of our\nmethod on the MIMIC-CXR dataset demonstrates that our framework achieves an\noptimal tradeoff between accuracy and fairness compared to baseline methods."
  },
  {
    "CAGR": 0.9022404341,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.1824096676,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Generative Medical Segmentation",
    "abstract": "Rapid advancements in medical image segmentation performance have been\nsignificantly driven by the development of Convolutional Neural Networks (CNNs)\nand Vision Transformers (ViTs). These models follow the discriminative\npixel-wise classification learning paradigm and often have limited ability to\ngeneralize across diverse medical imaging datasets. In this manuscript, we\nintroduce Generative Medical Segmentation (GMS), a novel approach leveraging a\ngenerative model to perform image segmentation. Concretely, GMS employs a\nrobust pre-trained vision foundation model to extract latent representations\nfor images and corresponding ground truth masks, followed by a model that\nlearns a mapping function from the image to the mask in the latent space. Once\ntrained, the model generates an estimated segmentation mask using the\npre-trained vision foundation model to decode the predicted latent\nrepresentation back into the image space. The design of GMS leads to fewer\ntrainable parameters in the model which reduces the risk of overfitting and\nenhances its generalization capability. Our experimental analysis across five\npublic datasets in different medical imaging domains demonstrates GMS\noutperforms existing discriminative and generative segmentation models.\nFurthermore, GMS is able to generalize well across datasets from different\ncenters within the same imaging modality. Our experiments suggest GMS offers a\nscalable and effective solution for medical image segmentation. GMS\nimplementation and trained model weights are available at\nhttps:\/\/github.com\/King-HAW\/GMS."
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -1.1035246851,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.8995375913,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Hybrid silicon all-optical switching devices integrated with two-dimensional material",
    "abstract": "We propose and demonstrate hybrid all-optical switching devices that combine\nsilicon nanocavities and two-dimensional semiconductor material. By exploiting\nthe refractive index modulation caused by photo-induced carriers in the\ntwo-dimensional material instead of the silicon substrate, we overcome the\nswitching performance limitation imposed by the substrate material. Air-mode\nphotonic crystal nanobeam cavities capable of efficient interaction with\ntwo-dimensional materials are fabricated, and molybdenum ditelluride, a\ntwo-dimensional material with rapid carrier recombination, is transferred onto\nthe cavities. The molybdenum ditelluride flake is excited by an optical pump\npulse to shift the resonant wavelength of the cavity for switching operation.\nWe have successfully achieved all-optical switching operations on the time\nscale of tens of picoseconds while requiring low switching energies of a few\nhundred femtojoules."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -2.1424131503,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.7562984273,
    "title": "Next-Generation Time-Resolved Scanning Probe Microscopy",
    "abstract": "Understanding the nanoscale carrier dynamics induced by light excitation is\nthe key to unlocking futuristic devices and innovative functionalities in\nadvanced materials. Optical pump-probe scanning tunneling microscopy (OPP-STM)\nhas opened a window to these phenomena. However, mastering the combination of\nultrafast pulsed lasers with STM requires high expertise and effort. We have\nshattered this barrier and developed a compact OPP-STM system accessible to\nall. This system precisely controls laser pulse timing electrically and enables\nstable laser irradiation on sample surfaces. Furthermore, by applying this\ntechnique to atomic force microscopy (AFM), we have captured time-resolved\nforce signals with an exceptionally high signal-to-noise ratio. Originating\nfrom the dipole-dipole interactions, these signals provide insights into the\ncarrier dynamics on sample surfaces, which are activated by photo-illumination.\nThese technologies are promising as powerful tools for exploring a wide range\nof photoinduced phenomena in conductive and insulating materials."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check",
    "abstract": "Retrieval-Augmented Generation (RAG) aims to generate more reliable and\naccurate responses, by augmenting large language models (LLMs) with the\nexternal vast and dynamic knowledge. Most previous work focuses on using RAG\nfor single-round question answering, while how to adapt RAG to the complex\nconversational setting wherein the question is interdependent on the preceding\ncontext is not well studied. In this paper, we propose a conversation-level RAG\napproach, which incorporates fine-grained retrieval augmentation and self-check\nfor conversational question answering (CQA). In particular, our approach\nconsists of three components, namely conversational question refiner,\nfine-grained retriever and self-check based response generator, which work\ncollaboratively for question understanding and relevant information acquisition\nin conversational settings. Extensive experiments demonstrate the great\nadvantages of our approach over the state-of-the-art baselines. Moreover, we\nalso release a Chinese CQA dataset with new features including reformulated\nquestion, extracted keyword, retrieved paragraphs and their helpfulness, which\nfacilitates further researches in RAG enhanced CQA."
  },
  {
    "CAGR": 2.973568966,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.0592499803,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": 1.2607533636,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Enhancing Generative Class Incremental Learning Performance with Model Forgetting Approach",
    "abstract": "This study presents a novel approach to Generative Class Incremental Learning\n(GCIL) by introducing the forgetting mechanism, aimed at dynamically managing\nclass information for better adaptation to streaming data. GCIL is one of the\nhot topics in the field of computer vision, and this is considered one of the\ncrucial tasks in society, specifically the continual learning of generative\nmodels. The ability to forget is a crucial brain function that facilitates\ncontinual learning by selectively discarding less relevant information for\nhumans. However, in the field of machine learning models, the concept of\nintentionally forgetting has not been extensively investigated. In this study\nwe aim to bridge this gap by incorporating the forgetting mechanisms into GCIL,\nthereby examining their impact on the models' ability to learn in continual\nlearning. Through our experiments, we have found that integrating the\nforgetting mechanisms significantly enhances the models' performance in\nacquiring new knowledge, underscoring the positive role that strategic\nforgetting plays in the process of continual learning."
  },
  {
    "CAGR": -0.4510275401,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 1.0963433736,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.3469684869,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -1.0364164027,
    "annual_revenue_USD_log": 1.2607533636,
    "rnd_investment_required_log": 0.3526483917,
    "title": "H2ASeg: Hierarchical Adaptive Interaction and Weighting Network for Tumor Segmentation in PET\/CT Images",
    "abstract": "Positron emission tomography (PET) combined with computed tomography (CT)\nimaging is routinely used in cancer diagnosis and prognosis by providing\ncomplementary information. Automatically segmenting tumors in PET\/CT images can\nsignificantly improve examination efficiency. Traditional multi-modal\nsegmentation solutions mainly rely on concatenation operations for modality\nfusion, which fail to effectively model the non-linear dependencies between PET\nand CT modalities. Recent studies have investigated various approaches to\noptimize the fusion of modality-specific features for enhancing joint\nrepresentations. However, modality-specific encoders used in these methods\noperate independently, inadequately leveraging the synergistic relationships\ninherent in PET and CT modalities, for example, the complementarity between\nsemantics and structure. To address these issues, we propose a Hierarchical\nAdaptive Interaction and Weighting Network termed H2ASeg to explore the\nintrinsic cross-modal correlations and transfer potential complementary\ninformation. Specifically, we design a Modality-Cooperative Spatial Attention\n(MCSA) module that performs intra- and inter-modal interactions globally and\nlocally. Additionally, a Target-Aware Modality Weighting (TAMW) module is\ndeveloped to highlight tumor-related features within multi-modal features,\nthereby refining tumor segmentation. By embedding these modules across\ndifferent layers, H2ASeg can hierarchically model cross-modal correlations,\nenabling a nuanced understanding of both semantic and structural tumor\nfeatures. Extensive experiments demonstrate the superiority of H2ASeg,\noutperforming state-of-the-art methods on AutoPet-II and Hecktor2022\nbenchmarks. The code is released at https:\/\/github.com\/JinPLu\/H2ASeg."
  },
  {
    "CAGR": -0.7548223915,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": -0.692474134,
    "title": "Ship in Sight: Diffusion Models for Ship-Image Super Resolution",
    "abstract": "In recent years, remarkable advancements have been achieved in the field of\nimage generation, primarily driven by the escalating demand for high-quality\noutcomes across various image generation subtasks, such as inpainting,\ndenoising, and super resolution. A major effort is devoted to exploring the\napplication of super-resolution techniques to enhance the quality of\nlow-resolution images. In this context, our method explores in depth the\nproblem of ship image super resolution, which is crucial for coastal and port\nsurveillance. We investigate the opportunity given by the growing interest in\ntext-to-image diffusion models, taking advantage of the prior knowledge that\nsuch foundation models have already learned. In particular, we present a\ndiffusion-model-based architecture that leverages text conditioning during\ntraining while being class-aware, to best preserve the crucial details of the\nships during the generation of the super-resoluted image. Since the specificity\nof this task and the scarcity availability of off-the-shelf data, we also\nintroduce a large labeled ship dataset scraped from online ship images, mostly\nfrom ShipSpotting\\footnote{\\url{www.shipspotting.com}} website. Our method\nachieves more robust results than other deep learning models previously\nemployed for super resolution, as proven by the multiple experiments performed.\nMoreover, we investigate how this model can benefit downstream tasks, such as\nclassification and object detection, thus emphasizing practical implementation\nin a real-world scenario. Experimental results show flexibility, reliability,\nand impressive performance of the proposed framework over state-of-the-art\nmethods for different tasks. The code is available at:\nhttps:\/\/github.com\/LuigiSigillo\/ShipinSight ."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.3053923151,
    "annual_revenue_USD_log": -1.1517610651,
    "rnd_investment_required_log": -0.5595405096,
    "title": "A Delaunay Refinement Algorithm for the Particle Finite Element Method applied to Free Surface Flows",
    "abstract": "This paper proposes two contributions to the calculation of free surface\nflows using the particle finite element method (PFEM). The PFEM is based on a\nLagrangian approach: a set of particles defines the fluid. Then, unlike a pure\nLagrangian method, all the particles are connected by a triangular mesh. The\ndifficulty lies in locating the free surface from this mesh. It is a matter of\ndeciding which of the elements in the mesh are part of the fluid domain, and to\ndefine a boundary - the free surface. Then, the incompressible Navier-Stokes\nequations are solved on the fluid domain and the particles' position is updated\nusing the resulting velocity vector. Our first contribution is to propose an\napproach to adapt the mesh with theoretical guarantees of quality: the mesh\ngeneration community has acquired a lot of experience and understanding about\nmesh adaptation approaches with guarantees of quality on the final mesh. We use\nhere a Delaunay refinement strategy, allowing to insert and remove nodes while\ngradually improving mesh quality. We show that this allows to create stable and\nsmooth free surface geometries. Our PFEM approach models the topological\nevolution of one fluid. It is nevertheless necessary to apply conditions on the\ndomain boundaries. When a boundary is a free surface, the flow on the other\nside is not modelled, it is represented by an external pressure. On the\nexternal free surface boundary, atmospheric pressure can be imposed.\nNevertheless, there may be internal free surfaces: the fluid can fully\nencapsulate cavities to form bubbles. The pressure required to maintain the\nvolume of those bubbles is a priori unknown. We propose a multi-point\nconstraint approach to enforce global incompressibility of those empty bubbles.\nThis approach allows to accurately model bubbly flows that involve two fluids\nwith large density differences, while only modelling the heavier fluid."
  },
  {
    "CAGR": 1.1784175717,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.8999974487,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.6430551002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": 0.5747930357,
    "title": "BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text",
    "abstract": "Models such as GPT-4 and Med-PaLM 2 have demonstrated impressive performance\non a wide variety of biomedical NLP tasks. However, these models have hundreds\nof billions of parameters, are computationally expensive to run, require users\nto send their input data over the internet, and are trained on unknown data\nsources. Can smaller, more targeted models compete? To address this question,\nwe build and release BioMedLM, a 2.7 billion parameter GPT-style autoregressive\nmodel trained exclusively on PubMed abstracts and full articles. When\nfine-tuned, BioMedLM can produce strong multiple-choice biomedical\nquestion-answering results competitive with much larger models, such as\nachieving a score of 57.3% on MedMCQA (dev) and 69.0% on the MMLU Medical\nGenetics exam. BioMedLM can also be fine-tuned to produce useful answers to\npatient questions on medical topics. This demonstrates that smaller models can\npotentially serve as transparent, privacy-preserving, economical and\nenvironmentally friendly foundations for particular NLP applications, such as\nin biomedicine. The model is available on the Hugging Face Hub:\nhttps:\/\/huggingface.co\/stanford-crfm\/BioMedLM."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.876511833,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -2.4658964612,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.5595405096,
    "title": "TriviaHG: A Dataset for Automatic Hint Generation from Factoid Questions",
    "abstract": "Nowadays, individuals tend to engage in dialogues with Large Language Models,\nseeking answers to their questions. In times when such answers are readily\naccessible to anyone, the stimulation and preservation of human's cognitive\nabilities, as well as the assurance of maintaining good reasoning skills by\nhumans becomes crucial. This study addresses such needs by proposing hints\n(instead of final answers or before giving answers) as a viable solution. We\nintroduce a framework for the automatic hint generation for factoid questions,\nemploying it to construct TriviaHG, a novel large-scale dataset featuring\n160,230 hints corresponding to 16,645 questions from the TriviaQA dataset.\nAdditionally, we present an automatic evaluation method that measures the\nConvergence and Familiarity quality attributes of hints. To evaluate the\nTriviaHG dataset and the proposed evaluation method, we enlisted 10 individuals\nto annotate 2,791 hints and tasked 6 humans with answering questions using the\nprovided hints. The effectiveness of hints varied, with success rates of 96%,\n78%, and 36% for questions with easy, medium, and hard answers, respectively.\nMoreover, the proposed automatic evaluation methods showed a robust correlation\nwith annotators' results. Conclusively, the findings highlight three key\ninsights: the facilitative role of hints in resolving unknown questions, the\ndependence of hint quality on answer difficulty, and the feasibility of\nemploying automatic evaluation methods for hint assessment."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.5773864797,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 1.6433203181,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.7018568771,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.6546111698,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.3526483917,
    "title": "iFace: Hand-Over-Face Gesture Recognition Leveraging Impedance Sensing",
    "abstract": "Hand-over-face gestures can provide important implicit interactions during\nconversations, such as frustration or excitement. However, in situations where\ninterlocutors are not visible, such as phone calls or textual communication,\nthe potential meaning contained in the hand-over-face gestures is lost. In this\nwork, we present iFace, an unobtrusive, wearable impedance-sensing solution for\nrecognizing different hand-over-face gestures. In contrast to most existing\nworks, iFace does not require the placement of sensors on the user's face or\nhands. Instead, we proposed a novel sensing configuration, the shoulders, which\nremains invisible to both the user and outside observers. The system can\nmonitor the shoulder-to-shoulder impedance variation caused by gestures through\nelectrodes attached to each shoulder. We evaluated iFace in a user study with\neight participants, collecting six kinds of hand-over-face gestures with\ndifferent meanings. Using a convolutional neural network and a user-dependent\nclassification, iFace reaches 82.58 \\% macro F1 score. We discuss potential\napplication scenarios of iFace as an implicit interaction interface."
  },
  {
    "CAGR": 1.8688604156,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.9725576892,
    "annual_revenue_USD_log": 0.2045195276,
    "rnd_investment_required_log": -1.2495847072,
    "title": "Collaborative Active Learning in Conditional Trust Environment",
    "abstract": "In this paper, we investigate collaborative active learning, a paradigm in\nwhich multiple collaborators explore a new domain by leveraging their combined\nmachine learning capabilities without disclosing their existing data and\nmodels. Instead, the collaborators share prediction results from the new domain\nand newly acquired labels. This collaboration offers several advantages: (a) it\naddresses privacy and security concerns by eliminating the need for direct\nmodel and data disclosure; (b) it enables the use of different data sources and\ninsights without direct data exchange; and (c) it promotes cost-effectiveness\nand resource efficiency through shared labeling costs. To realize these\nbenefits, we introduce a collaborative active learning framework designed to\nfulfill the aforementioned objectives. We validate the effectiveness of the\nproposed framework through simulations. The results demonstrate that\ncollaboration leads to higher AUC scores compared to independent efforts,\nhighlighting the framework's ability to overcome the limitations of individual\nmodels. These findings support the use of collaborative approaches in active\nlearning, emphasizing their potential to enhance outcomes through collective\nexpertise and shared resources. Our work provides a foundation for further\nresearch on collaborative active learning and its practical applications in\nvarious domains where data privacy, cost efficiency, and model performance are\ncritical considerations."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -1.1035246851,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.8006044343,
    "annual_revenue_USD_log": 2.1709094741,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Coherent Collections of Rules Describing Exceptional Materials Identified with a Multi-Objective Optimization of Subgroups",
    "abstract": "Useful materials are often statistically exceptional and they might be\noverlooked by AI models that attempt to describe all materials simultaneously.\nThese global models perform well for the majority of (useless) materials, but\nthey do not necessarily capture the useful ones. Subgroup discovery (SGD)\nidentifies rules describing subsets of materials (SGs) associated to\nexceptional values, e.g., high values, of a materials property of interest.\nThus, SGD can better capture exceptional materials compared to most widely used\nAI techniques. Previous works focused on the SG that maximizes an objective\nfunction that establishes one tradeoff between the size of the SG and the\nexceptionality of the distribution of property values in the SG. However, this\noptimization does not give a unique solution, but many SGs typically have\nsimilar objective-function values. Here, we identify a Pareto region of SGs\npresenting a multitude of size-exceptionality tradeoffs. The approach is\ndemonstrated by the learning of rules describing perovskites with high bulk\nmodulus. These rules are used to screen a large space of perovskites and to\nefficiently identify materials with bulk modulus up to 13 % higher than the\nhighest value of the training set."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.6707699505,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 1.2605876197,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 1.3861709233,
    "annual_revenue_USD_log": 1.7158314185,
    "rnd_investment_required_log": 0.3526483917,
    "title": "CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in Resource-Constrained CPS and IoT",
    "abstract": "Foundation models (FMs) emerge as a promising solution to harness distributed\nand diverse environmental data by leveraging prior knowledge to understand the\ncomplicated temporal and spatial correlations within heterogeneous datasets.\nUnlike distributed learning frameworks such as federated learning, which often\nstruggle with multimodal data, FMs can transform diverse inputs into\nembeddings. This process facilitates the integration of information from\nvarious modalities and the application of prior learning to new domains.\nHowever, deploying FMs in resource-constrained edge systems poses significant\nchallenges. To this end, we introduce CoRAST, a novel learning framework that\nutilizes FMs for enhanced analysis of distributed, correlated heterogeneous\ndata. Utilizing a server-based FM, CoRAST can exploit existing environment\ninformation to extract temporal, spatial, and cross-modal correlations among\nsensor data. This enables CoRAST to offer context-aware insights for localized\nclient tasks through FM-powered global representation learning. Our evaluation\non real-world weather dataset demonstrates CoRAST's ability to exploit\ncorrelated heterogeneous data through environmental representation learning to\nreduce the forecast errors by up to 50.3% compared to the baselines."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.4744240256,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": -0.790545315,
    "rnd_investment_required_log": -1.027440103,
    "title": "CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration",
    "abstract": "Assembly processes involving humans and robots are challenging scenarios\nbecause the individual activities and access to shared workspace have to be\ncoordinated. Fixed robot programs leave no room to diverge from a fixed\nprotocol. Working on such a process can be stressful for the user and lead to\nineffective behavior or failure. We propose a novel approach of online\nconstraint-based scheduling in a reactive execution control framework\nfacilitating behavior trees called CoBOS. This allows the robot to adapt to\nuncertain events such as delayed activity completions and activity selection\n(by the human). The user will experience less stress as the robotic coworkers\nadapt their behavior to best complement the human-selected activities to\ncomplete the common task. In addition to the improved working conditions, our\nalgorithm leads to increased efficiency, even in highly uncertain scenarios. We\nevaluate our algorithm using a probabilistic simulation study with 56000\nexperiments. We outperform all baselines by a margin of 4-10%. Initial real\nrobot experiments using a Franka Emika Panda robot and human tracking based on\nHTC Vive VR gloves look promising."
  },
  {
    "CAGR": 0.2117975901,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.0817321758,
    "ROI_percent": -0.2360999473,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": 0.1021283321,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 0.2045195276,
    "rnd_investment_required_log": 0.7562984273,
    "title": "DiffStyler: Diffusion-based Localized Image Style Transfer",
    "abstract": "Image style transfer aims to imbue digital imagery with the distinctive\nattributes of style targets, such as colors, brushstrokes, shapes, whilst\nconcurrently preserving the semantic integrity of the content. Despite the\nadvancements in arbitrary style transfer methods, a prevalent challenge remains\nthe delicate equilibrium between content semantics and style attributes. Recent\ndevelopments in large-scale text-to-image diffusion models have heralded\nunprecedented synthesis capabilities, albeit at the expense of relying on\nextensive and often imprecise textual descriptions to delineate artistic\nstyles. Addressing these limitations, this paper introduces DiffStyler, a novel\napproach that facilitates efficient and precise arbitrary image style transfer.\nDiffStyler lies the utilization of a text-to-image Stable Diffusion model-based\nLoRA to encapsulate the essence of style targets. This approach, coupled with\nstrategic cross-LoRA feature and attention injection, guides the style transfer\nprocess. The foundation of our methodology is rooted in the observation that\nLoRA maintains the spatial feature consistency of UNet, a discovery that\nfurther inspired the development of a mask-wise style transfer technique. This\ntechnique employs masks extracted through a pre-trained FastSAM model,\nutilizing mask prompts to facilitate feature fusion during the denoising\nprocess, thereby enabling localized style transfer that preserves the original\nimage's unaffected regions. Moreover, our approach accommodates multiple style\ntargets through the use of corresponding masks. Through extensive\nexperimentation, we demonstrate that DiffStyler surpasses previous methods in\nachieving a more harmonious balance between content preservation and style\nintegration."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.3806707369,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": 1.754666411,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": 0.0662541385,
    "title": "HEMIT: H&E to Multiplex-immunohistochemistry Image Translation with Dual-Branch Pix2pix Generator",
    "abstract": "Computational analysis of multiplexed immunofluorescence histology data is\nemerging as an important method for understanding the tumour micro-environment\nin cancer. This work presents HEMIT, a dataset designed for translating\nHematoxylin and Eosin (H&E) sections to multiplex-immunohistochemistry (mIHC)\nimages, featuring DAPI, CD3, and panCK markers. Distinctively, HEMIT's mIHC\nimages are multi-component and cellular-level aligned with H&E, enriching\nsupervised stain translation tasks. To our knowledge, HEMIT is the first\npublicly available cellular-level aligned dataset that enables H&E to\nmulti-target mIHC image translation. This dataset provides the computer vision\ncommunity with a valuable resource to develop novel computational methods which\nhave the potential to gain new insights from H&E slide archives.\n  We also propose a new dual-branch generator architecture, using residual\nConvolutional Neural Networks (CNNs) and Swin Transformers which achieves\nbetter translation outcomes than other popular algorithms. When evaluated on\nHEMIT, it outperforms pix2pixHD, pix2pix, U-Net, and ResNet, achieving the\nhighest overall score on key metrics including the Structural Similarity Index\nMeasure (SSIM), Pearson correlation score (R), and Peak signal-to-noise Ratio\n(PSNR). Additionally, downstream analysis has been used to further validate the\nquality of the generated mIHC images. These results set a new benchmark in the\nfield of stain translation tasks."
  },
  {
    "CAGR": 2.4212146908,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.0758772526,
    "annual_revenue_USD_log": 1.5534070302,
    "rnd_investment_required_log": 1.9548816498,
    "title": "Benchmarking Quantum Generative Learning: A Study on Scalability and Noise Resilience using QUARK",
    "abstract": "Quantum computing promises a disruptive impact on machine learning\nalgorithms, taking advantage of the exponentially large Hilbert space\navailable. However, it is not clear how to scale quantum machine learning (QML)\nto industrial-level applications. This paper investigates the scalability and\nnoise resilience of quantum generative learning applications. We consider the\ntraining performance in the presence of statistical noise due to finite-shot\nnoise statistics and quantum noise due to decoherence to analyze the\nscalability of QML methods. We employ rigorous benchmarking techniques to track\nprogress and identify challenges in scaling QML algorithms, and show how\ncharacterization of QML systems can be accelerated, simplified, and made\nreproducible when the QUARK framework is used. We show that QGANs are not as\naffected by the curse of dimensionality as QCBMs and to which extent QCBMs are\nresilient to noise."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.5252415266,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9086309264,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.7348723755,
    "annual_revenue_USD_log": 1.0983289757,
    "rnd_investment_required_log": -1.027440103,
    "title": "Bringing Textual Prompt to AI-Generated Image Quality Assessment",
    "abstract": "AI-Generated Images (AGIs) have inherent multimodal nature. Unlike\ntraditional image quality assessment (IQA) on natural scenarios, AGIs quality\nassessment (AGIQA) takes the correspondence of image and its textual prompt\ninto consideration. This is coupled in the ground truth score, which confuses\nthe unimodal IQA methods. To solve this problem, we introduce IP-IQA (AGIs\nQuality Assessment via Image and Prompt), a multimodal framework for AGIQA via\ncorresponding image and prompt incorporation. Specifically, we propose a novel\nincremental pretraining task named Image2Prompt for better understanding of\nAGIs and their corresponding textual prompts. An effective and efficient\nimage-prompt fusion module, along with a novel special [QA] token, are also\napplied. Both are plug-and-play and beneficial for the cooperation of image and\nits corresponding prompt. Experiments demonstrate that our IP-IQA achieves the\nstate-of-the-art on AGIQA-1k and AGIQA-3k datasets. Code will be available at\nhttps:\/\/github.com\/Coobiw\/IP-IQA."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 3.3426552987,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.7100391355,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -1.7569770067,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -2.0363352893,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": -0.952969694,
    "rnd_investment_required_log": 1.8499927794,
    "title": "Hydroflux-Controlled Growth of Magnetic K-Cu-Te-O(H) Phases",
    "abstract": "Innovative synthetic approaches can yield new phases containing novel\nstructural and magnetic motifs. In this work, we show the synthesis and\nmagnetic characterization of three new and one previously reported layered\nphase in the K-Cu-Te-O(H) phase space using a tunable hydroflux technique. The\nhydroflux, with a roughly equal molar ratio of water and alkali hydroxide, is a\nhighly oxidizing, low melting solvent which can be used to isolate metastable\nphases unattainable through traditional solid state or flux techniques. The\nnewly synthesized phases, K$_{2}$Cu$_{2}$TeO$_{6}$, K$_{2}$Cu$_{2}$TeO$_{6}$\n$\\cdot$ H$_{2}$O, and K$_{6}$Cu$_{9}$Te$_{4}$O$_{24}$ $\\cdot$ 2 H$_{2}$O,\ncontain Cu$^{2+}$ within CuO$_{4}$ square planar plaquettes and TeO$_{6}$\noctahedra ordering to form structural honeycomb layers isolated by interlayer\nK$^{+}$ ions and H$_{2}$O molecules. We find the synthesized structures display\nvarying tilt sequences of the CuO$_{4}$ plaquettes, leading to distinct\nCu$^{2+}$ magnetic motifs on the structural honeycomb lattice and a range of\neffective magnetic dimensionalities. We find that K$_{2}$Cu$_{2}$TeO$_{6}$\n$\\cdot$ H$_{2}$O does not order and displays alternating chain Heisenberg\nantiferromagnetic (AFM) behavior, while K$_{2}$Cu$_{2}$TeO$_{6}$ and\nK$_{6}$Cu$_{9}$Te$_{4}$O$_{24}$ $\\cdot$ 2 H$_{2}$O order antiferromagnetically\n(T$_{N}$ = 100 K and T$_{N}$ = 6.5 K respectively). The previously known phase,\nK$_{2}$CuTeO$_{4}$(OH)$_{2}$ $\\cdot$ H$_{2}$O, we find contains structurally\nand magnetically one-dimensional CuO$_{4}$ plaquettes leading to uniform chain\nHeisenberg AFM behavior and shows no magnetic order down to T = 0.4 K. We\ndiscuss and highlight the usefulness of the hydroflux technique in novel\nsyntheses and the interesting magnetic motifs that arise in these particular\nphases."
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.310959674,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 0.5923303378,
    "rnd_investment_required_log": 0.7562984273,
    "title": "JEP-KD: Joint-Embedding Predictive Architecture Based Knowledge Distillation for Visual Speech Recognition",
    "abstract": "Visual Speech Recognition (VSR) tasks are generally recognized to have a\nlower theoretical performance ceiling than Automatic Speech Recognition (ASR),\nowing to the inherent limitations of conveying semantic information visually.\nTo mitigate this challenge, this paper introduces an advanced knowledge\ndistillation approach using a Joint-Embedding Predictive Architecture (JEPA),\nnamed JEP-KD, designed to more effectively utilize audio features during model\ntraining. Central to JEP-KD is the inclusion of a generative network within the\nembedding layer, which enhances the video encoder's capacity for semantic\nfeature extraction and brings it into closer alignment with the audio features\nfrom a pre-trained ASR model's encoder. This approach aims to progressively\nreduce the performance gap between VSR and ASR. Moreover, a comprehensive\nmultimodal, multistage training regimen for the JEP-KD framework is\nestablished, bolstering the robustness and efficacy of the training process.\nExperiment results demonstrate that JEP-KD significantly improves the\nperformance of VSR models and demonstrates versatility across different VSR\nplatforms, indicating its potential for broader application within other\nmultimodal tasks."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": 0.1976124216,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.4808265359,
    "rnd_investment_required_log": 1.2648373378,
    "title": "Directed Criteria Citation Recommendation and Ranking Through Link Prediction",
    "abstract": "We explore link prediction as a proxy for automatically surfacing documents\nfrom existing literature that might be topically or contextually relevant to a\nnew document. Our model uses transformer-based graph embeddings to encode the\nmeaning of each document, presented as a node within a citation network. We\nshow that the semantic representations that our model generates can outperform\nother content-based methods in recommendation and ranking tasks. This provides\na holistic approach to exploring citation graphs in domains where it is\ncritical that these documents properly cite each other, so as to minimize the\npossibility of any inconsistencies"
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.3762510632,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 1.9391692981,
    "annual_revenue_USD_log": -1.1517610651,
    "rnd_investment_required_log": -1.027440103,
    "title": "Towards a Cloud-based Smart Office Solution for Shared Workplace Individualization",
    "abstract": "In the evolving landscape of workplace dynamics, the shift towards hybrid\nworking models has highlighted inefficiencies in the use of traditional office\nspace and the need for an improved employee experience. In this position paper\nwe propose a Smart Office solution that addresses these challenges by\nintegrating a microservice architecture with Internet of Things (IoT)\ntechnologies to provide a flexible, personalized workspace environment. The\nposition paper focuses on the technical implementation of this solution,\nincluding the design of a Workplace Environment Index (WEI) to monitor and\nimprove office conditions. By using cloud technology, IoT devices with sensors,\nand following a user-centred design, the proposed solution shows how Shared\nOpen Workspaces can be transformed into adaptive, efficient environments that\nsupport the diverse needs of the modern workforce. This position paper paves\nthe way for future experimentation in real-world office environments to\nvalidate the effectiveness of the Smart Office solution and provide insights\ninto its potential to redefine the workplace for improved productivity and\nemployee satisfaction."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.729673728,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.5316285223,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Hybridizing Traditional and Next-Generation Reservoir Computing to Accurately and Efficiently Forecast Dynamical Systems",
    "abstract": "Reservoir computers (RCs) are powerful machine learning architectures for\ntime series prediction. Recently, next generation reservoir computers (NGRCs)\nhave been introduced, offering distinct advantages over RCs, such as reduced\ncomputational expense and lower training data requirements. However, NGRCs have\ntheir own practical difficulties, including sensitivity to sampling time and\ntype of nonlinearities in the data. Here, we introduce a hybrid RC-NGRC\napproach for time series forecasting of dynamical systems. We show that our\nhybrid approach can produce accurate short term predictions and capture the\nlong term statistics of chaotic dynamical systems in situations where the RC\nand NGRC components alone are insufficient, e.g., due to constraints from\nlimited computational resources, sub-optimal hyperparameters, sparsely-sampled\ntraining data, etc. Under these conditions, we show for multiple model chaotic\nsystems that the hybrid RC-NGRC method with a small reservoir can achieve\nprediction performance approaching that of a traditional RC with a much larger\nreservoir, illustrating that the hybrid approach can offer significant gains in\ncomputational efficiency over traditional RCs while simultaneously addressing\nsome of the limitations of NGRCs. Our results suggest that hybrid RC-NGRC\napproach may be particularly beneficial in cases when computational efficiency\nis a high priority and an NGRC alone is not adequate."
  },
  {
    "CAGR": 0.3498861589,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.5136932106,
    "ROI_percent": 0.7758955802,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.0271308869,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.6551468353,
    "annual_revenue_USD_log": 1.0368654543,
    "rnd_investment_required_log": -1.2495847072,
    "title": "Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems",
    "abstract": "Microservice-based systems (MSS) may experience failures in various fault\ncategories due to their complex and dynamic nature. To effectively handle\nfailures, AIOps tools utilize trace-based anomaly detection and root cause\nanalysis. In this paper, we propose a novel framework for few-shot abnormal\ntrace classification for MSS. Our framework comprises two main components: (1)\nMulti-Head Attention Autoencoder for constructing system-specific trace\nrepresentations, which enables (2) Transformer Encoder-based Model-Agnostic\nMeta-Learning to perform effective and efficient few-shot learning for abnormal\ntrace classification. The proposed framework is evaluated on two representative\nMSS, Trainticket and OnlineBoutique, with open datasets. The results show that\nour framework can adapt the learned knowledge to classify new, unseen abnormal\ntraces of novel fault categories both within the same system it was initially\ntrained on and even in the different MSS. Within the same MSS, our framework\nachieves an average accuracy of 93.26\\% and 85.2\\% across 50 meta-testing tasks\nfor Trainticket and OnlineBoutique, respectively, when provided with 10\ninstances for each task. In a cross-system context, our framework gets an\naverage accuracy of 92.19\\% and 84.77\\% for the same meta-testing tasks of the\nrespective system, also with 10 instances provided for each task. Our work\ndemonstrates the applicability of achieving few-shot abnormal trace\nclassification for MSS and shows how it can enable cross-system adaptability.\nThis opens an avenue for building more generalized AIOps tools that require\nless system-specific data labeling for anomaly detection and root cause\nanalysis."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 1.8562839899,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": -0.7864618083,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 1.2081452101,
    "annual_revenue_USD_log": 0.4193630149,
    "rnd_investment_required_log": -0.3373958805,
    "title": "Sequential Inference of Hospitalization Electronic Health Records Using Probabilistic Models",
    "abstract": "In the dynamic hospital setting, decision support can be a valuable tool for\nimproving patient outcomes. Data-driven inference of future outcomes is\nchallenging in this dynamic setting, where long sequences such as laboratory\ntests and medications are updated frequently. This is due in part to\nheterogeneity of data types and mixed-sequence types contained in variable\nlength sequences. In this work we design a probabilistic unsupervised model for\nmultiple arbitrary-length sequences contained in hospitalization Electronic\nHealth Record (EHR) data. The model uses a latent variable structure and\ncaptures complex relationships between medications, diagnoses, laboratory\ntests, neurological assessments, and medications. It can be trained on original\ndata, without requiring any lossy transformations or time binning. Inference\nalgorithms are derived that use partial data to infer properties of the\ncomplete sequences, including their length and presence of specific values. We\ntrain this model on data from subjects receiving medical care in the Kaiser\nPermanente Northern California integrated healthcare delivery system. The\nresults are evaluated against held-out data for predicting the length of\nsequences and presence of Intensive Care Unit (ICU) in hospitalization bed\nsequences. Our method outperforms a baseline approach, showing that in these\nexperiments the trained model captures information in the sequences that is\ninformative of their future values."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.310959674,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": -1.343842487,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.2476060596,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 0.0662541385,
    "title": "Illicit object detection in X-ray images using Vision Transformers",
    "abstract": "Illicit object detection is a critical task performed at various\nhigh-security locations, including airports, train stations, subways, and\nports. The continuous and tedious work of examining thousands of X-ray images\nper hour can be mentally taxing. Thus, Deep Neural Networks (DNNs) can be used\nto automate the X-ray image analysis process, improve efficiency and alleviate\nthe security officers' inspection burden. The neural architectures typically\nutilized in relevant literature are Convolutional Neural Networks (CNNs), with\nVision Transformers (ViTs) rarely employed. In order to address this gap, this\npaper conducts a comprehensive evaluation of relevant ViT architectures on\nillicit item detection in X-ray images. This study utilizes both Transformer\nand hybrid backbones, such as SWIN and NextViT, and detectors, such as DINO and\nRT-DETR. The results demonstrate the remarkable accuracy of the DINO\nTransformer detector in the low-data regime, the impressive real-time\nperformance of YOLOv8, and the effectiveness of the hybrid NextViT backbone."
  },
  {
    "CAGR": 0.0737090213,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.5073055989,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": -1.8008719909,
    "commercialisation_success_probability_percent": -1.0271308869,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": -0.450849914,
    "annual_revenue_USD_log": 0.2820351529,
    "rnd_investment_required_log": -1.7174842259,
    "title": "Equity in Healthcare: Analyzing Disparities in Machine Learning Predictions of Diabetic Patient Readmissions",
    "abstract": "This study investigates how machine learning (ML) models can predict hospital\nreadmissions for diabetic patients fairly and accurately across different\ndemographics (age, gender, race). We compared models like Deep Learning,\nGeneralized Linear Models, Gradient Boosting Machines (GBM), and Naive Bayes.\nGBM stood out with an F1-score of 84.3% and accuracy of 82.2%, accurately\npredicting readmissions across demographics. A fairness analysis was conducted\nacross all the models. GBM minimized disparities in predictions, achieving\nbalanced results across genders and races. It showed low False Discovery Rates\n(FDR) (6-7%) and False Positive Rates (FPR) (5%) for both genders.\nAdditionally, FDRs remained low for racial groups, such as African Americans\n(8%) and Asians (7%). Similarly, FPRs were consistent across age groups (4%)\nfor both patients under 40 and those above 40, indicating its precision and\nability to reduce bias. These findings emphasize the importance of choosing ML\nmodels carefully to ensure both accuracy and fairness for all patients. By\nshowcasing effectiveness of various models with fairness metrics, this study\npromotes personalized medicine and the need for fair ML algorithms in\nhealthcare. This can ultimately reduce disparities and improve outcomes for\ndiabetic patients of all backgrounds."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.9391417136,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": -1.027440103,
    "title": "QNCD: Quantization Noise Correction for Diffusion Models",
    "abstract": "Diffusion models have revolutionized image synthesis, setting new benchmarks\nin quality and creativity. However, their widespread adoption is hindered by\nthe intensive computation required during the iterative denoising process.\nPost-training quantization (PTQ) presents a solution to accelerate sampling,\naibeit at the expense of sample quality, extremely in low-bit settings.\nAddressing this, our study introduces a unified Quantization Noise Correction\nScheme (QNCD), aimed at minishing quantization noise throughout the sampling\nprocess. We identify two primary quantization challenges: intra and inter\nquantization noise. Intra quantization noise, mainly exacerbated by embeddings\nin the resblock module, extends activation quantization ranges, increasing\ndisturbances in each single denosing step. Besides, inter quantization noise\nstems from cumulative quantization deviations across the entire denoising\nprocess, altering data distributions step-by-step. QNCD combats these through\nembedding-derived feature smoothing for eliminating intra quantization noise\nand an effective runtime noise estimatiation module for dynamicly filtering\ninter quantization noise. Extensive experiments demonstrate that our method\noutperforms previous quantization methods for diffusion models, achieving\nlossless results in W4A8 and W8A8 quantization settings on ImageNet (LDM-4).\nCode is available at: https:\/\/github.com\/huanpengchu\/QNCD"
  },
  {
    "CAGR": 0.7641518653,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.4144686061,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 1.1178478089,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.5710893717,
    "annual_revenue_USD_log": 0.6914176643,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Uncertainty-Aware Deep Video Compression with Ensembles",
    "abstract": "Deep learning-based video compression is a challenging task, and many\nprevious state-of-the-art learning-based video codecs use optical flows to\nexploit the temporal correlation between successive frames and then compress\nthe residual error. Although these two-stage models are end-to-end optimized,\nthe epistemic uncertainty in the motion estimation and the aleatoric\nuncertainty from the quantization operation lead to errors in the intermediate\nrepresentations and introduce artifacts in the reconstructed frames. This\ninherent flaw limits the potential for higher bit rate savings. To address this\nissue, we propose an uncertainty-aware video compression model that can\neffectively capture the predictive uncertainty with deep ensembles.\nAdditionally, we introduce an ensemble-aware loss to encourage the diversity\namong ensemble members and investigate the benefits of incorporating\nadversarial training in the video compression task. Experimental results on\n1080p sequences show that our model can effectively save bits by more than 20%\ncompared to DVC Pro."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.8572985792,
    "ROI_percent": -1.6095224489,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -1.1514009986,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -0.2473925479,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": 1.9391692981,
    "annual_revenue_USD_log": -0.1981394181,
    "rnd_investment_required_log": -0.8459347379,
    "title": "Mining Bug Repositories for Multi-Fault Programs",
    "abstract": "Datasets such as Defects4J and BugsInPy that contain bugs from real-world\nsoftware projects are necessary for a realistic evaluation of automated\ndebugging tools. However these datasets largely identify only a single bug in\neach entry, while real-world software projects (including those used in\nDefects4J and BugsInPy) typically contain multiple bugs at the same time. We\nlift this limitation and describe an extension to these datasets in which\nmultiple bugs are identified in individual entries. We use test case\ntransplantation and fault location translation, in order to expose and locate\nthe bugs, respectively. We thus provide datasets of true multi-fault versions\nwithin real-world software projects, which maintain the properties and\nusability of the original datasets."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": -0.9307079673,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 2.3141419596,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 2.216071444,
    "title": "Dual-Personalizing Adapter for Federated Foundation Models",
    "abstract": "Recently, foundation models, particularly large language models (LLMs), have\ndemonstrated an impressive ability to adapt to various tasks by fine-tuning\ndiverse instruction data. Notably, federated foundation models (FedFM) emerge\nas a privacy preservation method to fine-tune models collaboratively under\nfederated learning (FL) settings by leveraging many distributed datasets with\nnon-IID data. To alleviate communication and computation overhead,\nparameter-efficient methods are introduced for efficiency, and some research\nadapted personalization methods to FedFM for better user preferences alignment.\nHowever, a critical gap in existing research is the neglect of test-time\ndistribution shifts in real-world applications, and conventional methods for\ntest-time distribution shifts in personalized FL are less effective for FedFM\ndue to their failure to adapt to complex distribution shift scenarios and the\nrequirement to train all parameters. To bridge this gap, we refine the setting\nin FedFM, termed test-time personalization, which aims to learn personalized\nfederated foundation models on clients while effectively handling test-time\ndistribution shifts simultaneously. To address challenges in this setting, we\nexplore a simple yet effective solution, a Federated Dual-Personalizing Adapter\n(FedDPA) architecture. By co-working with a foundation model, a global adapter\nand a local adapter jointly tackle the test-time distribution shifts and\nclient-specific personalization. Additionally, we introduce an instance-wise\ndynamic weighting mechanism that dynamically integrates the global and local\nadapters for each test instance during inference, facilitating effective\ntest-time personalization. The effectiveness of the proposed method has been\nevaluated on benchmark datasets across different NLP tasks."
  },
  {
    "CAGR": 1.0403290029,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": 1.2238634122,
    "usd_savings_per_year": -0.768942913,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.3114647731,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 0.5747930357,
    "title": "Blind Identification of Binaural Room Impulse Responses from Smart Glasses",
    "abstract": "Smart glasses are increasingly recognized as a key medium for augmented\nreality, offering a hands-free platform with integrated microphones and\nnon-ear-occluding loudspeakers to seamlessly mix virtual sound sources into the\nreal-world acoustic scene. To convincingly integrate virtual sound sources, the\nroom acoustic rendering of the virtual sources must match the real-world\nacoustics. Information about a user's acoustic environment however is typically\nnot available. This work uses a microphone array in a pair of smart glasses to\nblindly identify binaural room impulse responses (BRIRs) from a few seconds of\nspeech in the real-world environment. The proposed method uses dereverberation\nand beamforming to generate a pseudo reference signal that is used by a\nmultichannel Wiener filter to estimate room impulse responses which are then\nconverted to BRIRs. The multichannel room impulse responses can be used to\nestimate room acoustic parameters which is shown to outperform baseline\nalgorithms in the estimation of reverberation time and direct-to-reverberant\nenergy ratio. Results from a listening experiment further indicate that the\nestimated BRIRs often reproduce the real-world room acoustics perceptually more\nconvincingly than measured BRIRs from other rooms of similar size."
  },
  {
    "CAGR": -0.4786452539,
    "years_to_50pct_penetration": -0.8052479298,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -1.2659314651,
    "annual_revenue_USD_log": 1.3546156451,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Neural Fields for 3D Tracking of Anatomy and Surgical Instruments in Monocular Laparoscopic Video Clips",
    "abstract": "Laparoscopic video tracking primarily focuses on two target types: surgical\ninstruments and anatomy. The former could be used for skill assessment, while\nthe latter is necessary for the projection of virtual overlays. Where\ninstrument and anatomy tracking have often been considered two separate\nproblems, in this paper, we propose a method for joint tracking of all\nstructures simultaneously. Based on a single 2D monocular video clip, we train\na neural field to represent a continuous spatiotemporal scene, used to create\n3D tracks of all surfaces visible in at least one frame. Due to the small size\nof instruments, they generally cover a small part of the image only, resulting\nin decreased tracking accuracy. Therefore, we propose enhanced class weighting\nto improve the instrument tracks. We evaluate tracking on video clips from\nlaparoscopic cholecystectomies, where we find mean tracking accuracies of 92.4%\nfor anatomical structures and 87.4% for instruments. Additionally, we assess\nthe quality of depth maps obtained from the method's scene reconstructions. We\nshow that these pseudo-depths have comparable quality to a state-of-the-art\npre-trained depth estimator. On laparoscopic videos in the SCARED dataset, the\nmethod predicts depth with an MAE of 2.9 mm and a relative error of 9.2%. These\nresults show the feasibility of using neural fields for monocular 3D\nreconstruction of laparoscopic scenes."
  },
  {
    "CAGR": -0.3405566851,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.8572985792,
    "ROI_percent": 0.5590393957,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.9966200997,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 1.6673875671,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.9118165304,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "Hypergraph-based Multi-View Action Recognition using Event Cameras",
    "abstract": "Action recognition from video data forms a cornerstone with wide-ranging\napplications. Single-view action recognition faces limitations due to its\nreliance on a single viewpoint. In contrast, multi-view approaches capture\ncomplementary information from various viewpoints for improved accuracy.\nRecently, event cameras have emerged as innovative bio-inspired sensors,\nleading to advancements in event-based action recognition. However, existing\nworks predominantly focus on single-view scenarios, leaving a gap in multi-view\nevent data exploitation, particularly in challenges like information deficit\nand semantic misalignment. To bridge this gap, we introduce HyperMV, a\nmulti-view event-based action recognition framework. HyperMV converts discrete\nevent data into frame-like representations and extracts view-related features\nusing a shared convolutional network. By treating segments as vertices and\nconstructing hyperedges using rule-based and KNN-based strategies, a multi-view\nhypergraph neural network that captures relationships across viewpoint and\ntemporal features is established. The vertex attention hypergraph propagation\nis also introduced for enhanced feature fusion. To prompt research in this\narea, we present the largest multi-view event-based action dataset\n$\\text{THU}^{\\text{MV-EACT}}\\text{-50}$, comprising 50 actions from 6\nviewpoints, which surpasses existing datasets by over tenfold. Experimental\nresults show that HyperMV significantly outperforms baselines in both\ncross-subject and cross-view scenarios, and also exceeds the state-of-the-arts\nin frame-based multi-view action recognition."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 1.867836726,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": 3.0890282145,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.1472391536,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 0.4999666368,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -2.2952530831,
    "enables_or_reshapes_market_1_to_10": 1.6488544853,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": -1.5704720804,
    "rnd_investment_required_log": -0.8459347379,
    "title": "Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models",
    "abstract": "To address the challenges associated with data processing at scale, we\npropose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipeline\nfor large language models (LLMs) with a user-friendly design at its core. Easy\naddition of custom processors with block-based interface in Dataverse allows\nusers to readily and efficiently use Dataverse to build their own ETL pipeline.\nWe hope that Dataverse will serve as a vital tool for LLM development and open\nsource the entire library to welcome community contribution. Additionally, we\nprovide a concise, two-minute video demonstration of our system, illustrating\nits capabilities and implementation."
  },
  {
    "CAGR": -1.4452652355,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": 1.4890352234,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -1.2031092336,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -1.7018568771,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 0.4771211221,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -0.1558904989,
    "title": "Emergent predictability in microbial ecosystems",
    "abstract": "Microbial ecosystems carry out essential functions for global climate, human\nhealth, and industry. These complex communities exhibit a surprising amount of\nfunctionally relevant diversity at all levels of taxonomic resolution,\npresenting a significant challenge for most modeling frameworks. A\nlong-standing hope of theoretical ecology is that some patterns might persist\ndespite community complexity -- or perhaps even emerge because of it. A deeper\nunderstanding of such \"emergent simplicity\" could enable new approaches for\npredicting the behaviors of the complex ecosystems in nature. However, most\nexamples described so far afford limited predictive power, as they focused on\nreproducibility rather than prediction. Here, we propose an\ninformation-theoretic framework for defining, nuancing and quantifying emergent\nsimplicity in empirical data based on the ability of simple models to predict\ncommunity-level functional properties. Applying this framework to two published\ndatasets, we demonstrate that the majority of properties measured across both\nexperiments exhibit robust evidence of emergent predictability: surprisingly,\nas community richness increases, simple compositional descriptions become more\npredictive. We show that this behavior is not typical within the standard\nmodeling frameworks of theoretical ecology, and argue that improving our\nability to predict and control natural microbial communities will require a\nshift of focus: away from complexity of _ecosystems_, and towards prediction\ncomplexity of _properties_ of ecosystems."
  },
  {
    "CAGR": -1.0309995291,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.808212098,
    "ROI_percent": 1.281893344,
    "novelty_1_to_10": -2.2988573914,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": -2.5229468335,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -2.2573987178,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -0.4834180283,
    "annual_revenue_USD_log": 0.4193630149,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Predicting Excitation Energies in Warm Dense Matter",
    "abstract": "In a dense plasma environment, the energy levels of an ion shift relative to\nthe isolated ion values. This shift is reflected in the optical spectrum of the\nplasma and can be measured in, for example, emission experiments. In this work,\nwe use a recently developed method of modeling electronic states in warm dense\nmatter to predict these level energies. In this model, excited state energies\nare calculated directly by enforcing constrained one-electron occupation\nfactors, thus allowing the calculation of specific transition and ionization\nenergies. This model includes plasma effects self-consistently, so the effect\nof continuum lowering is included in an ab-initio sense. We use the model to\ncalculate the K-edge and K-alpha energies of solid density magnesium, aluminum,\nand silicon over a range of temperatures, finding close agreement with\nexperimental results. We also calculate the ionization potential depression\n(IPD) to compare to widely used models, and investigate the effects of\ntemperature on the lowering of the continuum."
  },
  {
    "CAGR": 1.592683278,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.5152628518,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 1.8004679874,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -0.6288756272,
    "annual_revenue_USD_log": 0.119610767,
    "rnd_investment_required_log": -1.027440103,
    "title": "CDIMC-net: Cognitive Deep Incomplete Multi-view Clustering Network",
    "abstract": "In recent years, incomplete multi-view clustering, which studies the\nchallenging multi-view clustering problem on missing views, has received\ngrowing research interests. Although a series of methods have been proposed to\naddress this issue, the following problems still exist: 1) Almost all of the\nexisting methods are based on shallow models, which is difficult to obtain\ndiscriminative common representations. 2) These methods are generally sensitive\nto noise or outliers since the negative samples are treated equally as the\nimportant samples. In this paper, we propose a novel incomplete multi-view\nclustering network, called Cognitive Deep Incomplete Multi-view Clustering\nNetwork (CDIMC-net), to address these issues. Specifically, it captures the\nhigh-level features and local structure of each view by incorporating the\nview-specific deep encoders and graph embedding strategy into a framework.\nMoreover, based on the human cognition, i.e., learning from easy to hard, it\nintroduces a self-paced strategy to select the most confident samples for model\ntraining, which can reduce the negative influence of outliers. Experimental\nresults on several incomplete datasets show that CDIMC-net outperforms the\nstate-of-the-art incomplete multi-view clustering methods."
  },
  {
    "CAGR": -0.4786452539,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.8866685007,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.5566742331,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.6009451201,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": -1.6126329047,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 1.0426926888,
    "title": "Swarm Characteristics Classification Using Neural Networks",
    "abstract": "Understanding the characteristics of swarming autonomous agents is critical\nfor defense and security applications. This article presents a study on using\nsupervised neural network time series classification (NN TSC) to predict key\nattributes and tactics of swarming autonomous agents for military contexts.\nSpecifically, NN TSC is applied to infer two binary attributes - communication\nand proportional navigation - which combine to define four mutually exclusive\nswarm tactics. We identify a gap in literature on using NNs for swarm\nclassification and demonstrate the effectiveness of NN TSC in rapidly deducing\nintelligence about attacking swarms to inform counter-maneuvers. Through\nsimulated swarm-vs-swarm engagements, we evaluate NN TSC performance in terms\nof observation window requirements, noise robustness, and scalability to swarm\nsize. Key findings show NNs can predict swarm behaviors with 97% accuracy using\nshort observation windows of 20 time steps, while also demonstrating graceful\ndegradation down to 80% accuracy under 50% noise, as well as excellent\nscalability to swarm sizes from 10 to 100 agents. These capabilities are\npromising for real-time decision-making support in defense scenarios by rapidly\ninferring insights about swarm behavior."
  },
  {
    "CAGR": -1.1690880979,
    "years_to_50pct_penetration": 1.0382646162,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": 1.983678614,
    "usd_savings_per_year": -0.8180293942,
    "ROI_percent": 1.281893344,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -2.0830009669,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 1.435773719,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -2.2523127556,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": -3.0614283806,
    "improvement_compared_to_existing_1_to_10": -0.9300127263,
    "enables_or_reshapes_market_1_to_10": -1.2992973344,
    "global_market_size_USD_log": -1.1818740016,
    "annual_revenue_USD_log": -0.335467278,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Ghost cycles exhibit increased entrainment and richer dynamics in response to external forcing compared to slow-fast systems",
    "abstract": "Many natural, living and engineered systems display oscillations that are\ncharacterized by multiple timescales. Typically, such systems are described as\nslow-fast systems, where the slow dynamics result from a hyperbolic slow\nmanifold that guides the movement of the system trajectories. Recently, we have\nprovided an alternative description in which the slow dynamics result from a\nnon-hyperbolic and Lyapunov-unstable attracting sets from connected dynamical\nghosts that form a closed orbit (termed ghost cycles). Here we investigate the\nresponse properties of both type of systems to external forcing. Using the\nclassical Van-der-Pol oscillator and two modified versions of this model that\ncorrespond to a 1-ghost and a 2-ghost cycle, respectively, we find that ghost\ncycles are characterized by significant increase especially in the 1:1\nentrainment regions as demonstrated by the corresponding Arnold tongues and\nexhibit richer dynamics (bursting, chaos) in contrast to the classical\nslow-fast system. Phase plane analysis reveals that these features result from\nthe continuous remodeling of the attractor landscape of the ghost cycles models\ncharacteristic for non-autonomous systems, whereas the attractor landscape of\nthe corresponding slow-fast system remains qualitatively unaltered. We propose\nthat systems containing ghost cycles display increased flexibility and\nresponsiveness to continuous environmental changes."
  },
  {
    "CAGR": -0.6167338227,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": -1.5033194645,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": 0.1146137491,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": 2.4137341868,
    "commercialisation_success_probability_percent": 1.4365659664,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -0.6378639301,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 2.7875027103,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.1546902707,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.1021484606,
    "annual_revenue_USD_log": 0.6432509228,
    "rnd_investment_required_log": 0.3526483917,
    "title": "RSMamba: Remote Sensing Image Classification with State Space Model",
    "abstract": "Remote sensing image classification forms the foundation of various\nunderstanding tasks, serving a crucial function in remote sensing image\ninterpretation. The recent advancements of Convolutional Neural Networks (CNNs)\nand Transformers have markedly enhanced classification accuracy. Nonetheless,\nremote sensing scene classification remains a significant challenge, especially\ngiven the complexity and diversity of remote sensing scenarios and the\nvariability of spatiotemporal resolutions. The capacity for whole-image\nunderstanding can provide more precise semantic cues for scene discrimination.\nIn this paper, we introduce RSMamba, a novel architecture for remote sensing\nimage classification. RSMamba is based on the State Space Model (SSM) and\nincorporates an efficient, hardware-aware design known as the Mamba. It\nintegrates the advantages of both a global receptive field and linear modeling\ncomplexity. To overcome the limitation of the vanilla Mamba, which can only\nmodel causal sequences and is not adaptable to two-dimensional image data, we\npropose a dynamic multi-path activation mechanism to augment Mamba's capacity\nto model non-causal data. Notably, RSMamba maintains the inherent modeling\nmechanism of the vanilla Mamba, yet exhibits superior performance across\nmultiple remote sensing image classification datasets. This indicates that\nRSMamba holds significant potential to function as the backbone of future\nvisual foundation models. The code will be available at\n\\url{https:\/\/github.com\/KyanChen\/RSMamba}."
  },
  {
    "CAGR": 2.4212146908,
    "years_to_50pct_penetration": 0.1165083432,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 2.0780729981,
    "ROI_percent": 0.053041632,
    "novelty_1_to_10": 2.1949731652,
    "number_distinct_patents": 1.0088654609,
    "commercialisation_success_probability_percent": 0.3806958864,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": 0.5363978213,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": -0.2792323317,
    "annual_revenue_USD_log": 0.7371132038,
    "rnd_investment_required_log": 0.3526483917,
    "title": "Capability-aware Prompt Reformulation Learning for Text-to-Image Generation",
    "abstract": "Text-to-image generation systems have emerged as revolutionary tools in the\nrealm of artistic creation, offering unprecedented ease in transforming textual\nprompts into visual art. However, the efficacy of these systems is intricately\nlinked to the quality of user-provided prompts, which often poses a challenge\nto users unfamiliar with prompt crafting. This paper addresses this challenge\nby leveraging user reformulation data from interaction logs to develop an\nautomatic prompt reformulation model. Our in-depth analysis of these logs\nreveals that user prompt reformulation is heavily dependent on the individual\nuser's capability, resulting in significant variance in the quality of\nreformulation pairs. To effectively use this data for training, we introduce\nthe Capability-aware Prompt Reformulation (CAPR) framework. CAPR innovatively\nintegrates user capability into the reformulation process through two key\ncomponents: the Conditional Reformulation Model (CRM) and Configurable\nCapability Features (CCF). CRM reformulates prompts according to a specified\nuser capability, as represented by CCF. The CCF, in turn, offers the\nflexibility to tune and guide the CRM's behavior. This enables CAPR to\neffectively learn diverse reformulation strategies across various user\ncapacities and to simulate high-capability user reformulation during inference.\nExtensive experiments on standard text-to-image generation benchmarks showcase\nCAPR's superior performance over existing baselines and its remarkable\nrobustness on unseen systems. Furthermore, comprehensive analyses validate the\neffectiveness of different components. CAPR can facilitate user-friendly\ninteraction with text-to-image systems and make advanced artistic creation more\nachievable for a broader range of users."
  },
  {
    "CAGR": -0.5476895383,
    "years_to_50pct_penetration": -0.3443697933,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -1.055582193,
    "usd_savings_per_year": 3.0598026227,
    "ROI_percent": 2.7276012404,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": 0.1167283664,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": 0.3989548944,
    "technological_risk_1_to_10": -0.5945919245,
    "competitors_count": 1.0504225153,
    "5_year_market_share_percent": 0.7218301117,
    "disruption_score_1_to_10": 0.4092811451,
    "standalone_commericality_1_to_10": 0.9587199335,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.0356259449,
    "annual_revenue_USD_log": -1.3141854392,
    "rnd_investment_required_log": 0.4917846862,
    "title": "Latent Embedding Clustering for Occlusion Robust Head Pose Estimation",
    "abstract": "Head pose estimation has become a crucial area of research in computer vision\ngiven its usefulness in a wide range of applications, including robotics,\nsurveillance, or driver attention monitoring. One of the most difficult\nchallenges in this field is managing head occlusions that frequently take place\nin real-world scenarios. In this paper, we propose a novel and efficient\nframework that is robust in real world head occlusion scenarios. In particular,\nwe propose an unsupervised latent embedding clustering with regression and\nclassification components for each pose angle. The model optimizes latent\nfeature representations for occluded and non-occluded images through a\nclustering term while improving fine-grained angle predictions. Experimental\nevaluation on in-the-wild head pose benchmark datasets reveal competitive\nperformance in comparison to state-of-the-art methodologies with the advantage\nof having a significant data reduction. We observe a substantial improvement in\noccluded head pose estimation. Also, an ablation study is conducted to\nascertain the impact of the clustering term within our proposed framework."
  },
  {
    "CAGR": 0.4879747277,
    "years_to_50pct_penetration": -1.2661260663,
    "TRL": 0.7441179958,
    "time_to_TRL_7_years": -0.2957669913,
    "usd_savings_per_year": -0.2780781007,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": -0.8009138725,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.3232175002,
    "break_even_time_years": -0.7047004036,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": 2.1513342723,
    "5_year_market_share_percent": -0.7241407074,
    "disruption_score_1_to_10": -1.9822047618,
    "standalone_commericality_1_to_10": -1.453369055,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": -0.5622593795,
    "global_market_size_USD_log": 0.3705887071,
    "annual_revenue_USD_log": -0.1981394181,
    "rnd_investment_required_log": -0.5595405096,
    "title": "LayerNorm: A key component in parameter-efficient fine-tuning",
    "abstract": "Fine-tuning a pre-trained model, such as Bidirectional Encoder\nRepresentations from Transformers (BERT), has been proven to be an effective\nmethod for solving many natural language processing (NLP) tasks. However, due\nto the large number of parameters in many state-of-the-art NLP models,\nincluding BERT, the process of fine-tuning is computationally expensive. One\nattractive solution to this issue is parameter-efficient fine-tuning, which\ninvolves modifying only a minimal segment of the model while keeping the\nremainder unchanged. Yet, it remains unclear which segment of the BERT model is\ncrucial for fine-tuning. In this paper, we first analyze different components\nin the BERT model to pinpoint which one undergoes the most significant changes\nafter fine-tuning. We find that output LayerNorm changes more than any other\ncomponents when fine-tuned for different General Language Understanding\nEvaluation (GLUE) tasks. Then we show that only fine-tuning the LayerNorm can\nreach comparable, or in some cases better, performance to full fine-tuning and\nother parameter-efficient fine-tuning methods. Moreover, we use Fisher\ninformation to determine the most critical subset of LayerNorm and demonstrate\nthat many NLP tasks in the GLUE benchmark can be solved by fine-tuning only a\nsmall portion of LayerNorm with negligible performance degradation."
  },
  {
    "CAGR": -1.3071766667,
    "years_to_50pct_penetration": 1.9600208892,
    "TRL": -0.3796007344,
    "time_to_TRL_7_years": 0.4640482105,
    "usd_savings_per_year": -0.5725969881,
    "ROI_percent": -0.1638145525,
    "novelty_1_to_10": 0.6970296464,
    "number_distinct_patents": -0.396003265,
    "commercialisation_success_probability_percent": -0.7631633669,
    "break_even_time_years": 0.5757917932,
    "adoption_risk_1_to_10": -1.6746827546,
    "technological_risk_1_to_10": -1.7255816704,
    "competitors_count": -0.0504892417,
    "5_year_market_share_percent": -0.3110061877,
    "disruption_score_1_to_10": 1.6050240986,
    "standalone_commericality_1_to_10": -0.6493393921,
    "improvement_compared_to_existing_1_to_10": 0.4352276305,
    "enables_or_reshapes_market_1_to_10": 0.1747785754,
    "global_market_size_USD_log": 1.3861709233,
    "annual_revenue_USD_log": -0.696683038,
    "rnd_investment_required_log": -0.3373958805,
    "title": "A microstructure-sensitive electro-chemo-mechanical phase-field model of pitting and stress corrosion cracking",
    "abstract": "An electro-chemo-mechanical phase-field formulation is developed to simulate\npitting and stress corrosion in polycrystalline materials. The formulation\nincorporates dependencies of mechanical properties and corrosion potential on\ncrystallographic orientation. The model considers the formation and charging\ndynamics of an electric double layer through a new general boundary condition\nfor the solution potential. The potential of the model is demonstrated by\nsimulating corrosion in polycrystalline materials with various grain morphology\ndistributions. The results show that incorporating the underlying\nmicrostructure yields more extensive defects, faster defect kinetics, and\nirregular pit and crack shapes relative to a microstructurally-insensitive\nhomogeneous material scenario."
  }
]